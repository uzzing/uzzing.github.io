[ { "title": "[AWS] Cloudfront", "url": "/posts/cloudfront/", "categories": "Development", "tags": "eng", "date": "2023-04-25 13:00:00 +0900", "snippet": "Cloudfront Edge Location을 활용해서 정적/동적 콘텐츠를 유저들에게 보다 빠르게 전달해주는 서비스 Edge Location : 콘텐츠가 캐시(Cache)되고 유저에게 제공하는 곳 원리 : Cloudfront는 여러 나라의 Edge를 보유하고있음 » 만약 요청 받은 컨텐츠가 Edge Location에 있다면 » 바로 유저들에게 콘텐츠를 제공 만약 요청 받은 컨텐츠가 Edge Location에 없다면 » 가장 가까운 Edge에 접근하여, origin에서 정보를 제공받고, TTL(Time to Live)만큼 Edge Location에 캐싱 » 유저들에게 콘텐츠를 제공 Edge와 Origin 사이의 데이터 전송의 지속적인 연결을 유지하기에 콘텐츠 전송 속도의 향상이 증가됩니다. origin (ex. AWS service(EC2 Instance, S3 Bucket), On-Premise etc…) static contents : S3 (캐싱으로 접근 속도 최적화) dynamic contents : 네트워크 최적화, 연결 유지, Gzip 압축 등을 사용 Content Delivery Network(CDN) 만약 특정 웹 페이지를 서버에 요청할 때 현재 어디에서 불려지는지, 웹 페이지를 불러오려고 하는 사용자가 어디에 거주하는지에 근거하여 콘텐츠 웹 페이지에 전달해주는 분산 네트워크 대부분 CDN은 보통 정적/동적 컨텐츠를 분리해서 사용 동적 컨텐츠는 App Server에서 구동되고, 그 안에 정적 컨텐츠는 CDN Server를 통해 End-Point를 구분지어 컨텐츠를 전달 정적 컨텐츠 파일 html, css, js, image, etc… (서버(EC2)가 필요하지 않은, 자주 바뀌지 않는 정적 파일들) 여러 CDN Server에 올려 사용자가 좀 더 빠르게 콘텐츠를 전달받을 수 있게 해준다. origin : S3 S3에 넣어 호스팅하는것이 훨씬 저렴하게 먹힌다. 수천, 수만명 사람들에게 한꺼번에 서비스 되어도 상관 없을 정도로 견고하기 때문에 따로 오토스케일링이나 로드밸런서 작업이 필요없다. 동적 컨텐츠 서버가 필요한 콘텐츠 (Node.js 웹서버, PHP, Go, Python 등 서버에서 매번 바뀌는 컨텐츠, DB조회 등 ex. 로그인, 게시판) 자주 변경되는 정보, 사용자가 보낸 요청에 포함된 요인에 따라 그 내용이 변경되는 컨텐츠 정적 캐싱한다면 TTL 시간 동안 사용자는 새롭게 추가/수정된 데이터를 볼 수 없게 된다. Example서버(EC2)의 연산이 필요한 동적 콘텐츠의 요청을 EC2로 향하게 Distribution 처리하고 서버가 필요하지 않은 정적 콘텐츠는 S3 버킷 등으로 Distribution 처리하는 구성을 고려해볼 수 있다. https://blog.bespinglobal.com/post/cloudfront%EB%A5%BC-%EC%82%AC%EC%9A%A9%ED%95%98%EC%97%AC-%EC%BD%98%ED%85%90%EC%B8%A0-%EA%B0%80%EC%86%8D%ED%99%94%ED%95%98%EA%B8%B01/Recommend 특별한 이유가 없는 한 Cloudfront를 App Server 앞단에 배치하여 보안 및 성능 증가를 권장한다. 또한 Cloudfront Traffic의 경우 사용량에 따라 비용을 절감하기를 바란다. (CloudFront의 경우 사용량에 따라 비용을 할인 받을 수 있다.) reference https://inpa.tistory.com/entry/AWS-%F0%9F%93%9A-S3-%EC%A0%95%EC%A0%81-%EC%9B%B9-%EC%82%AC%EC%9D%B4%ED%8A%B8-%ED%98%B8%EC%8A%A4%ED%8C%85-%EB%8F%84%EB%A9%94%EC%9D%B8-%EC%84%A4%EC%A0%95Route-53 https://medium.com/wizpace/aws-cloudfront%EB%A5%BC-%EC%82%AC%EC%9A%A9%ED%95%98%EC%97%AC-%EB%8F%99%EC%A0%81-%EC%BB%A8%ED%85%90%EC%B8%A0-%EC%A0%84%EC%86%A1%ED%95%98%EA%B8%B0-dynamic-content-delivery-c249da4b269b https://overcome-the-limits.tistory.com/378 https://blog.leedoing.com/35 https://bosungtea9416.tistory.com/entry/AWS-CloudFront https://velog.io/@ragnarok_code/Amazon-CloudFront%EB%9E%80 " }, { "title": "[Development] Redis", "url": "/posts/redis/", "categories": "Development", "tags": "eng", "date": "2023-04-21 17:00:00 +0900", "snippet": "Redis an in-memory key-value store that can be used as a database, cache or message broker. Redis began as a caching database, but it has since evolved into a primary database. Many applications built today use Redis as a primary database. However, most Redis service providers support Redis as a cache but not as a primary database. you can use Redis as both an in-memory cache and a primary database in a single system, thus eliminating the complexity and latency of two separate systemsRedis as a Cache vs Redis as a Primary Database scalability (Scaling) fast performance » real-time analytics, chat/messaging, media streaming, and pub/sub apps. https://redis.com/blog/redis-cache-vs-redis-primary-database-in-90-seconds/#:~:text=Redis%20began%20as%20a%20caching,not%20as%20a%20primary%20database.Redis VS Memcached Memcached에 비해 다양한 기능을 제공하며 싱글 스레드 방식으로 동작하여 가볍기 때문입니다.Spring Data Redis (What I used)https://docs.spring.io/spring-data/data-redis/docs/current/reference/html/application.ymlspring: cloud: cache: type: redis cache-names: - *** - *** - *** redis: host: *** lettuce: pool: max-active: ** min-idle: **lettuce a Redis client of Java that is fully non-blocking. It supports both synchronous and asynchronous communication. scalable thread-safe https://www.baeldung.com/java-redis-lettuceJedis VS Lettuce commonality : Redis에 접근하기 위해서 사용하는 Spring Data Redis Library (성능과 사용성을 위해 만들어진 클라이언트) Jedis : deprecated 동기 방식으로 작동하여 Blocking 이슈가 발생 가능하다는 단점이 있습니다. Lettuce Lettuce 역시 클라이언트 라이브러리이며 동기, 비동기 방식을 둘 다 지원하여 non-blocking하게 요청을 처리할 수 있고 확장성이 뛰어나다는 장점이 있습니다. 하지만 사용성이 Jedis에 비해 어렵다는 단점이 있습니다. ** 빠르게 쉽게 개발할 필요성보다 추후 변경 사항 및 튜닝 등을 대비하여 확장성이 높으며 비동기 처리를 통해 안정적으로 요청을 처리할 수 있는 Lettuce가 더 적합 https://abbo.tistory.com/107 https://velog.io/@gale4739/Spring-Boot-Redis-%EC%A0%81%EC%9A%A9%EA%B8%B0-With-lettuce https://redis.com/blog/jedis-vs-lettuce-an-exploration/#:~:text=What%20is%20Lettuce%3F,Sentinel%2C%20Pipelining%2C%20and%20codecs. non-blocking VS blocking https://1-7171771.tistory.com/131 pooling max-acitve : Maximum active connections to Redis instance maxidle : the max number of connections that can be idle in the pool without being quickly closed (the default value is 8) minIdle : This is the number of connections that are ready for immediate use. https://medium.com/geekculture/the-pooling-of-connections-in-redis-e8188335bf64#:~:text=maxIdle%3A%20This%20is%20the%20max,a%20short%20period%20of%20time. max-active VS max-idle max-active : the maximum number of active connections that can be allocated from this pool at the same time. max-idle : The maximum number of connections that should be kept in the pool at all times. https://stackoverflow.com/questions/9451818/what-is-the-difference-between-maxactive-vs-maxidle-for-tomcat-connection-poolshow to use Redis-clibrew install redis ( default port : 6379)redis-cli --raw -h ... -p ... (--raw : 한글 안깨져서 나옴)&amp;gt;&amp;gt; ping (접속 테스트)&amp;gt;&amp;gt; keys * &amp;gt;&amp;gt; get (key name)Caching 한번 처리한 데이터를 임시로 저장소에 저장하는 것으로, 이 임시 데이터를 동일하거나 유사 요청이 왔을 경우 저장소에서 바로 읽어와서 응답을 하여 성능 및 응답속도 향상을 위한 기술@Cachable vs @CacheEvict @Cacheable 캐시가 있으면 캐시의 정보를 가져오고, 없으면 등록한다. @CacheEvict 캐시삭제 먼저 Evict 에 대해서는 Cache 자체를 지운다는 의미보다는, 메모리가 부족해서 더 이상 캐시할 수 없을 때, 메모리를 확보하기 위해서, 기존 캐시된 데이터를 지우는 것을 의미합니다. https://charsyam.wordpress.com/2022/04/18/%EC%9E%85-%EA%B0%9C%EB%B0%9C-spring-%EC%9D%98-cacheevict-%EC%97%90%EC%84%9C-allentriestrue-%EB%8A%94-redis%EC%97%90%EC%84%9C-%EC%96%B4%EB%96%BB%EA%B2%8C-%EB%8F%99%EC%9E%91%ED%95%98%EA%B2%8C/ @Cacheable(cacheNames = CacheNames.DISCLOSURE)@Cacheable(cacheNames = CacheNames.ADD_ATTR, key = “#root.methodName”, condition = “#result != null”)@Cacheable(cacheNames = CacheNames.SUPPLIER, key = “#supplierCode”)@Cacheable(value = “ownerCode”, key = “#result == null”)public String getOwnerCode() {...}@Cacheable(cacheNames = CacheNames.PROMO, key = “#root.methodName”, unless = “#result.isEmpty()”)@CacheEvict(cacheNames = CacheNames.DISCLOSURE)@CacheEvict(cacheNames = ”supplier”, key = “#request.supplierCode”)public void changeSupplier(@NotNull SupplierModifyRequest request) {...} https://yonguri.tistory.com/82Redis Sharding Sharding, also known as partitioning, is splitting the data up by key; While replication, also known as mirroring, is to copy all data. Sharding is useful to increase performance, reducing the hit and memory load on any one resource. Replication is useful for getting a high availability of reads. Sharding is used to scale Writes while Replication is used to scale Reads. https://stackoverflow.com/questions/2139443/redis-replication-and-redis-sharding-cluster-difference#:~:text=Sharding%2C%20also%20known%20as%20partitioning,a%20high%20availability%20of%20reads. Redis Redis Çluster Redis scales horizontally with a deployment topology called Redis Cluster. https://redis.io/docs/management/scaling/ Advantages High Performance High Availability Horizontal &amp;amp; Vertical Scalability Native Solution https://scalegrid.io/blog/intro-to-redis-cluster-sharding-advantages-limitations-deploying-and-client-connections/" }, { "title": "[Development] ElasticSearch - UpdateByQuery", "url": "/posts/ElasticSearch-detail/", "categories": "Development", "tags": "eng", "date": "2023-03-28 17:00:00 +0900", "snippet": "Update VS Reindex An update is a reindex of the original document, then marking that original as deleted, then having to merge it out of the segement. A reindex adds the original document to a new segment in a new index (usually), and leaves the original.https://discuss.elastic.co/t/update-vs-reindex/269929UpdateByQuery Sync bulkUpdateByQueryAsync Asynchronous execution Executing a UpdateByQueryRequest can also be done in an asynchronous fashion so that the client can return directly. Users need to specify how the response or potential failures will be handled by passing the request and a listener to the asynchronous update-by-query method: UpdateByQuery ctx._source map ctx is a special variable that allows you to access the source of the object that you want to update. The ctx._source is a writable version of the source. NOTE: You can modify this document in the script and the modified source will be persisted as the new version of the document. https://stackoverflow.com/questions/37696380/elasticsearch-update-with-scripts-what-does-ctx-mean#:~:text=ctx%20is%20a%20special%20variable,new%20version%20of%20the%20document. 작업 중간에 실패하더라도 이미 UPDATE된 내용은 롤백하지 않는다. ES의 경우 오류가 발생하면 업데이트된 내용은 남겨둡니다. 이어서 작업을 즉시 중지하고 이후의 작업도 중지됩니다. conflicts 옵션은 default 값은 ‘abort’ : 충돌이 발생시 그 상태에서 중지 conflicts ‘proceed’ : 충돌이 발생 시 멈추지 않고 변경하려는 내용으로 업데이트 https://danawalab.github.io/elastic/2022/01/12/Update-By-Query-copy.html boolQuery().filter() vs termsQuery() the only difference is “caching” filter is not cached by default the succeeding calls will befaster since the first call will cache the result of the above filter. Filter query works much much faster as chunks with just terms query. But making really big filter can slower getting the result a lot. In my case, using filter query with chunks of 10 000 ids is 10 times faster, than using filter query with all 100 000 ids at once (btw, this number is already restricted in Elasticsearch 6). https://stackoverflow.com/questions/51464083/elasticsearch-filter-vs-term-query-for-many-ids Generally, filters are executed in a “non-scoring” mode which gives them two main performance advantages. Firstly, they can omit the actual scoring of the document. Scoring a doc is relatively quick (the summation of a bunch of multiplications), but even 1ns for a billion documents is 1 second of computation. Secondly, non-scoring filters can be cached, meaning subsequent executions of the filter clause can leverage the cache instead of hitting the various data-structures. Where possible, we encourage people to convert queries =&amp;gt; filters for better performance (assuming you don’t need the scoring aspect) https://discuss.elastic.co/t/filter-performance-difference-bool-vs-terms/59928 for clarity and simplicity, we will use the term “filter” to mean a query which is used in a non-scoring, filtering context. You can think of the terms “filter”, “filtering query” and “non-scoring query” as being identical. Similarly, if the term “query” is used in isolation without a qualifier, we are referring to a “scoring query”. https://nag-9-s.gitbook.io/elastic-search-notes/query-dsl/query-and-filter-context/termquery-vs-termfilter filter vs match term is designed for exact comparison while match is analyzed and used as full-text search. https://stackoverflow.com/questions/53053054/query-vs-filter-in-elastic-search _search APIif arrayGET /product/_search{ &quot;query&quot;: { &quot;nested&quot; : { &quot;path&quot;: &quot;flags&quot;, &quot;query&quot;: { &quot;term&quot;: { &quot;flags.flagCode&quot;: { &quot;value&quot;: &quot;dd&quot; } } } } }}if arrayGET /product/_search{ &quot;query&quot;: { &quot;nested&quot; : { &quot;path&quot;: &quot;flags&quot;, &quot;query&quot;: { &quot;term&quot;: { &quot;flags.flagCode&quot;: { &quot;value&quot;: &quot;dd&quot; } } } } }}" }, { "title": "[Development] StopWatch", "url": "/posts/Stopwatch/", "categories": "Development", "tags": "eng", "date": "2023-03-27 17:00:00 +0900", "snippet": "StopWatch allowing for timing of a number of tasks, exposing total running time and running time for each named task.Methods@Slf4jpublic class ... {StopWatch stopwatch = new StopWatch();stopWatch.start();// logic 1stopWatch.stop();log.info(&quot;stopwatch 1 : &quot; + stopWatch.getTotalTimeSeconds());stopWatch.start();// logic 2stopWatch.stop();log.info(&quot;stopwatch 2 : &quot; + stopWatch.getTotalTimeSeconds());// Generate a string with a table describing all tasks performed.log.info(stopWatch.prettyPrint());}https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/util/StopWatch.html" }, { "title": "[Tokyo] 在留期間更新申請", "url": "/posts/renewal-of-residence-period/", "categories": "Tokyo", "tags": "tokyo", "date": "2023-03-08 18:00:00 +0900", "snippet": "必要書類会社側 申請書 2枚 下のリンクでダウンロード 登記事項証明書 法定調書合計表本人 申請書 2枚 下のリンクでダウンロード 住民税の課税証明書、納税証明書 前年分の給与所得の源泉徴収書 パスポート 在留カード 証明写真 (3x4)https://www.moj.go.jp/isa/applications/status/gijinkoku.html位置出張所によって担当区域が違うので、お住まいのところを担当になる出張所を確認必要。私の場合、品川の出入国在留管理局（普通はここで申請）品川の場合、予約システムあり 申請予約リンク： https://www.tokyoimmi-yoyaku.moj.go.jp/事前に予約したら、待ち時間を短くできる。私の場合、3時30分に予約し、完了まで30分がかかった。申請順序 ２階のB1カウンター内の「申請予約レーン」で予約画面確認、書類提出 確認後、ハガキと番号表をもらう ハガキに受け取る住所と名前を書く B２窓口のお近くで待つ 自分の番号が呼ばれたら、ハガキを提出、申請受付票と在留カード、パスポートをもらう 完了。オンライン申請 マイナンバーカードがあれば、オンライン申請をおすすめ リンク： https://www.moj.go.jp/isa/applications/guide/onlineshinsei.html" }, { "title": "[Tokyo] 板橋区役所関連", "url": "/posts/itabashiku/", "categories": "Tokyo", "tags": "tokyo", "date": "2023-03-06 14:00:00 +0900", "snippet": "区役所運営時間 月曜日から金曜日（祝日を除く）　午前8時30分から午後5時 注：毎月第2日曜日は午前9時から午後5時まで、一部の窓口を開設しております。 注：毎週火曜日は午後7時まで一部の窓口を延長して開設しております。 休日・夜間の取扱業務については、以下をご確認ください。 リアルタイム窓口情報https://madoguchi.city.itabashi.tokyo.jp/国保年金課国民年金係 南館2階25番窓口 国民年金保険料の免除申請必要転入転出 住民票2枚マイナンバーカードの申請 PayPayに登録し、20000ポイントお得" }, { "title": "[Tokyo] Go Travel to Taiwan", "url": "/posts/tokyo-to-taiwan/", "categories": "Tokyo", "tags": "tokyo", "date": "2023-03-06 14:00:00 +0900", "snippet": "Flight - ScootBus池袋 &amp;gt; 成田空港第１ターミナルhttps://travel.willer.co.jp/st/share/lib/php/location/index.php?busStopId=10303&amp;amp;lang=ja&amp;amp;ret=3 池袋 乗り場：JR池袋駅 中央改札から5分 中野 &amp;gt; 池袋 成田空港第１ターミナル &amp;gt; 渋谷駅 成田空港到着ロビー内ローコストバス乗車券カウンターで乗車券をお買い求めください。" }, { "title": "[Development] Apache / Spring Utils", "url": "/posts/Utils/", "categories": "Development", "tags": "eng", "date": "2023-02-21 17:00:00 +0900", "snippet": "DateUtilsimport org.apache.commons.lang3.time.DateUtils; https://commons.apache.org/proper/commons-lang/apidocs/org/apache/commons/lang3/time/DateUtils.html truncate addMilliseconds Date now = new Date();Date new = DateUtils.addMilliseconds(now, -1); addDays Date now = new Date();DateUtils.addDays(now, 1); ceiling parseDateDate now = new Date();Date parse = DateUtils.parseDate(now, &quot;yyyyMMdd&quot;, &quot;yyyy-MM-dd&quot;);StringUtilsimport org.springframework.util.StringUtils;import org.apache.commons.lang3.StringUtils; springhttps://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/util/StringUtils.html apachehttps://commons.apache.org/proper/commons-lang/apidocs/org/apache/commons/lang3/StringUtils.htmlCollectionUtilsimport org.springframework.util.CollectionUtils;import org.apache.commons.collections4.CollectionUtils; springhttps://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/util/CollectionUtils.html apachehttps://commons.apache.org/proper/commons-collections/apidocs/org/apache/commons/collections4/CollectionUtils.htmlObjectUtilsimport org.springframework.util.ObjectUtils;import org.apache.commons.lang3.ObjectUtils; springhttps://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/util/ObjectUtils.html apachehttps://commons.apache.org/proper/commons-lang/apidocs/org/apache/commons/lang3/ObjectUtils.htmlNumberUtilsimport org.apache.commons.lang3.math.NumberUtils;https://commons.apache.org/proper/commons-lang/apidocs/org/apache/commons/lang3/math/NumberUtils.html" }, { "title": "[Medium] Swapping Nodes in a Linked List", "url": "/posts/algorithm-swapping-nodes-in-a-linked-list/", "categories": "Development, Algorithm", "tags": "algorithm, java, eng, leetcode, recursion", "date": "2023-02-20 17:00:00 +0900", "snippet": "‘Swapping Nodes in a Linked List (Medium)`📌 Problemhttps://leetcode.com/problems/swapping-nodes-in-a-linked-list/📌 Answer/** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode() {} * ListNode(int val) { this.val = val; } * ListNode(int val, ListNode next) { this.val = val; this.next = next; } * } */class Solution { public ListNode swapNodes(ListNode head, int k) { ListNode fast = head; ListNode slow = head; ListNode first = head, second = head; // Put fast (k-1) nodes after slow for (int i = 1; i &amp;lt; k; i++) fast = fast.next; // Save the node for swapping first = fast; // Move until the end of the list while (fast.next != null) { slow = slow.next; fast = fast.next; } // Save the second node for swapping // Note that the pointer second isn&#39;t necessary: we could use slow for swapping as well // However, having second improves readability second = slow; // Swap values int temp = first.val; first.val = second.val; second.val = temp; return head; }} Reference https://leetcode.com/problems/swapping-nodes-in-a-linked-list/solutions/1009918/java-two-pointers-detailed-explanation-o-n-time-o-1-space/?orderBy=most_votes&amp;amp;languageTags=java" }, { "title": "[Development] MSA", "url": "/posts/MSA/", "categories": "Development, Spring", "tags": "eng", "date": "2023-02-14 15:00:00 +0900", "snippet": "Strength 독립적으로 배포 가능하고 개발자의 자율성 증가 장애나는 서비스 격리를 통한 서버 재기동 시간 단축 팀별 코드 이해도 증가 및 유지보수 난이도 저하 Weakness 유지보수 난이도 증가 (통합테스트) API 관리의 중요성 증가 모놀리식보다 더 비싼 비용이 듬 (인프라) MicroService vs Monolithic항상 MSA가 좋은 것만은 아니다.Reference https://wakestand.tistory.com/480 https://lion-king.tistory.com/entry/%EB%A7%88%EC%9D%B4%ED%81%AC%EB%A1%9C-%EC%84%9C%EB%B9%84%EC%8A%A4-vs-%EB%AA%A8%EB%86%80%EB%A6%AC%EC%8B%9D-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98-MicroService-vs-Monolithic-Architecture-%EA%B0%84%EB%8B%A8-%EC%86%8C%EA%B0%9C-%EB%B0%8F-%EC%A3%BC%EA%B4%80%EC%A0%81-%EC%9D%98%EA%B2%AC https://www.samsungsds.com/kr/insights/msa.html" }, { "title": "[Easy] N-th Tribonacci Number", "url": "/posts/algorithm-tribonacci-number/", "categories": "Development, Algorithm", "tags": "algorithm, java, eng, leetcode, recursion", "date": "2023-01-30 17:00:00 +0900", "snippet": "‘N-th Tribonacci Number (Easy)`📌 Problemhttps://leetcode.com/problems/n-th-tribonacci-number/&amp;gt;📌 Answerclass Solution { public int tribonacci(int n) { if (n == 0) return 0; if (n == 1 || n == 2) return 1; int[] Tribonacci = new int[n + 1]; Tribonacci[0] = 0; Tribonacci[1] = 1; Tribonacci[2] = 1; for (int i = 3; i &amp;lt; n + 1; i++) { Tribonacci[i] = Tribonacci[i-1] + Tribonacci[i-2] + Tribonacci[i-3]; } return Tribonacci[n]; }}" }, { "title": "[Medium] All Possible Full Binary Trees", "url": "/posts/algorithm-all-possible-full-binary-trees/", "categories": "Development, Algorithm", "tags": "algorithm, java, eng, leetcode, recursion", "date": "2023-01-30 17:00:00 +0900", "snippet": "‘All Possible Full Binary Trees(Medium)`📌 Problemhttps://leetcode.com/problems/all-possible-full-binary-trees/📌 Answer/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode() {} * TreeNode(int val) { this.val = val; } * TreeNode(int val, TreeNode left, TreeNode right) { * this.val = val; * this.left = left; * this.right = right; * } * } */class Solution { Map&amp;lt;Integer , List&amp;lt;TreeNode&amp;gt;&amp;gt; map = new HashMap&amp;lt;&amp;gt;(); public List&amp;lt;TreeNode&amp;gt; allPossibleFBT(int n) { if (!map.containsKey(n)) { List&amp;lt;TreeNode&amp;gt; res = new ArrayList&amp;lt;&amp;gt;(); if (n == 1) { res.add(new TreeNode(0,null,null)); } else { for (int i = 1 ; i &amp;lt; n ; i += 2) { List&amp;lt;TreeNode&amp;gt; leftSubtree = allPossibleFBT(i); List&amp;lt;TreeNode&amp;gt; rightSubtree = allPossibleFBT(n - i - 1); for (TreeNode left : leftSubtree) { for (TreeNode right : rightSubtree) { res.add(new TreeNode(0,left,right)); } } } } map.put(n , res); } return map.get(n); }} reference https://leetcode.com/problems/all-possible-full-binary-trees/solutions/1556987/simple-java-dfs-memoization-solution/?orderBy=most_votes&amp;amp;languageTags=java " }, { "title": "[Easy] Power of Two", "url": "/posts/algorithm-the-power-of-two/", "categories": "Development, Algorithm", "tags": "algorithm, java, eng, leetcode, recursion", "date": "2023-01-30 15:00:00 +0900", "snippet": "‘Power of Two (Easy)`📌 Problemhttps://leetcode.com/problems/power-of-two/📌 Answerclass Solution { public boolean isPowerOfTwo(int n) { if (n == 1) return true; if (n == 0) return false; if (n % 2 != 0) return false; return isPowerOfTwo(n / 2); }}" }, { "title": "[Easy] Fibonacci Number", "url": "/posts/algorithm-fibonacci-number/", "categories": "Development, Algorithm", "tags": "algorithm, java, eng, leetcode, recursion", "date": "2023-01-30 14:00:00 +0900", "snippet": "‘Fibonacci Number (Easy)`📌 Problemhttps://leetcode.com/problems/fibonacci-number/📌 Answerclass Solution { public int fib(int n) { if (n == 0) return 0; if (n == 1) return 1; return fib(n - 2) + fib(n - 1); }}" }, { "title": "[Medium] Sort List", "url": "/posts/algorithm-sort-list/", "categories": "Development, Algorithm", "tags": "algorithm, java, eng, leetcode", "date": "2023-01-30 10:00:00 +0900", "snippet": "‘Sort List (Medium)`📌 Problemhttps://leetcode.com/problems/sort-list/📌 Answer/** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode() {} * ListNode(int val) { this.val = val; } * ListNode(int val, ListNode next) { this.val = val; this.next = next; } * } */class Solution { public ListNode sortList(ListNode head) { //bottom case if (head == null) { return head; } if (head.next == null) { return head; } //p1 move 1 step every time, p2 move 2 step every time, pre record node before p1 ListNode p1 = head; ListNode p2 = head; ListNode pre = head; while (p2 != null &amp;amp;&amp;amp; p2.next != null) { pre = p1; p1 = p1.next; p2 = p2.next.next; } //change pre next to null, make two sub list(head to pre, p1 to p2) pre.next = null; //handle those two sub list ListNode h1 = sortList(head); ListNode h2 = sortList(p1); return merge(h1, h2); } //merge two sorted list, return result head public ListNode merge(ListNode h1, ListNode h2) { if (h1 == null) { return h2; } if (h2 == null) { return h1; } if (h1.val &amp;lt; h2.val) { h1.next = merge(h1.next, h2); return h1; } else { h2.next = merge(h1, h2.next); return h2; } }} reference https://leetcode.com/problems/sort-list/solutions/46716/basically-it-seems-like-merge-sort-problem-really-easy-understand/?orderBy=most_votes&amp;amp;languageTags=java class Solution { public ListNode sortList(ListNode head) { ListNode temp=head; int count=0; while(temp!=null){ count++; temp=temp.next; } temp=head; int a[]=new int[count]; count=0; while(temp!=null){ a[count++]=temp.val; temp=temp.next; } temp=head; Arrays.sort(a); int k=0; while(temp!=null){ temp.val=a[k++]; temp=temp.next; } return head; }} reference https://leetcode.com/problems/sort-list/solutions/3027781/simple-java-code/?orderBy=most_votes&amp;amp;languageTags=java " }, { "title": "[Medium] Merge Nodes in Between Zeros", "url": "/posts/algorithm-merge-nodes-in-between-zeros/", "categories": "Development, Algorithm", "tags": "algorithm, java, eng, leetcode", "date": "2023-01-30 10:00:00 +0900", "snippet": "‘Merge Nodes in Between Zeros (Medium)`📌 Problemhttps://leetcode.com/problems/merge-nodes-in-between-zeros/📌 Answer/** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode() {} * ListNode(int val) { this.val = val; } * ListNode(int val, ListNode next) { this.val = val; this.next = next; } * } */class Solution { public ListNode mergeNodes(ListNode head) { ListNode result = new ListNode(0); ListNode resultNode = result; int sum = 0; while (head.next != null) { head = head.next; if (head.val != 0) sum += head.val; else { result.val = sum; if (head.next != null) { result.next = new ListNode(0); result = result.next; } sum = 0; } } return resultNode; }}class Solution { public ListNode mergeNodes(ListNode head) { ListNode dummy = new ListNode(Integer.MIN_VALUE), prev = dummy; while (head != null &amp;amp;&amp;amp; head.next != null) { prev.next = head; // prev connects next 0 node. head = head.next; // head forward to a non-zero node. while (head != null &amp;amp;&amp;amp; head.val != 0) { // traverse all non-zero nodes between two zero nodes. prev.next.val += head.val; // add current value to the previous zero node. head = head.next; // forward one step. } prev = prev.next; // prev point to the summation node (initially 0). } prev.next = null; // cut off last 0 node. return dummy.next; }} reference https://leetcode.com/problems/merge-nodes-in-between-zeros/solutions/1784766/java-python-3-one-pass-two-pointers-copy-sum-to-0-nodes/?orderBy=most_votes&amp;amp;languageTags=java " }, { "title": "[Medium] Merge In Between Linked Lists", "url": "/posts/algorithm-merge-in-between-linked-list/", "categories": "Development, Algorithm", "tags": "algorithm, java, eng, leetcode", "date": "2023-01-30 10:00:00 +0900", "snippet": "‘Merge In Between Linked Lists (Medium)`📌 Problemhttps://leetcode.com/problems/merge-in-between-linked-lists/📌 Answer/** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode() {} * ListNode(int val) { this.val = val; } * ListNode(int val, ListNode next) { this.val = val; this.next = next; } * } */class Solution { public ListNode mergeInBetween(ListNode list1, int a, int b, ListNode list2) { ListNode left = list1; for (int i = 1; i &amp;lt; a; i++) left = left.next; ListNode middle = left; for (int i = a; i &amp;lt;= b; i++) middle = middle.next; left.next = list2; while (list2.next != null) list2 = list2.next; list2.next = middle.next; return list1; }} reference https://leetcode.com/problems/merge-in-between-linked-lists/solutions/993116/java-easy-solution-beats-100-time-o-n-space-o-1/?languageTags=java " }, { "title": "[Medium] Maximum Twin Sum of a Linked List", "url": "/posts/algorithm-maximum-twin-sum-of-a-linked-list/", "categories": "Development, Algorithm", "tags": "algorithm, java, eng, leetcode", "date": "2023-01-30 10:00:00 +0900", "snippet": "‘Maximum Twin Sum of a Linked List (Medium)`📌 Problemhttps://leetcode.com/problems/maximum-twin-sum-of-a-linked-list/📌 Answer/** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode() {} * ListNode(int val) { this.val = val; } * ListNode(int val, ListNode next) { this.val = val; this.next = next; } * } */class Solution { public int pairSum(ListNode head) { // check size ListNode checkSize = head; int size = 1; while (checkSize.next != null) { checkSize = checkSize.next; size++; } // put the value of 0 ~ size/2 to stack Stack&amp;lt;Integer&amp;gt; stack = new Stack&amp;lt;&amp;gt;(); for (int i = 0; i &amp;lt; size / 2; i++) { stack.push(head.val); head = head.next; } // make sum pop plus head.val / head = head.next; // compare prev sum with curr sum // - if curr sum is bigger, sum will be changed int sum = 0; while (head != null) { int curr = stack.pop() + head.val; if (sum &amp;lt; curr) sum = curr; head = head.next; } return sum; }}class Solution { public int pairSum(ListNode head) { if (head == null) { return 0; } if (head.next == null) { return head.val; } ListNode slow = head; ListNode fast = head; while (fast != null &amp;amp;&amp;amp; fast.next != null) { slow = slow.next; fast = fast.next.next; } slow = reverse(slow); fast = head; int sum = Integer.MIN_VALUE; while (slow != null) { sum = Math.max(slow.val + fast.val, sum); slow = slow.next; fast = fast.next; } return sum; } public ListNode reverse(ListNode node) { if (node == null) { return null; } ListNode current = node; ListNode previous = null; while (current != null) { ListNode next = current.next; current.next = previous; previous = current; current = next; } return previous; }} reference https://leetcode.com/problems/maximum-twin-sum-of-a-linked-list/solutions/1675791/my-java-solution-using-the-concepts-of-linkedlist/?orderBy=most_votes&amp;amp;languageTags=java " }, { "title": "[Medium] Delete Node in a Linked List", "url": "/posts/algorithm-delete-node-in-a-linked-list/", "categories": "Development, Algorithm", "tags": "algorithm, java, eng, leetcode", "date": "2023-01-30 10:00:00 +0900", "snippet": "‘Delete Node in a Linked List (Medium)`📌 Problemhttps://leetcode.com/problems/delete-node-in-a-linked-list/📌 Answer/** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode(int x) { val = x; } * } */class Solution { // input node will be deleted node public void deleteNode(ListNode node) { ListNode nextNode = node.next; node.val = nextNode.val; node.next = nextNode.next; nextNode.next = null; }} reference https://leetcode.com/problems/delete-node-in-a-linked-list/solutions/2506192/delete-node-in-a-linked-list/?orderBy=most_votes " }, { "title": "[Medium] Rotate List", "url": "/posts/algorithm-rotate-list/", "categories": "Development, Algorithm", "tags": "algorithm, java, eng, leetcode", "date": "2023-01-11 16:00:00 +0900", "snippet": "‘Rotate List (Medium)’📌 Problemhttps://leetcode.com/problems/rotate-list/📌 Answer/** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode() {} * ListNode(int val) { this.val = val; } * ListNode(int val, ListNode next) { this.val = val; this.next = next; } * } */class Solution { public ListNode rotateRight(ListNode head, int k) { if (head == null || head.next == null) return head; ListNode dummy = new ListNode(0); dummy.next = head; ListNode fast = dummy, slow = dummy; int len; // Get the total length of the list for (len = 0; fast.next != null; len++) { fast = fast.next; } // Get the (len - k%len)th node for (int j = len - (k % len); j &amp;gt; 0; j--) { slow = slow.next; } // Do the rotation fast.next = dummy.next; dummy.next = slow.next; slow.next = null; return dummy.next; }} Reference https://leetcode.com/problems/rotate-list/solutions/22715/share-my-java-solution-with-explanation/?orderBy=most_votes&amp;amp;languageTags=java " }, { "title": "[Medium] Swap Nodes in Pairs", "url": "/posts/algorithm-swap-nodes-in-pairs/", "categories": "Development, Algorithm", "tags": "algorithm, java, eng, leetcode", "date": "2023-01-11 14:00:00 +0900", "snippet": "‘Swap Nodes in Pairs (Medium)📌 Problemhttps://leetcode.com/problems/swap-nodes-in-pairs/📌 Answer Iterative```java/** Definition for singly-linked list. public class ListNode { int val; ListNode next; ListNode() {} ListNode(int val) { this.val = val; } ListNode(int val, ListNode next) { this.val = val; this.next = next; } } */class Solution { public ListNode swapPairs(ListNode head) { ListNode temp = head; while (head != null &amp;amp;&amp;amp; head.next != null) { int curr = head.val; int next = head.next.val; head.next.val = curr; head.val = next; head = head.next.next; } return temp; } } ``` Recursive class Solution { public ListNode swapPairs(ListNode head) { if (head == null || head.next == null) return head; ListNode nxt = head.next; head.next = swapPairs(nxt.next); nxt.next = head; return nxt; }} Reference https://leetcode.com/problems/swap-nodes-in-pairs/solutions/11204/java-recursive-and-iterative-solutions/?orderBy=most_votes&amp;amp;languageTags=java " }, { "title": "[Medium] Remove Duplicates from Sorted List II", "url": "/posts/algorithm-remove-duplicates-from-sorted-list-2/", "categories": "Development, Algorithm", "tags": "algorithm, java, eng, leetcode", "date": "2023-01-11 14:00:00 +0900", "snippet": "‘Remove Duplicates from Sorted List II (Medium)’📌 Problemhttps://leetcode.com/problems/remove-duplicates-from-sorted-list-ii/📌 Answerclass Solution { public ListNode deleteDuplicates(ListNode head) { // sentinel ListNode sentinel = new ListNode(0, head); // predecessor = the last node // before the sublist of duplicates ListNode pred = sentinel; while (head != null) { // if it&#39;s a beginning of duplicates sublist // skip all duplicates if (head.next != null &amp;amp;&amp;amp; head.val == head.next.val) { // move till the end of duplicates sublist while (head.next != null &amp;amp;&amp;amp; head.val == head.next.val) { head = head.next; } // skip all duplicates pred.next = head.next; // otherwise, move predecessor } else { pred = pred.next; } // move forward head = head.next; } return sentinel.next; }} Reference https://leetcode.com/problems/remove-duplicates-from-sorted-list-ii/solutions/952302/remove-duplicates-from-sorted-list-ii/?orderBy=most_votes " }, { "title": "[Easy] Convert Binary Number in a Linked List to Integer", "url": "/posts/algorithm-convert-binary-number-in-a-linked-list-to-integer/", "categories": "Development, Algorithm", "tags": "algorithm, java, eng, leetcode", "date": "2023-01-11 13:30:00 +0900", "snippet": "‘Convert Binary Number in a Linked List to Integer (Easy)📌 Problemhttps://leetcode.com/problems/convert-binary-number-in-a-linked-list-to-integer/📌 Answer/** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode() {} * ListNode(int val) { this.val = val; } * ListNode(int val, ListNode next) { this.val = val; this.next = next; } * } */class Solution { public int getDecimalValue(ListNode head) { int num = head.val; while (head.next != null) { num = num * 2 + head.next.val; head = head.next; } return num; }} Reference https://leetcode.com/problems/convert-binary-number-in-a-linked-list-to-integer/solutions/851040/convert-binary-number-in-a-linked-list-to-integer/?orderBy=most_votes " }, { "title": "[Easy] Middle of the Linked List", "url": "/posts/algorithm-middle-of-the-linked-list/", "categories": "Development, Algorithm", "tags": "algorithm, java, eng, leetcode", "date": "2023-01-10 18:30:00 +0900", "snippet": "‘Middle of the Linked List’ in LeetCode (Easy)📌 Problemhttps://leetcode.com/problems/middle-of-the-linked-list/📌 AnswerWhen traversing the list with a pointer slow, make another pointer fast that traverses twice as fast. When fast reaches the end of the list, slow must be in the middle./** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode() {} * ListNode(int val) { this.val = val; } * ListNode(int val, ListNode next) { this.val = val; this.next = next; } * } */class Solution { public ListNode middleNode(ListNode head) { ListNode slow = head, fast = head; while (fast != null &amp;amp;&amp;amp; fast.next != null) { slow = slow.next; fast = fast.next.next; } return slow; }} Reference https://leetcode.com/problems/middle-of-the-linked-list/solutions/154715/middle-of-the-linked-list/?orderBy=most_votes " }, { "title": "[Easy] Remove Duplicates from Sorted List", "url": "/posts/algorithm-remove-duplicates-from-sorted-list/", "categories": "Development, Algorithm", "tags": "algorithm, java, eng, leetcode", "date": "2023-01-10 17:30:00 +0900", "snippet": "‘Remove Duplicates from Sorted List’ in LeetCode (Easy)📌 Problemhttps://leetcode.com/problems/remove-duplicates-from-sorted-list/📌 Answer/** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode() {} * ListNode(int val) { this.val = val; } * ListNode(int val, ListNode next) { this.val = val; this.next = next; } * } */class Solution { public ListNode deleteDuplicates(ListNode head) { ListNode curr = head; while (curr != null &amp;amp;&amp;amp; curr.next != null) { if (curr.val == curr.next.val) curr.next = curr.next.next; else curr = curr.next; } return head; }}" }, { "title": "[Easy] Intersection of Two Linked Lists", "url": "/posts/algorithm-intersection-of-two-linked-lists/", "categories": "Development, Algorithm", "tags": "algorithm, java, eng, leetcode", "date": "2023-01-10 17:30:00 +0900", "snippet": "‘Intersection of Two Linked Lists’ in LeetCode (Easy)📌 Problemhttps://leetcode.com/problems/intersection-of-two-linked-lists/📌 Answer/** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode(int x) { * val = x; * next = null; * } * } */public class Solution { public ListNode getIntersectionNode(ListNode headA, ListNode headB) { ListNode p1 = headA, p2 = headB; int len1 = 0, len2 = 0; while (p1 != null) { p1 = p1.next; len1++; } while (p2 != null) { p2 = p2.next; len2++; } p1 = headA; p2 = headB; if (len1 &amp;gt; len2) { for (int i = 0; i &amp;lt; len1 - len2; i++) { p1 = p1.next; } } else { for (int i = 0; i &amp;lt; len2 - len1; i++) { p2 = p2.next; } } while (p1 != p2) { // System.out.println(&quot;p1 : &quot; + p1.val); // System.out.println(&quot;p2 : &quot; + p2.val); // System.out.println(); p1 = p1.next; p2 = p2.next; } return p1; }} Reference https://leetcode.com/problems/intersection-of-two-linked-lists/solutions/49902/java-beats-99-56/?orderBy=most_votes&amp;amp;languageTags=java " }, { "title": "[Easy] Remove Linked List Elements", "url": "/posts/algorithm-remove-linked-list-elements/", "categories": "Development, Algorithm", "tags": "algorithm, java, eng, leetcode", "date": "2023-01-10 16:00:00 +0900", "snippet": "‘Remove Linked List Elements’ in LeetCode (Easy)📌 Problemhttps://leetcode.com/problems/remove-linked-list-elements/📌 Answer/** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode() {} * ListNode(int val) { this.val = val; } * ListNode(int val, ListNode next) { this.val = val; this.next = next; } * } */public class Solution { public ListNode removeElements(ListNode head, int val) { while (head != null &amp;amp;&amp;amp; head.val == val) head = head.next; ListNode curr = head; while (curr != null &amp;amp;&amp;amp; curr.next != null) { // System.out.println(&quot;curr before : &quot; + curr.val); if (curr.next.val == val) curr.next = curr.next.next; // remove next else curr = curr.next; // go next // System.out.println(&quot;curr after : &quot; + curr.val); // System.out.println(); } return head; }}/**Input: head = [1,2,6,3,4,5,6], val = 6Output: [1,2,3,4,5]Stdoutcurr before : 1curr after : 2curr before : 2curr after : 2curr before : 2curr after : 3curr before : 3curr after : 4curr before : 4curr after : 5curr before : 5curr after : 5**/class Solution { public ListNode removeElements(ListNode head, int val) { if (head == null) return null; head.next = removeElements(head.next, val); return head.val == val ? head.next : head; }} Reference https://leetcode.com/problems/remove-linked-list-elements/solutions/57323/iterative-short-java-solution/?orderBy=most_votes&amp;amp;languageTags=java https://leetcode.com/problems/remove-linked-list-elements/solutions/57306/3-line-recursive-solution/?orderBy=most_votes&amp;amp;languageTags=java " }, { "title": "[Easy] Reverse Linked List", "url": "/posts/algorithm-reverse-linked-list/", "categories": "Development, Algorithm", "tags": "algorithm, java, eng, leetcode", "date": "2023-01-10 15:30:00 +0900", "snippet": "‘Reverse Linked List’ in LeetCode (Easy)📌 Problemhttps://leetcode.com/problems/reverse-linked-list/📌 Answer/** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode() {} * ListNode(int val) { this.val = val; } * ListNode(int val, ListNode next) { this.val = val; this.next = next; } * } */class Solution { public ListNode reverseList(ListNode head) { if (head == null || head.next == null) return head; ListNode curr = head; ListNode prev = null; ListNode next; while (curr != null) { next = curr.next; curr.next = prev; prev = curr; curr = next; } return prev; }} Reference https://leetcode.com/problems/reverse-linked-list/solutions/1866153/java-2-solutons-in-place-operation-beats-100-and-create-a-new-linked-list-beats-100/?orderBy=most_votes&amp;amp;languageTags=java " }, { "title": "[Easy] Linked List Cycle", "url": "/posts/algorithm-linked-list-cycle/", "categories": "Development, Algorithm", "tags": "algorithm, java, eng, leetcode", "date": "2023-01-10 13:00:00 +0900", "snippet": "‘Linked List Cycle’ in LeetCode (Easy)📌 Problemhttps://leetcode.com/problems/linked-list-cycle/📌 Answer/** * Definition for singly-linked list. * class ListNode { * int val; * ListNode next; * ListNode(int x) { * val = x; * next = null; * } * } */public class Solution { public boolean hasCycle(ListNode head) { if (head == null || head.next == null) return false; Set&amp;lt;ListNode&amp;gt; set = new HashSet&amp;lt;&amp;gt;(); while (head != null) { if (set.contains(head)) return true; set.add(head); head = head.next; } return false; }} Reference https://leetcode.com/problems/linked-list-cycle/solutions/44614/java-11ms-solution-with-hashset-and-1ms-solution-without-extra-space/?orderBy=most_votes&amp;amp;languageTags=java https://leetcode.com/problems/reverse-linked-list/solutions/1866153/java-2-solutons-in-place-operation-beats-100-and-create-a-new-linked-list-beats-100/?orderBy=most_votes&amp;amp;languageTags=java " }, { "title": "[Data Sturcture] LinkedList (vs ArrayList)", "url": "/posts/linked-list/", "categories": "Development, Algorithm", "tags": "algorithm, java, eng, leetcode", "date": "2023-01-09 17:00:00 +0900", "snippet": "LinkedList Method List Often using [*First] methods addFirst peekFirst pollFirst removeFirst // if you want to make the reverse order list, use addFirst()LinkedList&amp;lt;Integer&amp;gt; list = new LinkedList&amp;lt;&amp;gt;();list.addFirst(1);list.addFirst(2);list.addFirst(3);// list -&amp;gt; [3, 2, 1]ArrayList VS LinkedList Manipulation with LinkedList is faster than ArrayList Reference https://www.javatpoint.com/difference-between-arraylist-and-linkedlist " }, { "title": "[Easy] Panlindrome Linked List", "url": "/posts/algorithm-palindrome-linked-list/", "categories": "Development, Algorithm", "tags": "algorithm, java, eng, leetcode", "date": "2023-01-09 16:00:00 +0900", "snippet": "‘Panlindrome Linked List’ in LeetCode (Easy)📌 Problemhttps://leetcode.com/problems/palindrome-linked-list/📌 Answer/** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode() {} * ListNode(int val) { this.val = val; } * ListNode(int val, ListNode next) { this.val = val; this.next = next; } * } */class Solution { public boolean isPalindrome(ListNode head) { // 1. Copying the Linked List into an Array. List&amp;lt;Integer&amp;gt; vals = new ArrayList&amp;lt;&amp;gt;(); ListNode currentNode = head; while (currentNode != null) { vals.add(currentNode.val); currentNode = currentNode.next; } // 2. Checking whether or not the Array is a palindrome. int front = 0; int back = vals.size() - 1; while (front &amp;lt; back) { if (!vals.get(front).equals(vals.get(back))) { return false; } front++; back--; } return true; }} Reference https://leetcode.com/problems/palindrome-linked-list/solutions/433547/official-solution/ " }, { "title": "[Data Sturcture] Tree Traversal (preorder, inorder, postorder)", "url": "/posts/algorithm-traversal/", "categories": "Development, Algorithm", "tags": "algorithm, java, eng, leetcode", "date": "2023-01-09 14:00:00 +0900", "snippet": "Tree Traversal preorder traversal A -&amp;gt; B -&amp;gt; D -&amp;gt; H -&amp;gt; I -&amp;gt; E -&amp;gt; C -&amp;gt; F -&amp;gt; G inorder traversal H -&amp;gt; D -&amp;gt; I -&amp;gt; B -&amp;gt; E -&amp;gt; A -&amp;gt; F -&amp;gt; C -&amp;gt; G postorder traversal H -&amp;gt; I -&amp;gt; D -&amp;gt; E -&amp;gt; B -&amp;gt; F -&amp;gt; G -&amp;gt; C -&amp;gt; A Reference «https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&amp;amp;blogId=4717010&amp;amp;logNo=60209908735&amp;gt; Example : preorder traversalProblemhttps://leetcode.com/problems/binary-tree-preorder-traversal/ResultInput: root = [1,null,2,3]Output: [1,2,3]Answer/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode() {} * TreeNode(int val) { this.val = val; } * TreeNode(int val, TreeNode left, TreeNode right) { * this.val = val; * this.left = left; * this.right = right; * } * } */class Solution { public List&amp;lt;Integer&amp;gt; preorderTraversal(TreeNode root) { List&amp;lt;Integer&amp;gt; result = new ArrayList&amp;lt;Integer&amp;gt;(); if (root == null) return result; Stack&amp;lt;TreeNode&amp;gt; stack = new Stack&amp;lt;TreeNode&amp;gt;(); stack.push(root); while (!stack.isEmpty()) { TreeNode node = stack.pop(); result.add(node.val); if (node.right != null) stack.push(node.right); if (node.left != null) stack.push(node.left); } return result; }} Reference https://leetcode.com/problems/binary-tree-preorder-traversal/solutions/45417/preorder-traversal-java-solution-both-iteration-and-recursion/?orderBy=most_votes&amp;amp;languageTags=java Example : postorder traversalProblemhttps://leetcode.com/problems/binary-tree-postorder-traversal/ResultInput: root = [1,null,2,3]Output: [3,2,1]Answer/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode() {} * TreeNode(int val) { this.val = val; } * TreeNode(int val, TreeNode left, TreeNode right) { * this.val = val; * this.left = left; * this.right = right; * } * } */class Solution { public List&amp;lt;Integer&amp;gt; postorderTraversal(TreeNode root) { LinkedList&amp;lt;Integer&amp;gt; result = new LinkedList&amp;lt;&amp;gt;(); if (root == null) return result; Stack&amp;lt;TreeNode&amp;gt; stack = new Stack&amp;lt;&amp;gt;(); stack.push(root); while (!stack.isEmpty()) { TreeNode node = stack.pop(); result.addFirst(node.val); // difference if (node.left != null) stack.push(node.left); // difference if (node.right != null) stack.push(node.right); // difference } return result; }} Reference :https://leetcode.com/problems/binary-tree-postorder-traversal/solutions/45556/java-simple-and-clean/?orderBy=most_votes&amp;amp;languageTags=java" }, { "title": "[Development] API vs Endpoint", "url": "/posts/API-VS-Endpoint/", "categories": "Development, Spring", "tags": "eng", "date": "2022-11-14 15:00:00 +0900", "snippet": "API vs EndpointAPI (An application programming interface) a set of protocol and tools that allow two applications to communicate 두 시스템(어플리케이션)이 상호작용(소통) 할 수 있게 하는 프로토콜의 총 집합 Often, each REST API offers multiple endpoints from which you can get the data.Endpoint a URL that enables the API to access resources on a server API가 서버에서 리소스에 접근할 수 있도록 가능하게 하는 URL the locations of the resources [Reference] https://site.financialmodelingprep.com/education/api-endpoint https://blog.naver.com/ghdalswl77/222401162545" }, { "title": "[Development] Exception In Java", "url": "/posts/Exception/", "categories": "Development, Spring", "tags": "eng", "date": "2022-10-12 17:00:00 +0900", "snippet": "Exception in JavaChecked Exception vs Unchecked Exception   Checked Exception Unchecked Exception When checked checked at compile time. not checked at compile time, it occurs at runtime. Handling exception A checked must be handled either by re-throwing or with a try-catch block whereas an unchecked isn’t required to be handled. Checked Exception These are the exceptions that are checked at compile time. If some code within a method throws a checked exception, then the method must either handle the exception or it must specify the exception using the throws keyword.A fully checked exception A fully checked exception is a checked exception where all its child classes are also checked, like IOException, InterruptedException.A partially checked exception A partially checked exception is a checked exception where some of its child classes are unchecked, like Exception.Unchecked Exception These are the exceptions that are not checked at compile time. It is not forced by the compiler to either handle or specify the exception. It is up to the programmers to be civilized, and specify or catch the exceptions.[Reference] https://facingissuesonit.com/java-exception-handling/ https://www.geeksforgeeks.org/checked-vs-unchecked-exceptions-in-java/ https://www.theserverside.com/answer/What-are-checked-vs-unchecked-exceptions-in-Java " }, { "title": "[Development] Elasticsearch", "url": "/posts/Elastic-search/", "categories": "Development, Elasticsearch", "tags": "eng", "date": "2022-09-27 14:00:00 +0900", "snippet": "ArchitectureElasticsearch FlowSmall-sized SolutionELK StackElasticsearch / Lucene Lucene Elasticsearch is an open-source search engine built on top of Apache Lucene, as the rest of the ELK Stack, including Logstash and Kibana. Componenets Index An index consists of one or more Documents Shard, Replicas 2개 유형으로 구분 가능 Document Document consists of one or more Fields Cluster ES내 가장 큰 시스템 단위 서로 다른 cluster는 데이터의 접근, 교환을 할 수 없는 독립적인 시스템 여러 대의 server가 하나의 cluster를 구성 가능 / 한 서버에 여러 cluster가 존재할 수 있음 Node ES를 구성하는 하나의 단위 프로세스 (데이터를 저장하고 indexing을 하는 등의 ES Instance) Shards split up indices horizontally into pieces called shards index를 여러 shard로 쪼갬 for scaling out in ES Sharding : 데이터를 분산해서 저장하는 방법 Replica One or More copy of index 또 다른 형태의 shard node를 손실했을 경우의 데이터의 신뢰성을 위해 shard를 복제 권장사항 : replica는 서로 다른 노드에 존재할 것 Inverted index Elasticsearch uses a data structure called an inverted index that supports very fast full-text searches. An inverted index lists every unique word that appears in any document and identifies all of the documents each word occurs in.ExampleSource ExampleBlog.java@Entity ES 7.0.0 부터는 Type 이 deprecated 되어 indexName만 설정가능@Setter@Document(indexName = &quot;blog&quot;)public class Blog { @Id @Field(type = FieldType.Long) private String id; @Field(type = FieldType.Text) private String title; @Field(type = FieldType.Text) private String content; @Field(type = FieldType.Date) private Date log_date; @Field(type = FieldType.Text) private String log_text; @Field(type = FieldType.Long) private Long price;}BlogEsRepository.java@Repositorypublic interface BlogEsRepository extends ElasticsearchRepository&amp;lt;Blog, String&amp;gt; {}BlogEsService.java@Servicepublic class BlogEsService { @Autowired private ElasticsearchOperations operations; @Autowired private RestHighLevelClient client; public serviceMethod() { // BoolQueryBuilder // NativeSearchQueryBuilder // SearchHits // PageRequest // SearchRequest // SearchResponse // ... // Reference : Classes }}Test@ResourceBlogEsRepository blogEsRepository;@Testvoid test(){ Blog blog = new Blog(); blog.setId(&quot;1&quot;); blog.setContent(&quot;내용입니다.&quot;); blog.setTitle(&quot;제목입니다.&quot;); blogEsRepository.save(blog);}bulid.gradledependencies { implementation &#39;org.springframework.boot:spring-boot-starter-data-elasticsearch&#39;}application.ymlelasticsearch: host: localhost port: 9200Classes SearchRequest SearchResponse SearchSourceBuilder SearchHits Document @Document(indexName = “noresults_#{indexNames.getYMD()}”, createIndex = false) RequestOptions NativeSearchQueryBuilder QueryBuilders termsQuery boolQuery matchAllQuery wildcardQuery prefixQuery SortBuilders fieldSort IndexQueryBuilder ElasticsearchOperations search getIndexCoordinatesFor bulkUpdate RestHighLevelClient IndexCoordinatesSearch API : response[Reference]https://esbook.kimjmin.net/https://bgpark.tistory.com/158https://velog.io/@sunghwancode/TIL-%EA%B2%80%EC%83%89-%EC%8B%9C%EC%8A%A4%ED%85%9C-Elastic-Search-Redis SpringBoot ElasticSearch using Spring Data Java Techie https://www.youtube.com/watch?v=dlChXjE7IHw https://yeminyi.github.io/myblog/elk/2020/10/22/what-is-elk.htmlhttps://victorydntmd.tistory.com/308https://idea-sketch.tistory.com/59https://esbook.kimjmin.net/06-text-analysis/6.1-indexing-datahttps://engineering.mercari.com/en/blog/entry/20220311-operational-tips-on-using-elasticsearch/https://juntcom.tistory.com/137https://victorydntmd.tistory.com/313" }, { "title": "[Development] Docker", "url": "/posts/Docker/", "categories": "Development, Docker", "tags": "eng", "date": "2022-09-21 14:00:00 +0900", "snippet": "The Benefits With Docker, you can manage your infrastructure in the same ways you manage your applications. 서버마다, 개발자들이 사용하는 PC 마다 설치와 설정을 다르게 해야하는 번거로움을 해결해줌 The Features Docker provides the ability to package and run an application in a loosely isolated environment called a container Containers are great for continuous integration and continuous delivery (CI/CD) workflows The isolation and security allows you to run many containers simultaneously on a given host. Containers are lightweight and contain everything needed to run the application, so you do not need to rely on what is currently installed on the host. reference : https://docs.docker.com/get-started/overview/Docker Architecture Docker uses a client-server architectureDocker Container Orchestraction : Docker swarm vs KubernetesDocker SwarmArchitecture A group of either physical or virtual machines that are running the Docker application and that have been configured to join together in a cluster. The activities of the cluster are controlled by a swarm manager, and machines that have joined the cluster are referred to as nodes. The key components of a Docker Swarm are Docker Nodes, Docker Services, and Docker Tasks.Kuberneteshttps://uzzing.github.io/posts/Kubernetes/Docker Image &amp;amp; ContainerCLI[Reference]https://docs.docker.com/engine/reference/commandline/docker/ build / container / create / events / exec / image / images / inspect / kill / login / logout / network / ps / pull / push / rename / restart / rm / rmi / run / search / start / stop / swarm / system / tag / update / version / volume …Example docker –version docker pull [IMAGE] ex) docker pull nginx docker images ls docker run -d -p [PORT:hostmap] [IMAGE] ex) docker run -d -p 8080:80 nginx:latest -&amp;gt; localhost:8080 ex) docker run -d -p 8080:80 -p 3000:80 nginx:latest -&amp;gt; localhost:8080, localhost:3000 ex) docker run –name websitename -d -p 8080:80 -p 3000:80 nginx:latest -&amp;gt; NAMES : websitename ex) docker run –name website -v $(pwd):/usr/share/nginx/html:ro -d -p 8080:80 -p 3000:80 nginx ro : read only ex) docker run –name website-copy –volumes-from website -d -p 8081:80 -p nginx ex) docker run –name website -p 8080:80 -d website:latest docker ps (= docker container ls) docker stop [CONTAINER ID] (= [NAMES]) ex) docker stop 662e3476d306 ex) docker stop vigorous_mestorf docker rm $(docker ps -aq) docker rm -f $(docker ps -aq) docker rmi -f $(docker ps -aq) docker exec -it website bashBuild imagesARG vs ENV Write Dockerfile, .dockerignore -&amp;gt; build -&amp;gt; runDockerfile DockerFile : 로컬환경 자원을 사용해 빌드한 파일을 인스턴스에 넘겨줌 DockerFile-with-build : 인스턴스 내부의 자원을 사용해 빌드 -&amp;gt; 시간이 비약적으로 증가함 OPTION FROM : 생성할 이미지의 base image COPY : 로컬의 파일을 이미지에 복사 EXPOSE : 노출할 포트 지정 ENTRYPOINT : 컨테이너가 시작될 때 수행할 명령어를 지정 example FROM openjdk:11-jdk-slim-busterCOPY build/libs/login-service.jar app.jarEXPOSE 8080ENTRYPOINT [&quot;java&quot;, &quot;-jar&quot;, &quot;/app.jar&quot;] FROM nginxCOPY nginx.conf /etc/nginx/nginx.conf FROM nginx:alpineADD . /usr/share/nginx/html FROM node:latestWORKDIR /appADD package*.json ./RUN npm installADD . . -&amp;gt; first . : all the files in the folder, second . : to /app folderCMD node index.js .dockerignore ignore files, folders example node_modulesDockerfile.git*.gulp.js folder/** docker build Build an image from a Dockerfile example docker build –tag website:latest . docker build -t user-service-api:latest . docker run Run a command in a new container example docker run –name user-api -d -p 3000:3000 user-service-api:latest VolumesVersioning docker tag Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE docker tag SOURCE_IMAGE[:TAG] TARGET_IMAGE[:TAG] example docker tag amigoscode-website:latest amigoscode-website:1 docker tag amigoscode-website:latest amigoscode-website:2 Example docker pull nginx:alpine docker pull node:alpinenginx.confevents {}http { upstream app { server 172.17.0.1:8080; } server { listen 80; location / { proxy_pass http://app; } }} docker build -t user-service-api:latest docker build -t website:latest Docker Registry A Docker registry stores Docker images.CI/CD : Docker + JenkinsNginxa web server that can also be used as a reverse proxy, load balancer, mail proxy and HTTP cache. HTTP Web Server Reverse Proxy Server for load balancer maximum performance and stability. Nginx uses an asynchronous event-driven approach, rather than threads, to handle requests. it provide predictable performance under high loads. (concurrency, high performance and low memory usage) Nginx is easy to configure in order to serve static web content or to act as a proxy serverNginx in DockerNGINX is the native load balancer in Docker EE.NGINX is the most widely deployed Ingress controller for Kubernetes.Whether you choose Docker Swarm or Kubernetes, NGINX is the best choice for scaling container orchestration traffic.[Reference]https://subicura.com/2017/01/19/docker-guide-for-beginners-2.html Docker and Kubernetes Tutorial Full Course [2021] https://youtu.be/bhBSlnQcq2k " }, { "title": "[Development] Kubernetes", "url": "/posts/Kubernetes/", "categories": "Development, Kubernetes", "tags": "eng", "date": "2022-09-20 14:00:00 +0900", "snippet": "Kubernetest + DockerArchitecture / ComponentsCluster The control plane schedules Pods to run, routes traffic, and handles everything else happening inside a cluster. Everything inside Kubernetes is running in a cluster, everything managed via kubectl will always be the same, and that things may change externally depending on how your cluster is deployed. https://www.containiq.com/post/kubernetes-clusterNodeMaster Node (Control Plane Node) + Worker NodeMaster Node (Control Plane Node)API Server The central component in a Kubernetes cluster. It’s responsible for handling internal and external traffic. Kube-apiserver is the only component that connects with the etcd database and works as a master component and the frontend of the cluster’s shared state. It’s mainly responsible for handling the API calls that normally handle authentication, authorization, and admission controls. https://kubernetes.io/docs/reference/command-line-tools-reference/kube-apiserver/Scheduler It first checks for the availability of the resources in nodes, and based on the type of request, it assigns one that’s available. Worker node will host the pod using different scheduling algorithms. Scheduling decisions are based on resource availability and other factors like hardware, software, workload, and policy constraints. In the case that a node is not suitable for the current pod, the pod will remain unscheduled until there is a node available.https://kubernetes.io/docs/reference/command-line-tools-reference/kube-scheduler/Controller-ManagerKube-controller-manager It constantly interacts with the kube-apiserver to determine the state of the cluster. If the state is not matched, the manager contacts the necessary controller to match the desired state.Cloud-controller-manager It is similar to kube-controller-manager, except that it interacts with the cloud-specific APIs. As Kubernetes continues to advance, it also handles some of the controller tasks that had been previously handled by the kube-controller-manager. https://kubernetes.io/docs/reference/command-line-tools-reference/kube-controller-manager/Etcd database It stores information in the form of key-value pairs such as storing cluster state, networking information, and other persistent information. Update : When an update is needed, it doesn’t overwrite the pairs; rather, it creates a new entry and appends the end, and marks the previous entry for future removal. It works with most HTTP libraries and curl. Worker Node The worker nodes are where the actual application is deployed. A node is simply a physical or a virtual machine, depending on the type of cluster you have in your Kubernetes environment. To containerize your application, you need to put the containers in pods that run on different nodes. Each node is managed by the kube-apiserver, and scheduling happens via the kube-scheduler, which means each node is under the control of the control plane. https://kubernetes.io/docs/concepts/architecture/nodes/Pod A Pod is similar to a set of containers with shared namespaces and shared filesystem volumes. Within a Pod’s context, the individual applications may have further sub-isolations applied. Pods are the smallest deployable units of computing that you can create and manage in Kubernetes. Every Pod in a cluster gets its own unique cluster-wide IP address. This means you do not need to explicitly create links between Pods and you almost never need to deal with mapping container ports to host ports. Kubernetes IP addresses exist at the Pod scope - containers within a Pod share their network namespaces - including their IP address and MAC address. https://kubernetes.io/docs/concepts/workloads/pods/Kubelet Kubelet is the part of every worker node that makes sure the containers that need to run are currently running. It receives the pod specification as an API call and works to configure the worker node until the specifications are met. The most important part is that a kubelet does not manage any container that is not created by Kubernetes.https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet/Kube-proxy It manage the network requirements of the node by maintaining an iptable. Communication within or outside the cluster is enabled by Kube-proxy. Kube-proxy uses an operating system packet filtering layer if one exists and is currently available. Otherwise, kube-proxy itself forwards the traffic. Features Kubernetes expects all communication to the API server to be done over HTTPS. You enable service account tokens and at least one other authentication method. Such an authentication method could be Basic Auth or X509 certs. Network ModelKubernetes imposes the following fundamental requirements on any networking implementation (barring any intentional network segmentation policies): pods can communicate with all other pods on any other node without NAT agents on a node (e.g. system daemons, kubelet) can communicate with all pods on that nodeManagements The most popular managed Kubernetes services. Google Kubernetes Engine (GKE), by Google Amazon Elastic Kubernetes Service (EKS), by Amazon Azure Kubernetes Service (AKS), by Microsoft Cheet Sheethttps://kubernetes.io/docs/reference/kubectl/cheatsheet/[Reference]https://kubernetes.io/docs/concepts/overview/components/https://www.containiq.com/post/kubernetes-componentshttps://medium.com/devops-mojo/kubernetes-architecture-overview-introduction-to-k8s-architecture-and-understanding-k8s-cluster-components-90e11eb34ccd" }, { "title": "[Development] Transaction (@Transactional / JPA)", "url": "/posts/Transaction/", "categories": "Development, Spring", "tags": "eng", "date": "2022-09-02 15:00:00 +0900", "snippet": "Spring @Transactional Option Isolation Level Propagation no-rollback for Step transaction in Tasklet (job) of Spring batchSpring JPA Persistence Context @OneToMany, @ManyToMany, @ManyToOne, @OneToOne Option FetchType CascadeType orphanRemoval @Embeddable, @Embedded LockModeType Spring @TransactionalIsolation Level Default READ_UNCOMMITTED can read uncommited datas. allows dirty read (it can occur bad data consistency) prevents nothing. READ_UNCOMMITTED setting is the fastest. READ_COMMITTED (often used) can read committed datas. allows non-repeatable read prevents just one, Dirty reads REPEATABLE_READ allows phantom read (= repeatable read) prevents two anomalies: Dirty reads, Non-repeatable reads SERIALIZABLE prevents all three anomalies: Dirty reads, Non-repeatable reads and Phantom reads makes transactions very slow (weak) Read Uncommited &amp;lt; Read Committed &amp;lt; Repeatable Read &amp;lt; Serializable (strong) if you want to use more high isolation level, use LockModeTypeDirty Read VS Phantom Read VS Non-repeatable Read Dirty Read Phantom Read (= repeatable read) Non-repeatable Read read UNCOMMITED data from another transaction. read COMMITTED data from an UPDATE query from another transaction. read COMMITTED data from an INSERT or DELETE query from another transaction. Dirty Checking JPA에서는 Entity를 조회하면 해당 Entity의 조회 상태 그대로를 Snapshot을 만들어 놓음 트랜잭션이 끝나는 시점에 해당 Snapshot과 비교해 다른 점이 있다면 Update Query를 DB에 전달함reference : https://jojoldu.tistory.com/415Propagation@Transactional(propagation = Propagation.REQUIRES_NEW)@Transactional(propagation = Propagation.NEVER)if any component or service will or will not participate in transaction and how will it behave if the calling component/service already has or does not have a transaction created already. REQUIRED (default) Support a current transaction; create a new one if none exists. 부모 트랜잭션 내에서 실행하며 부모 트랜잭션이 없을 경우 새로운 트랜잭션을 생성 SUPPORTS Support a current transaction; execute non-transactionally if none exists. 부모 트랜잭션 내에서 실행하며 부모 트랜잭션이 없을 경우 nontransactionally로 실행 MANDATORY Support a current transaction; throw an exception if no current transaction exists. 부모 트랜잭션 내에서 실행되며 부모 트랜잭션이 없을 경우 예외가 발생 REQUIRES_NEW Create a new transaction, suspending the current transaction if one exists. 부모 트랜잭션을 무시하고 무조건 새로운 트랜잭션이 생성 NOT_SUPPORTED Do not support a current transaction; rather always execute non-transactionally. nontransactionally로 실행하며 부모 트랜잭션 내에서 실행될 경우 일시 정지 NEVER Do not support a current transaction; throw an exception if a current transaction exists. nontransactionally로 실행되며 부모 트랜잭션이 존재한다면 예외가 발생 NESTED Execute within a nested transaction if a current transaction exists, behave like PROPAGATION_REQUIRED otherwise. 둘러싼 트랜잭션이 없을 경우 REQUIRED와 동일하게 작동. 해당 메서드가 부모 트랜잭션에서 진행될 경우 별개로 커밋되거나 롤백될 수 있음. reference : https://jsonobject.tistory.com/467no-rollback for@Transactional(noRollbackFor = RuntimeException.class) 특정 예외가 발생하더라도 롤백되지 않도록 설정Read only@Transactional(readOnly = true) Entity를 read only로 조회하면, 변경 감지를 위한 snapshot을 유지하지 않아도 되고, 영속성 컨텍스트를 flush하지 않아도 되 성능을 향상 시킬 수 있음. other way : scala type in query select o.id, o.name from Order o Spring JPAPersistence Contextthe first-level cache where all the entities are fetched from the database or saved to the database. Persistence context keeps track of any changes made into a managed entity. If anything changes during a transaction, then the entity is marked as dirty. When the transaction completes, these changes are flushed into persistent storage. An EntityManager is associated with a persistence context. It sits between our application and persistent storage. PersistenceContextType Transaction-scoped persistence context (default) If one exists, then it will be used. Otherwise, it will create a persistence context. @PersistenceContextprivate EntityManager em; Extended-scoped persistence context it can span across multiple transactions. We can persist the entity without the transaction but cannot flush it without a transaction. @PersistenceContext(type = PersistenceContextType.EXTENDED) reference : https://www.baeldung.com/jpa-hibernate-persistence-contextEntityManager@PersistenceContextprivate EntityManager em;Member member = em.find(Member.class, &quot;member1&quot;); // get entitytransaction.commit();em.close(); // End persistence context@OneToMany, @ManyToMany, @ManyToOne, @OneToOne Option FetchType see next part CASCADE to inherit persistence CascadeType ALL, PERSIST, MERGE, REMOVE, REFRESH, DETACH orphanRemoval to remove child entity together when the parent entity is not related anymore orpahnRemoval = true remove the related child entity automatically example// can add or remove child entity when the parent entity is added or removed@OneToMany(mappedBy = &quot;parentClassName&quot;, cascade = {CascadeType.ALL}, orphanRemoval = true)private List&amp;lt;&amp;gt; ... = ...;Parent parent = em.find(Parent.class, parentld);// CascadeType.ALL =parent.addChild(child); // orphanRemoval = true =parent.getChildren().remove(object); FetchType Lazy Loading (Recommend) delays the initialization of a resource. (get proxy) the default of @OneToMany, @ManyToMany (optional = false) : inner join (optional = true) : outer join example@ManyToOne(fetch = FetchType.LAZY)@JoinColumn(name = &quot;TEAM_ID&quot;, nullable = false)private Team team;Member member = em.find(Member.class, &quot;member1&quot;);Team team = member.getTeam(); // proxy objectteam.getName(); // use real object (search data from DB on this time)// proxyMember member = em.getReference(Member.class, &quot;member1&quot;); find() : If there is no entity in the persistence context, search data from database. Eager Loading initializes or loads a resource as soon as the code is executed. (get data immediately) often use it with JOIN query the default of @ManyToOne, @OneToOne (optional = false) : outer join (optional = true) : inner join example@ManyToOne(fetch = FetchType.EAGER)@JoinColumn(name = &quot;TEAM_ID&quot;, nullable = false)private Team team;Member member = em.find(Member.class, &quot;member1&quot;);Team team = member.getTeam(); // get real object@Embeddable, @Embedded @Embeddable use on the defined value @Embedded use on the being used value example@Entitypublic class Member { String name; @Embedded Address address;}@Embeddablepublic class Address { String city; String street;} you can use @AttributeOverride if there are duplicated properties.LockModeTypecontrol DB concurrency READ (= OPTIMISTIC) WRITE (= OPTIMISTIC_FORCE_INCREMENT) OPTIMISTIC (= READ) OPTIMISTIC_FORCE_INCREMENT (= WRITE) PESSIMISTIC_READ PESSIMISTIC_WRITE PESSIMISTIC_FORCE_INCREMENT NONE Optimistic assume transaction will not be occured how to apply : Use @Version in JPA Entity 내부에 @Version이 붙은 int, Integer, long, Long, short, Short, Timestamp Type의 필드가 있으면 적용됨 (한 개의 필드만 허용) OPTIMISTIC 읽기 시에도 ＠Version 속성을 체크하고 트랜잭션이 종료될 때까지 다른 트랜잭션에서 변경하지 않음을 보장 (Dirty Read 방지) OPTIMISTIC_FORCE_INCREMENT @Version 정보를 강제로 증가시킴 Pessimistic assume transaction will be occured transaction will wait before getting Lock how to apply : Use Lock on DB PESSIMISTIC_WRITE (often used in PESSIMISTIC LOCK) select for update lock이 걸린 row는 다른 transaction이 read, update, delete 할 수 없음 (prevent non-repeatable read) PESSIMISTIC_READ only read / update, delete되는 것을 방지 / for share PESSIMISTIC_FORCE_INCREMENT Use @Version / 잠금을 획득할 시 @Version이 업데이트됨 / for update nowait Recommend JPA Transaction Read committed transaction + Optimistic Version managementreference : https://velog.io/@lsb156/JPA-Optimistic-Lock-Pessimistic-LockPrimary Cache, Secondary Cache primary cache in persistence context secondary cache in application before terminating application @Cacheable(cacheNames = &quot;&quot;) enable caching first check the cache before actually invoking the method and then caching the result. must have the return value @CacheEvict(cacheNames = {..., ...}) to indicate the removal of one or more/all values so that fresh values can be loaded into the cache again. the return value is not needed @CacheEvict(value=&quot;...&quot;, allEntries=true) this will clear all the entries in the caches and prepare it for new data. @CachePut we can update the content of the cache without interfering with the method execution. That is, the method will always be executed and the result cached: @CachePut will actually run the method and then put its results in the cache, whereas @Cacheable will skip running the method and first check the cache. @Caching @Caching(evict = {…}), group multiple caching annotations @CacheConfig we can streamline some of the cache configuration into a single place at the class level, so that we don’t have to declare things multiple times AopContext.currentProxy() to use this proxy, declare @EnableAspectJAutoProxy(exposeProxy = true) in configuration @EnableCaching in CachingConfig After we enable caching, for the minimal setup, we must register a cacheManager @Aspect // @Cacheable@Cacheable(cacheNames = &quot;member&quot;)public List&amp;lt;MemberDto&amp;gt; getMembers() { return api.getMembers();}// AopContext.currentProxy()public List&amp;lt;MemberDto&amp;gt; getMembersOver30age() { return AopContext.currentProxy().getMembers() .stream().filter(age -&amp;gt; age &amp;gt; 30) .collect(Collectors.toList());}// Api@CacheEvict(cacheNames = MEMBER)@PostMappingString registerMember(Member member);@CacheEvict(cacheNames = MEMBER)@PutMappingvoid modifyMember(String memberCode, Member member);reference : https://www.baeldung.com/spring-cache-tutorialEntityTransaction public void begin(); public void commit(); public void rollback(); public void setRollbackOnly(); public boolean getRollbackOnly(); public boolean isActive(); Word Data Consistency : 데이터 정합성 (데이터 값이 서로 일치하는 상태) Data Integrity : 데이터 무결성 (데이터 값이 정확한 상태)" }, { "title": "[Development] Swagger", "url": "/posts/swagger/", "categories": "Development, Spring", "tags": "eng", "date": "2022-08-17 15:00:00 +0900", "snippet": "What is Swagger?one of tools for describing RESTful APIs by OpenAPI specification OAS (OpenAPI Specification) the way to express RESTful API in json or yaml according to predefined rules the ways to visualize Swagger Swagger UI lets you edit OpenAPI specifications in YAML inside your browser and to preview documentations in real time. Swagger Editor a collection of HTML, Javascript, and CSS assets that dynamically generate beautiful documentation from an OAS-compliant API. Swagger Codegen code generator. You can use it to generate server stubs and client SDKs from an OpenAPI definition. reference :https://gruuuuu.github.io/programming/openapi/https://swagger.io/specification/Benefits human readable and machine readable API documentation Swagger allows you to describe the structure of your APIs, so that machines can read them. easily adjustable interactiveHow to use Swaggerspringdoc-openapi vs springfox-swaggerSpringdoc recently, commonly use Swagger3 a much more recent library that does not have so much legacy code as SpringfoxSpringfox deprecated The project seems to be no longer maintained last commit is of Oct 14, 2020 Springdocbuild.gradleimplementation &#39;org.springdoc:springdoc-openapi-ui:1.5.10&#39;application.yml setting swagger-ui pathspringdoc: swagger-ui: path: /swagger-ui.htmlAnnotations reference :https://jeonyoungho.github.io/posts/Open-API-3.0-Swagger-v3-%EC%83%81%EC%84%B8%EC%84%A4%EC%A0%95/import io.swagger.v3.oas.annotations.*;@Tag name, description…Example@Tag(name = &quot;Item&quot;, description = &quot;품목&quot;)@Operation summary, security, description…Example@Operation(summary = &quot;get&quot;, description = &quot;get user data by id&quot;)@Operation(summary = &quot;register&quot;, security = @SecurityRequirement(name = &quot;bearer-token&quot;))@Parameter Example 1 In @Parameters@Parameters({ @Parameter(name = &quot;id&quot;, description = &quot;아이디&quot;)}) Example 2 In @Operations @Operation(parameters = { @Parameter(name = &quot;name&quot;, in = ParameterIn.QUERY, schema = @Schema(implementation = String.class)) }) Example 3 In method argument@Operation(summary = &quot;게시글 조회&quot;, description = &quot;id를 이용하여 posts 레코드를 조회합니다.&quot;, responses = { @ApiResponse(responseCode = &quot;200&quot;, description = &quot;게시글 조회 성공&quot;, content = @Content(schema = @Schema(implementation = PostsResponseDto.class))), @ApiResponse(responseCode = &quot;404&quot;, description = &quot;존재하지 않는 리소스 접근&quot;, content = @Content(schema = @Schema(implementation = ErrorResponse.class)))})@GetMapping(&quot;/posts/{id}&quot;)public PostsResponseDto findById(@Parameter(name = &quot;id&quot;, description = &quot;posts 의 id&quot;, in = ParameterIn.PATH) @PathVariable Long id) { return postsService.findById(id);}@ApiResponse description, responseCode, content… content : @Content, @ExampleObject, @ArraySchema, @Schema… Use HTTP Status CodeExample// 200 OK@ApiResponse( description = &quot;OK&quot;, responseCode = &quot;200&quot;, content = {@Content( array = @ArraySchema( schema = @Schema( implementation = SuccessInfoDto.class, description = &quot;detail&quot; ) ) )})// 404 NOT FOUND@ApiResponse( description = &quot;Not Found&quot;, responseCode = &quot;404&quot;, content = {@Content( examples = { @ExampleObject(value = &quot;{\\n&quot; + &quot; \\&quot;timestamp\\&quot;: \\&quot;2022-08-17\\&quot;,\\n&quot; + &quot; \\&quot;error\\&quot;: \\&quot;DataNotFound\\&quot;,\\n&quot; + &quot; \\&quot;message\\&quot;: \\&quot;There is no data\\&quot;,\\n&quot; + &quot; \\&quot;status\\&quot;: 404\\n&quot; + &quot;}&quot; ) } ) }) Before After @Schema name, title, description, hidden… Example 1 in Dto.class@Schema(description = &#39;id&#39;, example = &quot;1&quot;)String id; Example 2 in @ApiResponse@ApiResponse(responseCode = &quot;200&quot;, description = &quot;게시글 조회 성공&quot;, content = @Content(schema = @Schema(implementation = PostsResponseDto.class))) Example 3 in @Parameters@Parameters({ @Parameter(name = &quot;id&quot;, description = &quot;아이디&quot;, schema = @Schema(type = &quot;integer&quot;, format = &quot;int32&quot;, minimum = &quot;1&quot;))}) Before After Code ExampleController.javaimport io.swagger.v3.oas.annotations.Operation;import io.swagger.v3.oas.annotations.Parameter;import io.swagger.v3.oas.annotations.Parameters;import io.swagger.v3.oas.annotations.responses.ApiResponse;import io.swagger.v3.oas.annotations.responses.ApiResponses;import io.swagger.v3.oas.annotations.tags.Tag;@Tag(name = &quot;Item&quot;, description = &quot;품목&quot;)@RestControllerpublic class Controller { @GetMapping(value = &quot;/{id}&quot;) @Operation(summary = &quot;조회&quot;) @Parameters({ @Parameter(name = &quot;id&quot;, description = &quot;아이디&quot;) }) @ApiResponse( description = &quot;&quot;, responseCode = &quot;200&quot;, content = { @Content( schema = @Schema( implementation = dto.class, description = &quot;detail&quot; ) )} ) public ResponseEntity&amp;lt;Response&amp;gt; getResponse(@PathVariable String id) { return ResponseEntity.of(service.findById(id)); }}Request.javaimport io.swagger.v3.oas.annotations.media.Schema;public class Request { @Schema(description = &#39;id&#39;, example = &quot;1&quot;) String id; @Schema(hidden = true) String status;} reference :https://jeonyoungho.github.io/posts/Open-API-3.0-Swagger-v3/https://velog.io/@hyejinjeong9999/springdoc%EC%9C%BC%EB%A1%9C-swagger3-%EB%8F%84%EC%9E%85" }, { "title": "[Development] HTTP Status Code", "url": "/posts/HTTP-status-code/", "categories": "Development, Spring", "tags": "eng", "date": "2022-08-17 15:00:00 +0900", "snippet": "RulesCommon HTTP Status Codes Status Code Meaning 200 OK the HTTP request was successfully carried out 201 Created the PUT, POST request was successfully carried out 204 No Content the request was successfully carried out and nothing to return 301 Moved Permanently the data requested from the client cannot be found under the given address since it has been moved permanently. 302 Moved Temporarily the requested data has temporarily been moved. the remaining information is specified so that an automatic redirection can take place. The old address remains valid. 400 Bad Request the server cannot or will not process the request due to something like invalid request message 401 Unauthorized when authentication is required but has failed or not been provided. 403 Forbidden the client that the requested data is access-protected and that the request cannot be performed due to the client not having authority. 404 Not Found the requested website information was not found on the server 409 Conflict the request could not be processed because of conflict in the request 500 Internal Server Error - 502 Bad Gateway something is wrong with your settings more info : https://restfulapi.net/http-status-codes/" }, { "title": "[Development] CI / CD", "url": "/posts/CI-CD/", "categories": "Development", "tags": "eng", "date": "2022-08-16 15:00:00 +0900", "snippet": "What is CI CD pipeline?a series of steps that must be performed in order to deliver a new version of software (bulding &amp;gt; testing &amp;gt; deploying) CI Continous Integration helps developers merge and test code more frequently, even on a daily basis.CI requires that all tests are automated. CD Continuous Deployment / Conitnous Delivery the next step in the process where the tested code from continuous integration is automatically deployed in various environments by a manual trigger.In continuous delivery, developers need to push changes to their production environment manually. Benefits Less risk: automated tests reduce the chance of introducing bugs, creating a safety net that increases the developer’s confidence in their code. More frequent releases: the automation provided by continuous delivery and continuous deployment allows developers to release and deploy software safely many times per day. Improved productivity: freed from the manual labor of building and testing the code, developers can focus on the creative aspects of coding. Elevated quality: CI acts as a quality gate, preventing code that is not up to standards from getting released. Better design: the iterative nature of continuous integration lets developers work in small increments, allowing a higher degree of experimentation, which leads to more innovative ideas. reference : https://www.youtube.com/watch?v=0Emq5FypiMMExample reference : https://crispyblog.kr/development/common/8 reference : https://velog.io/@haeny01/AWS-Jenkins%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-Docker-x-SpringBoot-CICD-%EA%B5%AC%EC%B6%95Example) JenkinsUnit Test (In Java case : Jacoco + JUnit)jacoco a library checking Java code coverage 테스트코드를 돌리고 그 커버리지 결과를 눈으로 보기 좋도록 html이나 xml, csv 같은 리포트로 생성합니다. 테스트 결과가 내가 설정한 커버리지 기준을 만족하는지 확인하는 기능도 있습니다. import to Gradle configuration jacocoTestReport binary coverage 결과를 사람이 보기 편한 형태의 report로 저장(html, xml, csv…) jacocoTestCoverageVerification 내가 원하는 coverage 기준을 설정 jacocoTestReport { reports { // 원하는 리포트를 켜고 끌 수 있습니다. html.enabled true xml.enabled false csv.enabled false// 각 리포트 타입 마다 리포트 저장 경로를 설정할 수 있습니다.// html.destination file(&quot;$buildDir/jacocoHtml&quot;)// xml.destination file(&quot;$buildDir/jacoco.xml&quot;)// dependsOn으로 실행 순서 지정 가능 dependsOn (`:test`, `:jacocoTestReport`, `:jacocoTestCoverageVerification`) }}jacocoTestCoverageVerification { violationRules { rule { element = &#39;CLASS&#39; limit { counter = &#39;BRANCH&#39; value = &#39;COVEREDRATIO&#39; minimum = 0.90 } } }}// defaulttest { jacoco { enabled = true destinationFile = file(&quot;$buildDir/jacoco/$.exec&quot;) includes = [] excludes = [] excludeClassLoaders = [] includeNoLocationClasses = false sessionId = &quot;&amp;lt;auto-generated value&amp;gt;&quot; dumpOnExit = true classDumpDir = null output = JacocoTaskExtension.Output.FILE address = &quot;localhost&quot; port = 6300 jmx = false }} reference : «https://techblog.woowahan.com/2661/&amp;gt;JUnit a simple Java unit testing framework Annotations @Test @BeforeEach @AfterEach @DisplayName Assert… assertEquals asssertThat().isEqualsTo() assertAll ** vs org.springframework.util.Assert - not for test code - often used to parameter verificationbuild.gradletest { useJUnitPlatform()}Test.javaimport org.junit.jupiter.api.Test;import org.junit.jupiter.api.Assertions;public class CaluratorTest {                                           @Test public void testSum() { // ... Assertions.assertEquals(...); }} reference :https://phoenixnap.com/kb/what-is-jenkinshttps://epthffh.tistory.com/entry/Junit%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EB%8B%A8%EC%9C%84%ED%85%8C%EC%8A%A4%ED%8A%B8Example) Gitlab CI/CDUse .gitlab-ci.yml for automation how to make [.gitlab-ci.yml]https://buildkite.com/ci-cdExample) BuildKitehttps://buildkite.com/ci-cdInterview Questions reference : https://semaphoreci.com/blog/common-cicd-interview-questions" }, { "title": "[Tail] Merge Sorted Array", "url": "/posts/algorithm-merge-sorted-array/", "categories": "Development, Algorithm", "tags": "algorithm, java, eng, leetcode", "date": "2022-08-05 18:00:00 +0900", "snippet": "’ Merge Sorted Array’ in LeetCode (Easy)📌 Problemhttps://leetcode.com/problems/merge-sorted-array/📌 AnswerThe point put data from the last index to first index (descending order)class Solution { public void merge(int[] nums1, int m, int[] nums2, int n) { int tail1 = m - 1, tail2 = n - 1, finished = m + n -1; while (tail1 &amp;gt;= 0 &amp;amp;&amp;amp; tail2 &amp;gt;= 0) nums1[finished--] = nums1[tail1] &amp;gt; nums2[tail2] ? nums1[tail1--] : nums2[tail2--]; while (tail2 &amp;gt;= 0) nums1[finished--] = nums2[tail2--]; }}" }, { "title": "[Easy] Plus One", "url": "/posts/algorithm-Plus-One/", "categories": "Development, Algorithm", "tags": "algorithm, java, eng, leetcode", "date": "2022-08-05 14:30:00 +0900", "snippet": "‘Plus One’ in LeetCode (Easy)📌 Problemhttps://leetcode.com/problems/plus-one/📌 Answerclass Solution { public int[] plusOne(int[] digits) { for (int i = digits.length - 1; i &amp;gt;= 0; i--) { if (digits[i] != 9) { digits[i]++; break; } else { digits[i] = 0; } } if (digits[0] == 0) { int[] res = new int[digits.length + 1]; res[0] = 1; return res; } return digits; }}" }, { "title": "[Java String methods] Implement strStr()", "url": "/posts/algorithm-Implement-strStr/", "categories": "Development, Algorithm", "tags": "algorithm, java, eng, leetcode", "date": "2022-08-05 14:00:00 +0900", "snippet": "’ Implement strStr()’ in LeetCode (Easy)📌 Problemhttps://leetcode.com/problems/implement-strstr/📌 AnswerThe Point String methods : contains(), indexOf() reference: https://www.w3schools.com/java/java_ref_string.asp class Solution { public int strStr(String haystack, String needle) { if (needle == &quot;&quot; || haystack == &quot;&quot;) return 0; else if (haystack.contains(needle)) return haystack.indexOf(needle); else return -1; }}class Solution { public int strStr(String haystack, String needle) { for (int i = 0; ; i++) { for (int j = 0; ; j++) { if (j == needle.length()) return i; if (i + j == haystack.length()) return -1; if (needle.charAt(j) != haystack.charAt(i + j)) break; } } }}" }, { "title": "[Easy] Remove Duplicates from Sorted Array", "url": "/posts/algorithm-remove-duplicates-from-sorted-array/", "categories": "Development, Algorithm", "tags": "algorithm, java, eng, leetcode", "date": "2022-08-05 13:30:00 +0900", "snippet": "‘Remove Duplicates from Sorted Array’ in LeetCode (Easy)📌 Problemhttps://leetcode.com/problems/remove-duplicates-from-sorted-array/📌 Answerclass Solution { public int removeDuplicates(int[] nums) { int i = 0; for (int n : nums) { if (i == 0 || n &amp;gt; nums[i-1]) nums[i++] = n; } return i; }}The point O(1) extra memory Do not allocate extra space for another array. return a array size that you modifiedclass Solution { public int removeDuplicates(int[] nums) { int j = 0; for (int i = 1; i &amp;lt; nums.length; i++) { if (nums[j] != nums[i]) { j++; nums[j] = nums[i]; } } return j + 1; }}Custom Judgeint[] nums = [...]; // Input arrayint[] expectedNums = [...]; // The expected answer with correct lengthint k = removeDuplicates(nums); // Calls your implementationassert k == expectedNums.length;for (int i = 0; i &amp;lt; k; i++) { assert nums[i] == expectedNums[i];}" }, { "title": "[Spring] Apache Kafka + Spring Boot", "url": "/posts/Kafka/", "categories": "Development, Spring", "tags": "spring, eng", "date": "2022-08-01 15:02:00 +0900", "snippet": "KafkaStructureRecord &amp;lt; Partition &amp;lt; Topic &amp;lt; Broker &amp;lt; Cluster Topic 메시지를 구분하는 논리적인 단위 Partition 모든 토픽은 각각 대응하는 하나 이상의 파티션이 브로커에 구성되고, 발행되는 토픽 메시지들은 파티션들에 나뉘어 저장됨. 하나의 토픽에 대하여 여러 파티션을 구성하는 가장 큰 이유 : 분산 처리를 통한 성능 향상 하나의 파티션 내에서는 메시지 순서가 보장 Broker 카프카 브로커는 프로듀서와 컨슈머 사이에서 메시지를 중계카프카 브로커가 일반적으로 ‘카프카’라고 불리는 시스템임. 프로듀서와 컨슈머는 별도의 애플리케이션으로 구성되는 반면, 브로커는 카프카 자체이기 때문입니다. 따라서 ‘카프카를 구성한다’ 혹은 ‘카프카를 통해 메시지를 전달한다’에서 카프카는 브로커를 의미. Producer, Consumer Producer는 오직 끝에만 쓰며, Consumer는 오프셋을 기준으로 차례차례 읽어나감. Topics a particular stream of data you can have as many topics as you want a topic is identified by its name Topics are split in partitions Each partition is ordered Each message within a paritition gets an incremental id, called offset 동일한 토픽의 메시지들은 논리적으로 같은 문맥(context)을 가집 Message Key(키)와 Value(값)로 구성 브로커를 통해 메시지가 발행되거나 소비될 때, 메시지 전체가 직렬화/역직렬화됨 특정한 구조인 스키마(schema)를 가짐 &amp;gt; 프로듀서가 발행하고 컨슈머가 소비할 때 메시지를 적절하게 처리하기 위해 필요 (만약 프로듀서와 컨슈머가 메시지에 대한 서로 다른 스키마를 가지고 있다면, 정상적인 처리를 할 수 없음) Replica 서비스 안정성과 장애 수용(Fault-Tolerance)에 관한 요소 하나의 파티션은 1개의 리더 레플리카와 그 외 0개 이상의 팔로어 레플리카로 구성됨. 리더 레플리카는 파티션의 모든 쓰기, 읽기 작업을 담당. 반대로 팔로어 레플리카는 리더 레플리카로 쓰인 메시지들을 그대로 복제하고, 만약 리더 레플리카에 장애가 발생하는 경우, 리더 자리를 승계받을 준비를 함. 참고로 승계받을 준비가 된 즉, 리더 레플리카의 메시지를 적절하게 복제하여 리더 레플리카와 동기화된 레플리카들의 그룹을 ISR(In-Sync Replica)라고 함. Replication-factor Offset only have ameaning for a specific partition Ex. offset3 in partition0 doesn’t represent the same data as offset3 in partition1 Order is guaranteed only within a partition (not across paritions) Data (Message / Record) Data is kept only for a limited time (default is one week) once the data is written to a partition, it’t be changed (immutabiltiy) Data is assigned randomly to a partition unless a key is provided (more on this later) necessary : offset, messageKey, messageValue reference : https://always-kimkim.tistory.com/entry/kafka101-message-topic-partitionFeatures good solution for large scale message processing applications better throughput, built-in partitioning, replication, and fault-tolerance, horizontal scalabiltiy messaging uses are often comparatively low-throughput but may require low end-to-end latency and often depend on the strong durability guarantees (Kafka can provide) kafka can scale to 100s of brokers kafka can scale to milions of messages per second high performance (latency of less than 10ms) - real time for the log history for decoupling of data streams &amp;amp; systemsUse cases messageing system activity tracking gather metrics from many different locations application logs gathering stream processing (with the kafka stream API or Spark for example) De-coupling of system dependencies Integration with Spark, Flink, Storm, Hadoop and many other Big Data technologies key point : in real-timeKafka VS RabbitMQ   Kafka RabbitMQ   distributed event streaming platform open source distributed message broker   pub/sub (생산자가 원하는 각 메시지를 게시할 수 있도록 하는 메시지 배포 패턴) message broker (응용프로그램, 서비스 및 시스템이 정보를 통신하고 교환할 수 있도록 하는 소프트웨어 모듈)   복잡한 라우팅에 의존하지 않고 최대 처리량으로 스트리밍하는 데 가장 적합, 다단계 파이프라인에서 데이터를 처리 복잡한 라우팅, 신속한 요청-응답이 필요한 웹 서버에 적합 reference : https://coding-nyan.tistory.com/129 reference : Apache Kafka in 5 minuteshttps://www.youtube.com/watch?v=PzPXRmVHMxIApache Kafka in 6 minuteshttps://www.youtube.com/watch?v=Ch5VhJzaoaIhttps://always-kimkim.tistory.com/entry/kafka101-brokerInternal/External StructureExamplebuild.gradledependencies { implementation: &quot;spring-kafka&quot;}application.ymlspring: kafka: bootstrap-servers: localhost:9092KafkaTopicConfig.java@Configurationpublic class KafkaTopicConfig { @Bean public NewTopic amgifoscodeTopic() { // NewTopic : org.apache.kafka.clients.admin.NewTopic return TopicBuilder.name(&quot;amigoscode&quot;).build(); }} Output Terminal https://kafka.apache.org/quickstart+additional command : https://sangchul.kr/144cd kafka_2.12-3.2.1bin/zookeeper-server-start.sh config/zookeeper.propertiesbin/kafka-server-start.sh config/server.properties// Create a topicbin/kafka-topics.sh --create --topic quickstart-events --bootstrap-server localhost:9092// Read the events (topic --&amp;gt; amigoscode)bin/kafka-console-consumer.sh --topic amigoscode --from-beginning --bootstrap-server localhost:9092KafkaProducerConfig.java Use KafkaTemplate for implemeting producer KafkaProducer.send() in KafkaTemplate.send() reference : https://jessyt.tistory.com/142 @Configurationpublic class KafkaProducerConfig { @Value(&quot;${spring.kafka.bootstrap-servers}&quot;) private String bootstrapServers; public Map&amp;lt;String, Object&amp;gt; producerConfig() { Map&amp;lt;String, Object&amp;gt; properties = new HashMap&amp;lt;&amp;gt;(); properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers); properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class); properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class); return properties; } @Bean public ProducerFactory&amp;lt;String, String&amp;gt; producerFactory() { return new DefaultKafkaProducerFactory&amp;lt;&amp;gt;(producerConfig()); } @Bean public KafkaTemplate&amp;lt;String, String&amp;gt; kafkaTemplate(ProducerFactory&amp;lt;String, String&amp;gt; producerFactory) { return new KafkaTemplate&amp;lt;&amp;gt;(producerFactory); } // KafkaTemplate&amp;lt;String, Object&amp;gt; ~~~} KafkaConsumerConfig.java Use ConcurrentKafkaListenerContainerFactory for implementing consumer reference : https://semtax.tistory.com/83 @Configurationpublic class KafkaConsumerConfig { @Value(&quot;localhost:9092&quot;) private String bootstrapServers; public Map&amp;lt;String, Object&amp;gt; consumerConfig() { Map&amp;lt;String, Object&amp;gt; properties = new HashMap&amp;lt;&amp;gt;(); properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers); properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringSerializer.class); properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringSerializer.class); return properties; } @Bean public ConsumerFactory&amp;lt;String, String&amp;gt; consumerFactory() { return new DefaultKafkaConsumerFactory&amp;lt;&amp;gt;(consumerConfig()); } @Bean public KafkaListenerContainerFactory&amp;lt;ConcurrentMessageListenerContainer&amp;lt;String,String&amp;gt;&amp;gt; factory(ConsumerFactory&amp;lt;String, String&amp;gt; consumerFactory) { ConcurrentKafkaListenerContainerFactory&amp;lt;String, String&amp;gt; factory = new ConcurrentKafkaListenerContainerFactory&amp;lt;&amp;gt;(); factory.setConsumerFactory(consumerFactory); return factory; } // ConcurrentKafkaListenerContainerFactory&amp;lt;String, Object&amp;gt; ~~~}KafkaApplication.java@SpringBootApplicationpublic class KafkaexampleApplication { public static void main(String[] args) { SpringApplication.run(KafkaexampleApplication.class, args); } @Bean CommandLineRunner commandLineRunner(KafkaTemplate&amp;lt;String, String&amp;gt; kafkaTemplate) { return args -&amp;gt; { kafkaTemplate.send(&quot;amigoscode&quot;, &quot;hello kafka&quot;); // topic, data(message) }; }} KafkaTemplate.send() it goes through different layers before the message is sent to Kafka.KafkaListeners.java@Componenetpublic class KafkaListeners { @KafkaListener(topics = &quot;amigoscode&quot;, groupId = &quot;groupId&quot;) void listener(String data) { System.out.println(&quot;Listener received: &quot; + data ); }}MessageRequest.java// recordpublic record MessageRequest(String message) {}=// class// Records provide a public constructor (with all arguments), read methods for each field (equivalent to getters) and the implementation of hashCode, equals and toString methods.public class MessageRequest { private String message; public MessageRequest() { } public MessageRequest(String message) { } public String getMessage() { return message; } public boolean equals(Object o) { return true; } public int hashCode() { return 0; } public String toString() { return &quot;&quot;; }}MessageController.java@RestController@RequestMapping(&quot;api/vi/messages&quot;)public class MessageController { private KafkaTemplate&amp;lt;String, String&amp;gt; kafkaTemplate; public MessageController(KafkaTemplate&amp;lt;String, String&amp;gt; kafkaTemplate) { this.kafkaTemplate = kafkaTemplate; } @PostMapping public void publish(@RequestBody MessageReqeust request) { kafkaTemplate.send(&quot;amigoscode&quot;, request.getMessage()); }} OutputAPI TESTPOST http://localhost:8080/api/vi/messagesContent-Type: application/json{ &quot;message&quot;: &quot;Api With Kafka&quot;} Output reference : Apache Kafka in 5 minutes https://www.youtube.com/watch?v=PzPXRmVHMxI Kafka Tutorial - Spring Boot Microservices https://www.youtube.com/watch?v=SqVfCyfCJqw Kafka Topics, Partitions and Offsets Explained https://www.youtube.com/watch?v=_q1IjK5jjyU Kafka Stream kafka streams api를 사용하여, 지속적으로 흘러들어오는 데이터에 대한 분석, 처리를 위한 client library 어떤 Topic으로 들어오는 데이터를 Consume하여, streams api를 통해 처리 후다른 Topic으로 전송(Producing) 하거나 끝내는 행위 Spring cloud stream에서 제공하는 Binder라는 구현체를 중간에 두고 통신하기 때문에, 어느 하나의 미들웨어에 강결합 되어있지 않은 상태에서 애플리케이션을 개발   binder bindings(input/output)   메시지 broker 정보 메세지를 전송할 채널정보   미들웨어와의 통신을 담당하는 컴포넌트 미들웨어와 통신을 위한 브릿지   미들웨어(kafka)와 producer 및 consumer의 연결, 위임 및 라우팅 등을 담당 바인더의 입/출력을 미들웨어(kafka)에 연결하기 위한 Bridge Examplebuild.gradledependencies { implementation &#39;org.springframework.cloud:spring-cloud-starter-stream-kafka&#39;}Default interfacepublic interface Sink { String INPUT = &quot;process-input&quot;; // INPUT : consumer 입장에서 subscribe 받을 TOPIC명 @Input(INPUT) SubscribableChannel input();}public interface Source { String OUTPUT = &quot;process-output&quot;; // OUTPUT : producer 입장에서 publish할 TOPIC명 @Output(OUTPUT) MessageChannel output();}public interface Processor extends Source, Sink {}Custom interfacepublic interface ProcessMessage { String SEND_MESSAGE = &quot;send-message&quot;; String RECEIVE_MESSAGE = &quot;receive-message&quot;; @Output(SEND_MESSAGE) MessageChannel sendMessage(); @Input(RECEIVE_MESSAGE) SubscribableChannel getMessage();}@ConditionalOnProperty(name = &quot;spring.cloud.stream.enabled&quot;, havingValue = &quot;true&quot;, matchIfMissing = true)@EnableBinding(EventSource.class)public class MessageConsumer { @StreamListener(target = ProcessMessage.RECEIVE_MESSAGE, condition = &quot;headers[&#39;eventType&#39;] == &#39;MessageEvent&#39;&quot;) public void pushMessage(MessageEvent event) throws JsonProcessingException { ... }}public class MessageEvent { // props}application.ymlspring: cloud: stream: enable: kafka: binder: brokers: localhost // broker ip # replication-factor: 2 // minimum = 2 # auto-create-topics: false bindings: // input/output receive-message: // channel name destination: &quot;${spring.cloud.stream.topic:}process-input&quot; // topic name group: &quot;${spring.cloud.stream.consumer.group:}&quot; // consumer group id send-message: // output destination: &quot;${spring.cloud.stream.topic:}process-output&quot;Related Annotations@EnableBinding@EnableBinding(EventSource.class)@KafkaListener@KafkaListener(topics = &quot;amigoscode&quot;, groupId = &quot;groupId&quot;)@ConditionalOnProperty(…) enables bean registration only if an environment property is present and has a specific value.@ConditionalOnProperty(name = &quot;spring.cloud.stream.enabled&quot;, havingValue = &quot;true&quot;, matchIfMissing = true) condition : spring.cloud.stream.enabled:true (in application.yml) name (=value) : key in application.yml havingValue : value of key in application.yml matchIfMissing : whether create a bean even if not matching@ConditionalOnMissingBean reference : https://saramin.github.io/2019-08-28-2/https://piotrminkowski.com/2021/11/11/kafka-streams-with-spring-cloud-stream/http://www.chidoo.me/index.php/2016/11/06/building-a-messaging-system-with-kafka/https://jaehun2841.github.io/2019/12/23/2019-12-23-kafka-streams-binder-feature/#Version-Uphttps://sangchul.kr/144" }, { "title": "[Spring] Microservices in Spring Boot", "url": "/posts/Spring-Boot-Microservices/", "categories": "Development, Spring", "tags": "spring, eng", "date": "2022-07-29 15:02:00 +0900", "snippet": "How to communicate microservices @FeignClient (ApiClient) Kafka (Use Event) RestTemplate (communicate with REST API) Circuit Breaker (Fault Tolerant Design Pattern)Spring Clouda framework for building robust cloud(strong and healthy) applications. (= microservices)Spring Cloud StreamA lightweight event-driven microservices framework to quickly build applications that can connect to external systems.Simple declarative model to send and receive messages using Apache Kafka(middleware) or RabbitMQbetween Spring Boot apps.@FeignClient Microservices communication method in Spring Boot @EnableFeignClientsuser-servicebuild.gradledependencies { implementation group: &#39;org.springframework.cloud&#39;, name: &#39;spring-cloud-starter-openfeign&#39;, version: &#39;2.1.1.RELEASE&#39;}user-service@EnableFeignClientspublic class ApiClientConfiguration { ...}departments-service@FeignClient(name = &quot;user&quot;, contextId = &quot;userEnvironmentSetting&quot;, url = &quot;${...}&quot;)@RequestMapping(path=&quot;/users&quot;, consumes = &quot;application/json&quot;)interface UserEnvironmentSettingClient { @Override @GetMapping(&quot;/users/environmentSetting&quot;) Map&amp;lt;String, String&amp;gt; getEnvironmentSetting();} name : LoadBalancer client name contextId : bean name instead of name if present issue : 동일 name 으로 두개의 class 에서 지정하면 오류 발생 reference: https://techblog.woowahan.com/2630/RestTemplate Spring Http communication template (Rest API 서비스를 요청 후 응답받을 때 주로 사용) For communiating over the microservices Synchronize (Async : org.springframework.web.client.AsyncRestTemplate) will be deprecatedbuild.gradleimplementation &#39;org.springframework.boot:spring-boot-starter-web&#39;RestTemplate VS WebCLient   RestTemplate WebCLient   Sync Async (= AsyncRestTemplate) Dependency implementation ‘org.springframework.boot:spring-boot-starter-web’ implementation ‘org.springframework.boot:spring-boot-starter-webflux’ referencehttps://backtony.github.io/spring/2021-07-12-spring-basic-8/https://blog.naver.com/hj_kim97/222295259904 https://sjh836.tistory.com/141Blocking VS Non-Blocking VS Sync VS Async Blocking / Non-blocking 다른 주체가 작업할 때 자신에게 자신의 작업에 대한 제어권이 있는지 없는지   Blocking Non-blocking   호출된 함수가 자신의 작업을 모두 마칠 때까지 호출한 함수에게 제어권을 넘겨주지 않고 대기하게 만든다면 (executes “in series”) 호출된 함수가 바로 리턴해서 호출한 함수에게 제어권을 넘겨주고, 호출한 함수가 다른 일을 할 수 있는 기회를 줄 수 있으면 (executes in parallel) Example 직원이 상사에게 서류를 제출하고, 상사가 서류를 다 읽을 때까지 자리에서 기다리는 상황 직원이 상사에게 서류를 제출했지만, 상사가 서류를 다 읽어볼 동안 자리에 가서 자신의 일을 처리하는 상황 Sync / Async 그것을 요청한 순서가 지켜지는가 아닌가 (호출되는 함수의 작업 완료 여부를 누가 신경쓰냐)   Synchronous Asynchronous   작업을 동시에 수행하거나, 동시에 끝나거나, 끝나는 동시에 시작함 (결과를 리턴받았을 때 바로 그 결과에 집중함 / scheduled, real-time) 시작, 종료가 일치하지 않으며 끝나는 동시에 시작을 하지 않음 (결과를 바로 처리하지 않아도 됨 / on your own time, no need schedule / use callback)   When a work is requested, the result value of the request is directly returned. When a work is requested, the result value of the request is indirectly received   요청을 보낸 후 응답을 받아야지만 다음 동작이 이루어짐 웹 페이지 전체를 새로고침 하지않고 데이터를 불러오는 방식   비동기 방식에 비해 설계가 매우 간단하고 직관적이지만 결과가 주어질 때 까지 아무 것도 못하고 대기해야함 비동기 방식을 이용할 경우, 필요한 부분의 데이터만 불러와 사용 가능. 결과가 주어지는데 시간이 걸리더라도 그 시간동안 다른 작업을 할 수 있으므로 자원의 효율적 사용 가능 Example 상사가 서류를 다 읽고 결과를 리턴해주면 직원은 바로 그 결과에 관심을 갖게 됩니다. 상사가 리턴한 결과를 바로 처리할지, 나중에 처리할지를 결정할 수 있습니다. common used : sync-blocking, sync-nonblocking, async-nonblocking (most efficient) reference https://studyandwrite.tistory.com/486https://baek-kim-dev.site/38CircuitBreaker (Design pattern using netfilx hystrix) Hystrix library form Netflix (spring-cloud-starter-netflix), isolates the points of access between the services, stops cascading failures across thhem and provides the fallback options Fallback provides an alternative solution during a service request failure Circuit Breaker Pattern prevents failure cascading and gives a default behavior when services fail Netflix Hystrix allows us to introduce fault tolerance and latency tolerance by isolating failure and by preventing them from cascading into the other part of the system building a more robust distributed application. @Servicepublic class GreetingService { @HystrixCommand(fallbackMethod = &quot;defaultGreeting&quot;) public String getGreeting(String username) { return new RestTemplate() .getForObject(&quot;http://localhost:9090/greeting/{username}&quot;, String.class, username); } private String defaultGreeting(String username) { return &quot;Hello User!&quot;; }} @EnableCircuitBreaker will scan the classpath for any compatible Circuit Breaker implementation. @SpringBootApplication@EnableCircuitBreakerpublic class RestConsumerApplication { public static void main(String[] args) { SpringApplication.run(RestConsumerApplication.class, args); }}Hystrix VS Resilience4J common feature : fault tolerant library Hystrix Resilience4J embraces an Object-Oriented design where calls to external systems have to be wrapped in a HystrixCommand offering multiple functionalities. relies on function composition to let you stack the specific decorators you need. referencehttps://engineering.linecorp.com/ko/blog/circuit-breakers-for-distributed-services/ https://www.baeldung.com/spring-cloud-netflix-hystrix https://digitalvarys.com/what-is-circuit-breaker-design-pattern/API Gateway (Load balancing)Service : Cloud-gatewayspring-cloud-starter-gatewaybulid.gradledependencies { compile &#39;org.springframework.cloud:spring-cloud-starter-gateway:2.1.0.RELEASE&#39;}application.ymlserver: port: 9191spring: cloud: gateway: routes: - id: USER-SERVICE url: ${cloud-gateway.user-url} predicates: - Path=/users/ ** - id: DEPARTMENT-SERVICE url: ${cloud-gateway.department-url} predicates: - Path=/departments/ ** filter: - name: CircuitBreaker args: name: USER-SERVICE fallbackuri: forward:/userServiceFallBackcloud-gateway: user-url: http://cloud-user-service:9001 department-url: http://cloud-department-service:9002Meaning: when you call http://localhost:9191/users/1, it goes to http://localhost:9001/users/1 when you call http://localhost:9191/departments/1, it goes to http://localhost:9002/departments/1 reference : https://cloud.spring.io/spring-cloud-gateway/reference/html/#configuration Spring-boot-starter-actuatorbulid.gradledependencies {  compile(&quot;org.springframework.boot:spring-boot-starter-actuator&quot;)}application.ymlFrom spring boot 2.x, you have to custom management part in application.yml because the default setting is not exposing most datas.management: endpoints: web: exposure: include: healthMeaning : expose the health informationmanagement: endpoints: web: exposure: exclude: env, beansMeaning : expose the information except for env, beansthe property exclude is prior than include, so if you declared some information on exclude, you can’t see it even if you declared that on include. reference : https://jeong-pro.tistory.com/160Spring Cloud Stream 이벤트 중심 microservcie를 구축하기 위한 프레임워크 Apache Kafka 또는 RabbitMQ 등을 사용하여 Spring Boot 어플리케이션과 메세지를 보내고 받음.https://saramin.github.io/2019-08-28-2/Eureke Client reference : https://www.baeldung.com/spring-cloud-netflix-eureka" }, { "title": "[Study] TODO", "url": "/posts/Study-Schedule/", "categories": "Diary", "tags": "eng, diary", "date": "2022-07-29 15:02:00 +0900", "snippet": "TODO Microservices Spring Security Kafka (Spring CLoud Stream) Docker Kubernetes CI/CD (jenkins, Gitlab…) Swagger AWS (ElasticSearch…) Network Server Vue.jsContents[Spring Boot + Microservices] Microservices using SpringBoot Full Example https://www.youtube.com/watch?v=BnknNTN8icw Microservices Using Spring Boot and Spring Cloud #1https://www.youtube.com/watch?v=p485kUNpPvE Microservices using Spring Boot and Spring Cloud - HTTP Communication #2https://www.youtube.com/watch?v=QWOgkI4DuE8 What are microservices really all about? - Microservices Basics Tutorialhttps://www.youtube.com/watch?v=j1gU2oGFayY[Spring Security] Spring Security FULL COURSE https://www.youtube.com/watch?v=her_7pa0vrg Spring Boot and Spring Security with JWT including Access and Refresh Tokens 🔑https://www.youtube.com/watch?v=VVn9OG9nfH0[Kafka] Kafka Tutorial - Spring Boot Microserviceshttps://youtu.be/SqVfCyfCJqw Kafka topics, partitions, and offsets explainedhttps://youtu.be/_q1IjK5jjyU[Docker] Docker Tutorial for Beginners [FULL COURSE in 3 Hours]https://www.youtube.com/watch?v=3c-iBn73dDE Docker Tutorial for Beginners Full Course [2021] https://www.youtube.com/watch?v=p28piYY_wv8 Docker and Kubernetes Tutorial Full Course [2021] https://www.youtube.com/watch?v=bhBSlnQcq2k[Kubernetes] Kubernetes Tutorial for Beginners [FULL COURSE in 4 Hours]https://www.youtube.com/watch?v=X48VuDVv0do[Spring Boot + Docker + Kubernetes + Microservices] Spring Boot Docker Kubernetes Spring Boot Kubernetes Microservices Docker Kubernetes tutorial https://www.youtube.com/watch?v=SzbeDqBSRkc Deploy Springboot Microservices to Kubernetes Cluster Full Example https://www.youtube.com/watch?v=VAmntTPebKE Introduction to Microservices, Docker, and Kuberneteshttps://www.youtube.com/watch?v=1xo-0gCVhTU?[CI/CD] GitLab CI CD Tutorial for Beginners [Crash Course]https://www.youtube.com/watch?v=qP8kir2GUgo[Network] Network Protocols - ARP, FTP, SMTP, HTTP, SSL, TLS, HTTPS, DNS, DHCP - Networking Fundamentals - L6https://www.youtube.com/watch?v=E5bSumTAHZE Proxy vs reverse proxy vs load balancer (2020) Explained with real life examples https://www.youtube.com/watch?v=MiqrArNSxSM[Server] Web Server and Application Server Explained 🔥🔥 https://www.youtube.com/watch?v=thJSev60yfg https://www.popit.kr/%EC%8A%A4%ED%83%80%ED%8A%B8%EC%97%85-%EA%B0%9C%EB%B0%9C%EC%9E%90-%ED%98%BC%EC%9E%90-%EB%B9%A0%EB%A5%B4%EA%B2%8C-%EC%8B%B8%EA%B2%8C-%EC%84%9C%EB%B2%84-%EA%B5%AC%EC%B6%95%ED%95%98%EA%B8%B0-1%ED%8E%B8/" }, { "title": "[Tokyo] Preparing to leave for tokyo", "url": "/posts/go-to-tokyo/", "categories": "Tokyo", "tags": "tokyo", "date": "2022-03-09 22:34:00 +0900", "snippet": "【 To do 】 【 Change Korea Mobile Carrier Plan 】 30.01.2022 ⭕️ 스노우맨 알뜰폰 2200 【 Buy 28inch Carrier 】 20.02.2022 ⭕️ American Tourister Assurance period : ~20.02.25 【 Apply VISA 】 JEC 대행사 04.03.2022 ⭕️ Documents 사증 신청서 여권 원본 사진 1매 주민등록등본 COE 원본 COE 사본 ERFS (03.03.2022) 【 VIVA X Hana Card 】 04.03.2022 ⭕️ 【 Reservation Flight Ticket 】 07.03.2022 ⭕️ Asiana Airline, 24.03.22 【 Buy Japan USIM for 10 days 】 10.03.2022 ⭕️ 10일간 10GB (+ 초과 시 무제한) 20300원 【 Contract Sharehouse 】 crosshouse 계약 08.03.2022 ⭕️ 초기비용(사례금) 30000円 입금 (09.03.2022) ⭕️ 3월 월세 입금 입주 28.03.2022 ~ 【 Book a hotel for self-isolation 】 14.03.2022 ⭕️ agoda 24.03.2022 ~ 28.03.2022 (4日間, Shinjuku, 254,488won) Official reference : https://www.cantour.co.jp/news/3593-2 【 Book a pcr test in Japan 】 14.03.2022 ⭕️ The place I booked (Shinjuku, 7800円): https://access.his-j.com/01/B39/ Official reference : https://www.c19.mhlw.go.jp/search/ 【 Documents 】 For entry 영문 PCR TEST in Korea 씨젠 의료재단 (3/22 1:30PM, 119000won) 영문 백신 접종증명서 2매 ⭕️ 서약서 질문서 (+ APP MySOS에 미리 등록) For emergency 반명함 사진 8장, 여권 사진 8장 ⭕️ 주민등록증 사본 ⭕️ 여권 사본 2매 COE 사본 ⭕️ 3/24 항공권 1매 ⭕️ 출입국 관리 기록 (for japan driver license) 한국 통장 사본 1매 (for 해외 취업 정착금) Certification TOEIC 2매 ⭕️ JLPT N1 ⭕️ HSK5 ⭕️ AWS SAA 2매 ⭕️ OCAJP 2매 ⭕️ OCPJP 2매 ⭕️ 【 Plan on 3/24 】 6:50AM take a taxi to 배곧 (20m) 7:20 take a Incheon airport bus 7000 (안산 to 배곧 : 20m) 8:00 arrive at Incheon airport, check-in 8:20 meet 린 at the greeting area 8:40 enter the arrival holl and shopping 9:30 take a flight 10:00 - 12:20 (fly~~~) " }, { "title": "[AWS Solution Architect] Contents &amp; I finally got pass! ", "url": "/posts/Contents/", "categories": "Development, AWS", "tags": "aws, certification, eng", "date": "2022-02-10 13:30:00 +0900", "snippet": "Certification Study period 2022.01.10 ~ 2022.02.09 (30days) Materials I used Youtube video (freeCodeCamp.org, 12/24/2022, https://www.youtube.com/watch?v=Ia-UEYYR44s) - AWS Lecture on 2022.01.24 - Examtopic dump (574 questions)Content Outline Module1 Design Resilient Architectures (30%) single AZ : not for scalability, availability managing service : for redundancy, availability in region 내결함성 : 성능상의 요구조건을 충족시키지 못한 것 ex. 어떤 서비스가 반드시 성능을 만족시키기 위해 4대가 동작해야함. 하지만 2개의 AZ에 instance가 2개씩 있음. 1개의 AZ가 다운 되더라도 나머지 AZ는 돌아감. -&amp;gt; 내구성 O 고가용성 O, but 내결함성은 X (결함 발생한 거라서) 가용성 : 시스템의 내구성을 측정하는 방법 ex. 2 AZ에 각각 4개의 instance가 있음. -&amp;gt; 고가용성 O, 내결함성 O 모든 구성요소에서 장애가 발생할 수 있음 자동으로 복구되거나 multi machine이 동작할 수 있도록 분산해서 처리하도록 설계하는 것이 중요 Module2 Define Performant Architectures (28%) Module3 Specify Secure Applications and Architectures (24%) Module4 Design Cost-Optimized Architectures (18%) Reference : AWS Lecture (2022.01.24)Contents 📓 (0:58:39) S3 - 2022/01/10, 2022/01/31 📓 (1:09:27) Snowball - 2022/01/14 📓 (1:26:19) VPC Endpoints - 2022/01/14 (module3) 📓 (1:29:09) VPC Flow Logs - 2022/01/14 (module3) 📓 (1:32:30) NACL - 2022/01/15 (module3) 📓 (1:38:39) Security Groups - 2022/01/15 (module3) 📓 (1:42:45) NAT - 2022/01/15 📓 (2:50:37) IAM - 2022/01/18 (module3) 📓 (2:58:12) Cognito - 2022/01/31 📓 (3:20:41) CLI &amp;amp; SDK - 2022/01/31 📓 (3:30:00) DNS - 2022/01/31 📓 (3:45:07) Route 53 - 2022/01/31 📓 (3:56:12) EC2 - 2022/01/26 (module1) 📓 (4:04:49) EC2 Pricing - 2022/01/26 (module1) 📓 (4:13:46) AMI - 2022/01/26 (module1) 📓 (4:23:36) Autoscaling Groups - 2022/01/29 (module2) 📓 (4:35:28) ELB - 2022/01/29 (module2) 📓 (5:49:50) EFS - 2022/01/27 (module1) 📓 (6:02:27) EBS - 2022/01/27 (module1) 📓 (7:00:11) RDS - 2022/01/30 (module2) 📓 (7:07:58) Redshift - 2022/01/30 (module2) 📓 (7:06:56) Aurora - 2022/01/30 (module2) 📓 (7:23:54) DynamoDB - 2022/01/30 (module2) 📓 (7:31:40) CloudFormation - 2022/01/26 📓 (7:51:56) CloudWatch - 2022/01/29 (module2) 📓 (8:06:30) CloudTrail - 2022/01/30 (module1) 📓 (8:18:16) Lambda - 2022/01/30 (module1) 📓 (8:28:30) SQS - 2022/01/29 (module1) 📓 (8:37:01) SNS - 2022/01/29 📓 (6:21:02) CloudFront - 2022/01/31 (module2) 📓 (8:42:21) ElastiCache - 2022/01/31 (module2) 📓 (8:43:03) High Availability (HA) - 2022/01/31 (module1) 📓 (9:02:49) Elastic Beanstalk - 2022/01/31 (module4) 📓 (9:12:41) API Gateway - 2022/01/31 (module3) 📓 (9:20:26) Kinesis - 2022/01/31 📓 (9:28:52) Storage Gateway(File Gateway) - 2022/01/31Reference :AWS Certified Solutions Architect - Associate 2020 (PASS THE EXAM!), Youtube, uploaded by freeCodeCamp.org, 12/24/2022,https://www.youtube.com/watch?v=Ia-UEYYR44sDumpI studied examtopic dump(574 questions) twice and tried to analyze and remember some keywords on each question. Some questions have the specific pattern like having same keywords. But I heard there are not similar questions on the real test. I felt I need to study and get used to many kinds of situation of efficient AWS solutions. And When I take a test, I exactly felt it and I did good study.For studying AWS SAA, I could know and understand flow of AWS and how to use many AWS solutions easily and efficiently.I totally can sure that AWS SAA will help our backend development skill improve." }, { "title": "[AWS Solution Architect] Additional Info", "url": "/posts/AWS-SAA02-1/", "categories": "Development, AWS", "tags": "aws, certification, eng", "date": "2022-02-08 16:06:00 +0900", "snippet": "CloudWatch alarm automated recovery of EC2 instance automatically stop / terminate / reboot / recover your EC2 instances. stop or terminate actions help you save money when you need longer an instance to be running. reboot and recover actions automatically reboot those instance or recover them onto new hardware if a system impairment occurs like hardware failure. CloudWatch VS CloudWatch Agent CloudWatch tracks CPU, Network, Disk usage CloudWatch Agent tracks Memory, disk swap, disk space utilization CloudTrail monitor API calls and actions governance, compliance, operational auditing, risk auditing logs calls between AWS services. turn on by default when you create your account but If you need more than 90 days, you need to create additional trail. CloudTrail can be set to deliver events to a CloudWatch log Trails are output to S3 don’t have GUI like event history To analyze a Trail, need Athena Management Events VS Data Events Management Events turned on by default Tracks management operations ex) AttachRolePolicy Data Events turned off by defual Tracks specific operations for specific AWS services ex) GetObject, PutObject, DeleteObject.. Elastic Beanstalk an easy-to-use service for deploying and scaling web applications and services developed with Java, . NET, PHP, Node. js, Python, Ruby, Go, and Docker on familiar servers such as Apache, Nginx, Passenger, and IIS. Auto Scaling monitoring application free. pay only for AWS resourcesRDS support also Oracle (DynamoDB does not support Oracle) always comfirms to the ACID system (Atomicity, Consistency, Isolation, and Durability)Aurora not serverlessFSx for Windows File Server using Active Directory files need to be shared internally have access to files via Microsoft Windows platform Keep the expense to a minimum : cost = 0 Request Pays on a S3 bucket making data available for third parties (the broader community) VPC endpoint within the same regionLambda resource policyKinesis Data Stream real-time EBS is not a target of Firehose (S3 is) Kinesis Data Stream + Firehose + S3 Lambda is not efficient for huge real-time dataDynamoDB a fully managed, multi-Region, multi-active DB that delivers reliable performance at any scale scalable, available,DynamaDB Streams provide audit logging and monitoring using CloudTrail (Database auditing)Redshift not DB refactoring &amp;amp; replatforming not minimize modifications Security groups VS Network ACL security group stateful : only inbound rule is okay for instance can’t deny (all is denid by default) Network ACL stateless : need both inbound and outbound rule for VPC subnet can deny " }, { "title": "[AWS Solution Architect] Storage Gateway", "url": "/posts/Storage-Gateway/", "categories": "Development, AWS", "tags": "aws, certification, eng", "date": "2022-01-31 16:06:00 +0900", "snippet": "Storage Gateway Introduction File Gateway Volume Gateway Stored Volume Cached Volume Tape Gateway (VTL) Cheat SheetReferenceAWS Certified Solutions Architect - Associate 2020 (PASS THE EXAM!), Youtube, uploaded by freeCodeCamp.org, 12/24/2019,https://www.youtube.com/watch?v=Ia-UEYYR44s" }, { "title": "[AWS Solution Architect] Kinesis", "url": "/posts/Kinesis/", "categories": "Development, AWS", "tags": "aws, certification, eng", "date": "2022-01-31 16:06:00 +0900", "snippet": "Kinesis Introduction Data Streams Firehose Video Streams Data Analytics Cheat SheetReferenceAWS Certified Solutions Architect - Associate 2020 (PASS THE EXAM!), Youtube, uploaded by freeCodeCamp.org, 12/24/2019,https://www.youtube.com/watch?v=Ia-UEYYR44s" }, { "title": "[AWS Solution Architect] API Gateway", "url": "/posts/API-Gateway/", "categories": "Development, AWS", "tags": "aws, certification, eng", "date": "2022-01-31 16:06:00 +0900", "snippet": "API Gateway Introduction Key Features Configuration Part Caching CORS Same Origin Policy Cheat SheetReferenceAWS Certified Solutions Architect - Associate 2020 (PASS THE EXAM!), Youtube, uploaded by freeCodeCamp.org, 12/24/2019,https://www.youtube.com/watch?v=Ia-UEYYR44s" }, { "title": "[AWS Solution Architect] Elastic BeanStalk", "url": "/posts/ElastiBeanStalk/", "categories": "Development, AWS", "tags": "aws, certification, eng", "date": "2022-01-31 15:21:00 +0900", "snippet": "Elastic BeanStalkReferenceAWS Certified Solutions Architect - Associate 2020 (PASS THE EXAM!), Youtube, uploaded by freeCodeCamp.org, 12/24/2019,https://www.youtube.com/watch?v=Ia-UEYYR44s" }, { "title": "[AWS Solution Architect] High Availability", "url": "/posts/High-Availability/", "categories": "Development, AWS", "tags": "aws, certification, eng", "date": "2022-01-31 14:44:00 +0900", "snippet": "High Availability ⭐️⭐️⭐️⭐️⭐️ the solution to remian available Scale up vs Scale outReferenceAWS Certified Solutions Architect - Associate 2020 (PASS THE EXAM!), Youtube, uploaded by freeCodeCamp.org, 12/24/2019,https://www.youtube.com/watch?v=Ia-UEYYR44s" }, { "title": "[AWS Solution Architect] ElastiCache", "url": "/posts/ElastiCache/", "categories": "Development, AWS", "tags": "aws, certification, eng", "date": "2022-01-31 14:32:00 +0900", "snippet": "ElastiCache Introduction Caching Comparison 같은 vpc안에 있는 리소스에만 접근 가능 걸리는 부하를 줄이기 위해서 반복되는 쿼리가 날려질 때, 매번 DB에서 가져오는 게 아니라, 가운데에 ElastiCache를 놓고 동일한 쿼리가 날려지는 경우, 이전에 동일한 쿼리의 캐시가 있으면 그 결과를 보내줌. 없으면 DB로 가서 결과를 가져옴. Memcached multi core를 가지고 있는 시스템에서 빠른 성능 제공 기능은 단촐한 대신, 속도와 안정성이 뛰어남 key-value만 지원 Redis 지속성 : reboot하더라도 데이터가 남아있을 수 있음 원자 조작 : 데이터를 업데이트 시킬 때 pub/sub 기능으로 데이터를 메세지로 보냄 클러스터 모드 : 여러개의 shard에 데이터가 중복되어서 저장되게 해서 high durability, performance Answer : b, c caching 일반적으로 RAM(Random Access Memory)과 같이 빠르게 액세스할 수 있는 하드웨어에 저장 캐시 계층을 구현할 때는 캐싱되는 데이터의 유효성을 이해하는 것이 중요합니다. 성공적인 캐시는 높은 적중률로 이어집니다. 즉, 가져온 데이터가 캐시에 존재합니다. 가져온 데이터가 캐시에 존재하지 않을 때 캐시 비적중이 발생합니다. TTL(Time To Live)과 같은 제어 항목을 적용하여 이에 따라 데이터를 만료되도록 할 수 있습니다. 다른 고려 사항은 캐시 환경이 고가용성이어야 할 필요가 있는지 여부인데, 이는 Redis와 같은 인 메모리 엔진을 사용하여 충족할 수 있습니다. 기본 위치에서 데이터를 캐싱하는 것과는 달리, 경우에 따라 인 메모리 계층을 독립형 데이터 스토리지 계층으로 사용할 수 있습니다. 이 시나리오에서는 인 메모리 엔진에 상주하는 데이터에 대해 적절한 RTO(복구 목표 시간 – 가동 중단으로부터 복구하는 데 걸리는 시간)와 RPO(목표 복구 시점 – 복구 시 캡처된 최종 시점 또는 트랜잭션)를 정의하여 이것이 적합한지를 파악하는 것이 중요합니다. 다른 인 메모리 엔진의 설계 전략 및 특성들을 적용하면 대부분의 RTO와 RPO 요구 사항을 충족시킬 수 있습니다. ** Reference : AWS https://aws.amazon.com/ko/caching/ReferenceAWS Certified Solutions Architect - Associate 2020 (PASS THE EXAM!), Youtube, uploaded by freeCodeCamp.org, 12/24/2019,https://www.youtube.com/watch?v=Ia-UEYYR44s" }, { "title": "[AWS Solution Architect] CloudFront", "url": "/posts/CloudFront/", "categories": "Development, AWS", "tags": "aws, certification, eng", "date": "2022-01-31 14:13:00 +0900", "snippet": "CloudFront Introduction Core Components Distributions Lambda@Edge Protection CloudFront Cheat Sheet presigned URL : for S3 signed URL : for CloudFront Create a Distribution Invalidation after updating files by AWS (01/24/2022) CloudFront edge-location : has cached copies Caching 오랜시간 걸리는 작업의 결과를 저장하는 것 for high performance origin storage에 access하는 것보다 더 빠르게 요청 가능 일반적으로 RAM(Random Access Memory)과 같이 빠르게 액세스할 수 있는 하드웨어에 저장 캐시 계층을 구현할 때는 캐싱되는 데이터의 유효성을 이해하는 것이 중요합니다. 성공적인 캐시는 높은 적중률로 이어집니다. 즉, 가져온 데이터가 캐시에 존재합니다. 가져온 데이터가 캐시에 존재하지 않을 때 캐시 비적중이 발생합니다. TTL(Time To Live)과 같은 제어 항목을 적용하여 이에 따라 데이터를 만료되도록 할 수 있습니다. 다른 고려 사항은 캐시 환경이 고가용성이어야 할 필요가 있는지 여부인데, 이는 Redis와 같은 인 메모리 엔진을 사용하여 충족할 수 있습니다. 기본 위치에서 데이터를 캐싱하는 것과는 달리, 경우에 따라 인 메모리 계층을 독립형 데이터 스토리지 계층으로 사용할 수 있습니다. 이 시나리오에서는 인 메모리 엔진에 상주하는 데이터에 대해 적절한 RTO(복구 목표 시간 – 가동 중단으로부터 복구하는 데 걸리는 시간)와 RPO(목표 복구 시점 – 복구 시 캡처된 최종 시점 또는 트랜잭션)를 정의하여 이것이 적합한지를 파악하는 것이 중요합니다. 다른 인 메모리 엔진의 설계 전략 및 특성들을 적용하면 대부분의 RTO와 RPO 요구 사항을 충족시킬 수 있습니다. ** Reference : AWS https://aws.amazon.com/ko/caching/ by AWS (01/24/2022) Answer : a, b, c d. 은행 계정 잔액 : consistency가 가장 중요하기 때문에 캐시 저장은 좋지 않음 (캐시는 업데이트가 늦어지기 때문에 은행 잔고는 늦게 갱신되면 안됨) ReferenceAWS Certified Solutions Architect - Associate 2020 (PASS THE EXAM!), Youtube, uploaded by freeCodeCamp.org, 12/24/2019,https://www.youtube.com/watch?v=Ia-UEYYR44s" }, { "title": "[AWS Solution Architect] DynamoDB", "url": "/posts/DynamoDB/", "categories": "Development, AWS", "tags": "aws, certification, eng", "date": "2022-01-31 00:07:00 +0900", "snippet": "DynamoDB Introduction Table Structure Consistent Reads ⭐️ DynamoDB Cheat Sheet ⭐️ ⭐️ ⭐️ 여러 리전의, 테이블 간, 비동기 복제 : 여러 region의 table을 서로 동기화시킬 수 있음 (비동기로) from AWS (01/24/2022) Reading / Writing 용량을 각각 돈을 주고 구입함 요구 사항에 따라 용량을 각각 provision해서 사용 가능 1번 시점 : 데이터가 저장됨 2번 시점 : 데이터 목록이 나오는 시점 Eventually consistent read (default) : 1번 시점, 2번 시점이 1초정도 늦게 동기화됨, 더 저렴함 use case : 싱크가 중요하지 않은 경우 충분히 잘 사용 가능 Strongly consistent read : 1번 시점, 2번 시점이 거의 비슷 use case : 은행! 은행간 거래에서 물건값 결제 등 잔고에 대해서 사용 eventually consistent read를 사용하면 2번 이상의 transaction을 발생시킬수도 있어서 두번 돈이 나갈 수 있음 from AWS (01/24/2022) Key point : Unrelational database Answer : D Redshift : rds -&amp;gt; X RDS -&amp;gt; X Glacier -&amp;gt; no database from AWS (01/24/2022)ReferenceAWS Certified Solutions Architect - Associate 2020 (PASS THE EXAM!), Youtube, uploaded by freeCodeCamp.org, 12/24/2019,https://www.youtube.com/watch?v=Ia-UEYYR44s" }, { "title": "[AWS Solution Architect] Redshift", "url": "/posts/Redshift/", "categories": "Development, AWS", "tags": "aws, certification, eng", "date": "2022-01-30 23:55:00 +0900", "snippet": "Redshiftfrom AWS (01/24/2022) Key point : 4TB의 초기 storage capacity, 관계형 데이터베이스, 매일 10GB씩 증가, read replica Answer : Aurora 자동으로 storage capacity가 increase dynamoDB : no rds / noSQL S3 : object storage Redshift : data warehouse / no read replica / no automatic scalable ReferenceAWS Certified Solutions Architect - Associate 2020 (PASS THE EXAM!), Youtube, uploaded by freeCodeCamp.org, 12/24/2019,https://www.youtube.com/watch?v=Ia-UEYYR44s" }, { "title": "[AWS Solution Architect] Aurora", "url": "/posts/Aurora/", "categories": "Development, AWS", "tags": "aws, certification, eng", "date": "2022-01-30 23:52:00 +0900", "snippet": "Aurora Introduction Scaling Availability Fault Tolerance &amp;amp; Durability Replicas Serverless Aurora Cheat Sheet ⭐️ ⭐️ ⭐️ from AWS (01/24/2022) Key point : 4TB의 초기 storage capacity, 관계형 데이터베이스, 매일 10GB씩 증가, read replica Answer : Aurora 자동으로 storage capacity가 increase dynamoDB : not rds / NoSQL S3 : object storage Redshift : data warehouse / no read replica / not automatic scalable ReferenceAWS Certified Solutions Architect - Associate 2020 (PASS THE EXAM!), Youtube, uploaded by freeCodeCamp.org, 12/24/2019,https://www.youtube.com/watch?v=Ia-UEYYR44s" }, { "title": "[AWS Solution Architect] RDS (Relational Database Service)", "url": "/posts/RDS/", "categories": "Development, AWS", "tags": "aws, certification, eng", "date": "2022-01-30 17:00:00 +0900", "snippet": "RDS (Relational Database Service) Introduction Encryption Backups Restoring Backups Multi-AZ Read Replicas Multi-AZ vs Read Replicas RDS Cheat Sheet multi AZ O : master-standby 2개의 AZ에 1개는 master, 1개는 복제본 Read replica async로 데이터가 master가 싱크되는 read replica를 만들 수 있음 db 종류에 따라 몇개까지 read replica를 만들 수 있는지 결정됨 maria db, postgre : ~ 5 aurora : ~ 15 읽기 로드를 offload하면서 성능 up 장애가 발생해도 for high durability, read replica를 master로 승격시켜서 빠르게 복구 가능 그때그때 throuhput에 따라 수평적인 확장 가능 (select문) from AWS (01/30/2022) Answer : a, d b. Sharding: 직접 디비를 ec2에 install해야 구현 가능 Sharding : 같은 테이블 스키마를 가진 데이터를 다수의 데이터베이스에 분산하여 저장하는 방법 reference https://nesoy.github.io/articles/2018-05/Database-Shard c. simple get/put request&amp;amp;query : KVS(key-value store)형태인 dynamoDB에 더 적합 e. rdbms 사용자 정의: 직접 디비를 ec2에 install해야 효율적 ReferenceAWS Certified Solutions Architect - Associate 2020 (PASS THE EXAM!), Youtube, uploaded by freeCodeCamp.org, 12/24/2019,https://www.youtube.com/watch?v=Ia-UEYYR44s" }, { "title": "[AWS Solution Architect] CloudTrail", "url": "/posts/CloudTrail/", "categories": "Development, AWS", "tags": "aws, certification, eng", "date": "2022-01-30 15:42:00 +0900", "snippet": "CloudTrail Introduction Event History Trail Options CloudTrail to CloudWatch CloudTrail Cheat Sheetfrom AWS (01/24/2022)Follow Along CloudTrail Overview Create a Trail CloudTrail to CloudWatch Athena ReferenceAWS Certified Solutions Architect - Associate 2020 (PASS THE EXAM!), Youtube, uploaded by freeCodeCamp.org, 12/24/2019,https://www.youtube.com/watch?v=Ia-UEYYR44s" }, { "title": "[AWS Solution Architect] Lambda", "url": "/posts/Lambda/", "categories": "Development, AWS", "tags": "aws, certification, eng", "date": "2022-01-30 14:35:00 +0900", "snippet": "Lambda Introduction Use Cases Triggers Pricing Interface Defaults and Limits Cold Starts Lambda Cheat Sheet 완전 관리형 컴퓨팅 서비스 : 코드를 실행하기 위해 필요한 컴퓨팅 resource를 전부 생성해줌 logging, monitoring, 확장, 병렬처리 등 스케쥴러기반, 상태 비저장 코드 Answer : CloudWatchReferenceAWS Certified Solutions Architect - Associate 2020 (PASS THE EXAM!), Youtube, uploaded by freeCodeCamp.org, 12/24/2019,https://www.youtube.com/watch?v=Ia-UEYYR44s" }, { "title": "[AWS Solution Architect] SNS (Simple Notification Service)", "url": "/posts/SNS/", "categories": "Development, AWS", "tags": "aws, certification, eng", "date": "2022-01-29 23:42:00 +0900", "snippet": "SNS (Simple Notification Service) Introduction Topics Subscriptions Application As Subscriber Cheat Sheet Webhook : 서버에서 특정 이벤트가 발생했을 때 타 서비스나 응용프로그램으로 알림을 보내는 기능 webhook provider은 특정 이벤트가 발생하면 클라이언트로 HTTP POST해서, callback URL로 해당 이벤트 정보를 보냅니다. Reference : https://leffept.tistory.com/329 ReferenceAWS Certified Solutions Architect - Associate 2020 (PASS THE EXAM!), Youtube, uploaded by freeCodeCamp.org, 12/24/2019,https://www.youtube.com/watch?v=Ia-UEYYR44s" }, { "title": "[AWS Solution Architect] SQS (Simple Queue Service)", "url": "/posts/SQS/", "categories": "Development, AWS", "tags": "aws, certification, eng", "date": "2022-01-29 23:28:00 +0900", "snippet": "SQS (Simple Queue Service) Introduction Use Case Limits &amp;amp; Retention Queue Types Visibility Timeout Short vs Long Polling SQS Cheat SheetReferenceAWS Certified Solutions Architect - Associate 2020 (PASS THE EXAM!), Youtube, uploaded by freeCodeCamp.org, 12/24/2019,https://www.youtube.com/watch?v=Ia-UEYYR44s" }, { "title": "[AWS Solution Architect] Cloud watch", "url": "/posts/Cloudwatch/", "categories": "Development, AWS", "tags": "aws, certification, eng", "date": "2022-01-29 15:50:00 +0900", "snippet": "Cloud watch Introduction CloudWatch Logs CloudWatch Metrics CloudWatch Events Custom Metrics CloudWatch Alarms CloudWatch Dashboards Availability Agent &amp;amp; Host Level Metrics CloudWatch Cheat SheetReferenceAWS Certified Solutions Architect - Associate 2020 (PASS THE EXAM!), Youtube, uploaded by freeCodeCamp.org, 12/24/2019,https://www.youtube.com/watch?v=Ia-UEYYR44s" }, { "title": "[AWS Solution Architect] ASG (Auto Scaling Groups)", "url": "/posts/ASG/", "categories": "Development, AWS", "tags": "aws, certification, eng", "date": "2022-01-29 14:06:00 +0900", "snippet": "ASG (Auto Scaling Groups) Introduction Capacity Settings Health Check Replacements Scaling Policies Target tracking scaling policy Simple scaling policy &amp;amp; Scaling policy with steps Scaling with SQS ELB Integration Use Case Launch Configuration Autoscaling Groups Cheat Sheet from AWS (01/24/2022) Key point : 요청의 90%, 성능SLA, 4개의 인스턴스로 요청을 분산, 성능 요구 사항을 충족, 고가용성 (+) 가용 영역에 도달할 수 없는 경우 (= 한개의 가용영역이 다운됬을 경우 -&amp;gt; 영문 파악 필요) a, b : 단일 AZ는 전체 서비스가 다 다운되어서 not correct recommend using multi AZ for high availability, scalability 예외 케이스 : cluster network service를 만들 때만 단일 AZ 사용을 추천 c : 4개의 서버가 2개의 AZ에 각각 있는 건지, 분산되어 있는 건지 영문에서 구체적으로 확인할 필요가 있음 각각이라면, 나머지 AZ에 4개의 서버가 있기 때문에 만족 d : 8개 too much** SLA : Service Level AgreementAmazon EC2 Auto Scaling Scale up, down : 수직적 조징 the size of instance, the count of cpu core, memory, etc. Scale in, out : 수평적 조정 the count of instances -&amp;gt; auto scaling (수평적 조정을 위한 기능) multi AZ에 띄울 수 있음 ELB 와 통합해서 사용 가능 from AWS (01/24/2022) Amazon EC2 Auto Scaling 각각의 서비스 별로 scale up, down 가능 EC2 cpu utilization / memory utilization / provisioned throughput like DynamoDB a : ELB c : cloudwatch d : SNS Answer : B, E, F Amazon EC2 Auto Scaling Amazon EC2 Instance를 추가, 종료하여 변화하는 상황에 대응합니다. 지정된 AMI에서 Instance를 시작합니다. 실행 Amazon EC2 Instance의 최소 수를 적용합니다. Cloudwatch Role : 리소스 상태를 파악 network : throughput (네트워크에 데이터가 얼마나 왔다갔다 하고 있는가) 사용자 지정 지표 : application 내부에서 cloud watch 쪽으로, 모니터링하고자 하는, 기본적으로 hiperbizer에서 수집할 수 있는 이외의 값도 보내줌 (웹서버에서는 내부 session 개수, 사용자수, etc / ec2에서는 memory 사용량, etc) Key point : 8개의 Amazon EC2 instance, 트래픽이 일시적으로 급증, 평소 2개의 EC2 Instance가 필요, 가장 비용 효과적인 방법 Answer :　C a, d : 수치(cpu or memory utilization)를 보면서 확장하는 것은 잘 작동하지 않을 수도 있음 ex. 이미 cpu의 사용도가 초과한 상태에서 장애가 발생한 다음에 확장될 수 있음 b : 가장 비용 효과적이지 않음ReferenceAWS Certified Solutions Architect - Associate 2020 (PASS THE EXAM!), Youtube, uploaded by freeCodeCamp.org, 12/24/2019,https://www.youtube.com/watch?v=Ia-UEYYR44s" }, { "title": "[AWS Solution Architect] ELB (Elastic Load Balancer)", "url": "/posts/ELB/", "categories": "Development, AWS", "tags": "aws, certification, eng", "date": "2022-01-29 13:14:00 +0900", "snippet": "ELB (Elastic Load Balancer) Introduction Rules of Traffic Application Load Balancer (ALB) Network Load Balancer (NLB) Classic Load Balancer (CLB) Sticky Sessions X-Forwarded-For Header Health Checks Cross-Zone Load Balancing Request Routing from AWS (01/24/2022) key point : 소결합 = 결합 해제 결합 해제 와 high availability는 연계되어있음 from AWS (01/24/2022) 내결함성이 있다 : 장애가 발생하더라도 전체 시스템은 장애가 발생하지 않음 (느슨한 결합) 2-tier architecture 웹서버가 앱서버를 직접적으로 호출하면 양쪽 전체에 장애가 확산될 수 있음 (밀결합된 것) 앱서버에 장애가 발생하면 격리시키고, 웹서버의 정상적인 traffic들을 load balancer가 분산시킴 ELB가 multi AZ에 분산시켜줌 AZ에 있는 용량을 자동으로 확장, 축소 가능한 것 = auto scaling 확장, 축소할 때 상태를 볼 수 있게 하는 것 = cloud watch 모니터링뿐 아니라 임계점을 걸어놓고 초과했을 경우 auto scaling policy로 trigger할 수 있는 것 = cloud watch alarm Flow 단일 AZ에서 장애가 발생하면? ELB가 Health Check를 통해 파악, stop traffic AZ가 사용이 불가하게 되어도 ELB에서 그 AZ로 보내는 통로를 봉쇄함 인스턴스 개수를 늘리도록 cloud watch alarm이 울림 Answer : C trigger : 어느 특정한 동작에 반응해 자동으로 필요한 동작을 실행하는 것ReferenceAWS Certified Solutions Architect - Associate 2020 (PASS THE EXAM!), Youtube, uploaded by freeCodeCamp.org, 12/24/2019,https://www.youtube.com/watch?v=Ia-UEYYR44s" }, { "title": "[AWS Solution Architect] EFS (Elastic File System)", "url": "/posts/EFS/", "categories": "Development, AWS", "tags": "aws, certification, eng", "date": "2022-01-27 16:33:00 +0900", "snippet": "EFS (Elastic File System)[ Amazon EFS with Standard storage classes ] multiple EC2 instances accessing an Amazon EFS file system that is configured with Standard storage classes from multiple Availability Zones in an AWS Region.[ Amazon EFS with One Zone storage classes ] multiple EC2 instances that are accessing an Amazon EFS file system. This file system is configured with One Zone storage from multiple Availability Zones in an AWS Region.referencehttps://docs.aws.amazon.com/efs/latest/ug/how-it-works.html 티어를 나누었을 때 데이터를 공유할 수 있는 방법 (파일 공유할 때 많이 사용) region service -&amp;gt; region level로 존재 네트워크 인터페이스를 생성해서 EFS에 접근 네트워크 인터페이스를 mount 대상으로 해서 자기 AZ에 있는 것에 접근 그래서 NAS에 파일을 공유 single instance에 데이터가 저장되는 것이 아니라서(multi instance) high durability 용량 확장 가능 (쓰는 만큼 자동으로, no need of 용량에 대한 provisioning)from AWS (01/24/2022)Mount target : where the volume is located in the file system tree and where you read and write files to after you mount the volume. (an NFS endpoint that lives in a VCN subnet of your choice and provides network access for file systems.) The mount target provides the IP address or DNS name that is used together with a unique export path to mount the file system.Mounting a file : a process by which the operating system makes files and directories on a storage device(such as hard drive, CD-ROM, or network share) available for users to access via the computer’s file system. NFS (Network File System) 네트워크에 파일을 저장하는 메커니즘 컴퓨터 사용자가 원격 컴퓨터에 있는 파일을 마치 자신의 컴퓨터에 있는 것처럼 검색하고, 마음대로 저장하거나 수정하도록 해주는 클라이언트/서버형 응용프로그램 사용자가 원격 컴퓨터에 있는 파일 및 디렉토리에 액세스할 수 있고 해당 파일 및 디렉토리가 로컬에 있는 것처럼 처리하도록 허용하는 분산 파일 시스템 사용자 시스템에는 NFS client, 원격 컴퓨터에는 NFS server가 있어야 함 예를 들어, 사용자는 운영 체제 명령을 사용하여 원격 파일 및 디렉토리에 대한 파일 속성을 작성, 제거, 읽기, 쓰기, 설정할 수 있습니다. referencehttps://www.ibm.com/docs/ko/aix/7.2?topic=management-network-file-systemNAS (Network Attached Storage): 네트워크에 연결된 storage - 권한이 있는 네트워크 사용자와 여러 클라이언트가 중앙 집중화된 위치의 데이터를 저장하고 검색할 수 있게 합니다.Follow Along Make EFS Make Instance Number of instances : 2 No subnet : to access from everywhere Create an IAM role Make new security group Check status Go to security groups Create inbound rules for NFS Check status Start session managerReferenceAWS Certified Solutions Architect - Associate 2020 (PASS THE EXAM!), Youtube, uploaded by freeCodeCamp.org, 12/24/2019,https://www.youtube.com/watch?v=Ia-UEYYR44s" }, { "title": "[AWS Solution Architect] EBS (Elastic Block Store)", "url": "/posts/EBS/", "categories": "Development, AWS", "tags": "aws, certification, eng", "date": "2022-01-27 15:05:00 +0900", "snippet": "EBS (Elastic Block Store) free tier : almost EBS (root device) Volumes always exists in the same AZ as the instance. Instance와 비독립적 -&amp;gt; Instance에서 EBS Volume을 분리 + 다른 Instance와 연결 사용 가능 (except for root device) 복수의 하드웨어에 저장되어서 high durability (&amp;gt; Instance Store)-&amp;gt; 복수의 곳에 저장되는 것은 S3 (= the highest durability) from AWS (01/24/2022)- Key point : 데이터 베이스, block storage, backup, 가장 저렴한 옵션- Answer : B- Key point : 서버를 호스팅, 대량의 로그를 처리- Answer : Dfrom AWS (01/24/2022)ReferenceAWS Certified Solutions Architect - Associate 2020 (PASS THE EXAM!), Youtube, uploaded by freeCodeCamp.org, 12/24/2022,https://www.youtube.com/watch?v=Ia-UEYYR44s" }, { "title": "[AWS Solution Architect] CloudFormation", "url": "/posts/CloudFormation/", "categories": "Development, AWS", "tags": "aws, certification, eng", "date": "2022-01-26 16:27:00 +0900", "snippet": "Cloud Formationby AWSThe copyright of all material here is on this videohttps://www.youtube.com/watch?v=Ia-UEYYR44sThis post is just for studying AWS SAA." }, { "title": "[AWS Solution Architect] EC2 Pricing", "url": "/posts/EC2-Pricing/", "categories": "Development, AWS", "tags": "aws, certification, eng", "date": "2022-01-26 15:41:00 +0900", "snippet": "EC2 Pricing Discount All Upfront &amp;gt; Partial Upfront &amp;gt; No Upfront All Upfront Pay full amount for the reservation term in one single payment Partial Upfront: Pay portion of amount for part of the reservation term in an upfront payment and pay the remaining in installments every month for the duration of the term. No Upfront: Pay for the reservation in installments throughout the term’s duration every month. This payment offers the lowest savings rate.https://www.botmetric.com/blog/aws-ec2-reserved-instances-choosing-right-one-fits/https://aws.amazon.com/ko/blogs/korea/simplified-reserved-instances/https://aws-diary.tistory.com/84https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/dedicated-hosts-overview.html An important difference between a Dedicated Host and a Dedicated instance Dedicate Host cost a physical server(host) with EC2 instance capacity fully dedicated to your use. it gives you additional visibility and control over how instances are placed on a physical server, and you can consistently deploy your instances to the same physical server over time. 인스턴스 실행을 전담하는 실제 호스트 비용을 지불하며, 기존의 소켓, 코어 또는 VM 소프트웨어별 라이선스를 가져와 비용을 절감합니다. Dedicate Instance 단일 테넌트 하드웨어에서 실행되는 인스턴스 비용을 시간 단위로 지불합니다 Support for multiple instance sizes on the same Dedicated Host is available for the following instance families: T3, A1, C5, M5, R5, C5n, R5n, and M5n. Other instance families support only a single instance size on the same Dedicated Host. https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/concepts.htmlThe copyright of all material here is on this videohttps://www.youtube.com/watch?v=Ia-UEYYR44sThis post is just for studying AWS SAA." }, { "title": "[AWS Solution Architect] AMI (Amazon Machine Image)", "url": "/posts/AMI/", "categories": "Development, AWS", "tags": "aws, certification, eng", "date": "2022-01-26 15:41:00 +0900", "snippet": "Amazon Machine Image (AMI)by AWSCloudFormationhttps://uzzing.github.io/posts/CloudFormation/The copyright of all material here is on this videohttps://www.youtube.com/watch?v=Ia-UEYYR44sThis post is just for studying AWS SAA." }, { "title": "[AWS Solution Architect] EC2", "url": "/posts/EC2/", "categories": "Development, AWS", "tags": "aws, certification, eng", "date": "2022-01-26 15:02:00 +0900", "snippet": "EC2 Elastic Compute Cloud a highly configurable server resizable compute capacityFunctions Instance AML (Amazon Machine Image) Instance types Key pair Instance store volume Amazon EBS (Elastic Block Store) Region &amp;amp; AZ (Availability Zone) Security group EIP (Elastic IP) Tag VPC (Virtual Private Clouds)https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/concepts.htmlhttps://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/placement-groups.htmlhttps://velog.io/@swhan9404/EC2-개념정리The copyright of all material here is on this videohttps://www.youtube.com/watch?v=Ia-UEYYR44sThis post is just for studying AWS SAA." }, { "title": "[AWS Solution Architect] Block Storage vs Object Storage vs File Storage", "url": "/posts/BlockStorage-ObjectStorage-FileStorage/", "categories": "Development, AWS", "tags": "aws, certification, eng", "date": "2022-01-26 14:36:00 +0900", "snippet": "서로 다른 방식으로 데이터를 저장하고 검색Block storage SAN(Storage Area Network) 또는 클라우드 기반 스토리지 환경에 데이터 파일을 저장하는 데 사용되는 기술 빠르고 효율적이며 안정적인 데이터 전송이 요구되는 컴퓨팅 상황의 경우 블록 스토리지를 선호 데이터를 블록으로 분할한 후, 해당 블록을 각각 고유 ID를 지닌 개별 조각으로 저장 사용자 환경으로부터 데이터를 디커플링함으로써 해당 데이터가 다수의 환경에서 분산될 수 있도록 허용합니다. 이렇게 되면 데이터에 대한 다수의 경로가 만들어지며, 사용자는 이를 통해 데이터를 빠르게 검색할 수 있습니다. VMFS를 저장하기 위한 블록 기반 스토리지 볼륨을 손쉽게 만들어서 이를 포맷할 수 있습니다. 그리고 물리적 서버가 해당 블록에 연결됨으로써 다수의 가상 머신을 구축할 수 있습니다. 게다가, 블록 기반 볼륨을 구축하고 운영체제를 설치한 후 해당 볼륨에 연결함으로써 사용자는 이러한 기본 운영체제를 사용하여 파일을 공유할 수 있습니다.Object Storage 데이터 파일을 오브젝트라고 하는 조각들로 분할, 단일 저장소에 해당 오브젝트를 저장. 다수의 네트워킹 시스템 간에 분산될 수 있습니다. 실제로 애플리케이션에서 모든 오브젝트를 관리하므로, 기존의 파일 시스템은 더 이상 필요가 없습니다. 각 오브젝트는 애플리케이션이 오브젝트 식별에 사용하는 고유 ID를 수신합니다. 그리고 각 오브젝트는 오브젝트에 저장된 파일에 대한 정보인 메타데이터를 저장합니다.*** Difference of block storage and object storage 각 스토리지가 메타데이터를 처리하는 방법 block storage 메타데이터가 기본 파일 속성으로 제한됨 파일을 변경하면 새로운 오브젝트가 생성되어서 자주 변경되지 않는 정적 파일에 가장 적합 object storage 오브젝트에 저장된 데이터 파일에 관한 추가적인 상세 정보를 포함하도록 메타데이터를 사용자 정의할 수 있습니다 File Storage NAS(Network Attached Storage) 기술과 밀접한 관련 기존의 네트워크 파일 시스템과 동일한 개념을 사용하여 사용자와 애플리케이션에 스토리지를 제공 사용자나 애플리케이션은 디렉토리 트리, 폴더 및 개별 파일을 통해 데이터를 수신 구성하기는 매우 쉽지만, 데이터에 대한 액세스가 데이터에 대한 단일 경로로 제한됨으로 인해 블록 스토리지나 오브젝트 스토리지에 비해 성능이 떨어질 수 있습니다 Windows용 NTFS(New Technology File System) 또는 Linux용 NFS(Network File System) 등의 공통 파일 레벨 프로토콜에서만 작동됩니다. 이로 인해 서로 다른 시스템 간에 가용성이 제한될 수 있음https://www.ibm.com/kr-ko/cloud/learn/block-storage" }, { "title": "[AWS Solution Architect] IAM (Identity Access Management)", "url": "/posts/IAM/", "categories": "Development, AWS", "tags": "aws, certification, eng", "date": "2022-01-18 16:39:00 +0900", "snippet": "IAM (Identity Access Management) Manages access of AWS users and resources. IAM Core ComponentsUse case Generally, mix and match of it.Type PoliciesManaged VS Customer VS Inline Policy Managed Policies most commonly permissions you might need. ex. AmazonEC2FullAcess Customer Managed Policies Inline Policies you can’t apply them to more than one identity or resource. Policies version if this changes, then that means all the rules here could change. SO this doesn’t change very often, if it did make changes, it probably would be minor. Statement we have an array and multiple. But you don’t want to get multiples, you just get rid of the square brackets there. you could have a single policy element there. Sid statement identifier Effect can be either allow or deny. Action the actual actions the policy will allow or deny. Effect: Deny -&amp;gt; deny policy, we’re denying access all to s3 for a specific user (Principal) Principal : conditional fieldPassword PolicyProgrammatic Access Keys when you create a user, you say it’s allowed to have programmatic access.it’s going to then create an access key for you which is an ID and a secret access key. as soon as we add a second one, that grey button for creating access ky will vanish.if we want more we would either have to we’d have to remove keys. MFA(Multi-factor Authentication)there’s a caveat to it where the user has to be the one that turns it on. Because when you turn it on, you have to connect it to a device. And your administrator is not going to have the device notes on the user to do.Administrator can do restrict access to resources only to people that are using MFA.So you can’t make the user account itself have MFA. But you can definitely restrict access to API calls.Words vanish : 사라지다. The copyright of all material here is on this videohttps://www.youtube.com/watch?v=Ia-UEYYR44sThis post is just for studying AWS SAA." }, { "title": "[AWS Solution Architect] Follow Along - VPC Clean up", "url": "/posts/Follow-Along-VPC-Cleanup/", "categories": "Development, AWS", "tags": "aws, certification, eng", "date": "2022-01-17 16:39:00 +0900", "snippet": "VPC Clean up terminate instances delete endpoint for s3 release elastic IPs (be created when we created NAT gateways, Ips not being utilized cost use money) double check NAT gateway, make user nothing is running under there delete subnets delete route tables detach internet gateways delete VPCWords free credits incur cost : 비용을 발생하다 The copyright of all material here is on this videohttps://www.youtube.com/watch?v=Ia-UEYYR44sThis post is just for studying AWS SAA." }, { "title": "[AWS Solution Architect] Follow Along - VPC Flow logs", "url": "/posts/Follow-Along-VPC-Flow-logs/", "categories": "Development, AWS", "tags": "aws, certification, eng", "date": "2022-01-17 16:23:00 +0900", "snippet": "VPC Flow logsInstructionhttps://uzzing.github.io/posts/VPC-Flow-Logs/ Flow logs will track all the traffic that is going through your VPC Create flow log we can have it to accept, reject or all. it can either be delivered to cloudwatch logs or s3 cloud watch is very good destination for that. in order to deliver that, we’re going to need a destination log group. go to cloudwatch and create a new cloudwatch log we need a IAM role to publish to cloud watch logs. under our VPC, we can see that we have flow logs enabled, we had just created that a log there just took public instances’s IP addresses and test enter enter enter source, destination ?????The copyright of all material here is on this videohttps://www.youtube.com/watch?v=Ia-UEYYR44sThis post is just for studying AWS SAA." }, { "title": "[AWS Solution Architect] Follow Along - NAT Gateway, VPC Endpoints", "url": "/posts/Follow-Along-NAT-Gateway-VPC-Endpoints/", "categories": "Development, AWS", "tags": "aws, certification, eng", "date": "2022-01-17 15:56:00 +0900", "snippet": "NAT Gateway (Network Address Translation)Instructionhttps://uzzing.github.io/posts/NAT/ ⭐️ If you have a private networking need to help gain outbound access to the internet, you need to use a NAT gateway to rempat the Private IPs. ⭐️ NAT Gateways is a managed service which launches redundant instances within the selected AZ. ⭐️ You have to launch a NAT gateway per AZ NAT gateway doesn’t do launch them automatically across other AZs for you. Follow alongthe way we’re going to get a route to the internet is by creating a NAT instacne or a NAT gateway.Generally you wanna use a NAT gateway.If you were trying to save mondy, you can definitely save money by having to manage a NAT instance by itself.But we’re gonna learn how to do NAT gateway, let’s do it! switch over to VPC because that’s where the NAT gateway is. launch a NAT gateway in a public subnet NAT gateway do cost money, but they’re not terribly expensive. Create NAT gateway select public one subnet Create Elastic IP Edit route table test we have one inbound traffic, but we definitely want outbound, because we wold probably want to update packages on our EC2 instance. if we did ‘sudo yum update’, we wouldn’t be able to do this without a outbound connection. it’s a way of getting access to the internet, only for the thing that we need for outbound connections.VPC Endpoints how we can set an outbound connection to the internet. let’s talk about how we could access other AWS services via our private EC2 instances here. so s3 would be a very common one to utilize. Instructionshttps://uzzing.github.io/posts/VPC-Endpoints/ switch over to s3 we get a IAM role permissions to access that stuff there. aws s3 ls we can definitely see that we have a way of accessing s3 via the CLI Q. what it happen when we remove that NAT gateway, would we still be able to access s3? A. No. it no longer has anyway to access s3. So the way to use EC2 instance through CLI is it’s going to go out to the internet and come back into AWS network to access s3. since there’s no outbound way of connection to the internet, there’s no way we’re gonna be able to connect to s3. Q. why doesn’t you just keep the traffic within the network? A. because we’re already on EC2 within AWS network and s3 is with Eva’s network. that bring us to endpoints which is how we can create our own private tunnel within AWS network, we don’t have to leave up the internet. we can connect to s3 without having outbound connect. Create a new Endpoints select VPC select S3 selete a route table associated with private subnet result Words switch over to N…..???!!!The copyright of all material here is on this video https://www.youtube.com/watch?v=Ia-UEYYR44sThis post is just for studying AWS SAA." }, { "title": "[AWS Solution Architect] Follow Along - Security Groups, NACL and Bastion", "url": "/posts/Follow-Along-Security-Groups-NACL-Bastion/", "categories": "Development, AWS", "tags": "aws, certification, eng", "date": "2022-01-17 14:54:00 +0900", "snippet": "Security Groups there’s IPv4 DNS and the public IP address for the public there’s nothing for the private Let’s check our website is working case1 public instance copy the public IP address or we can take the DNS when it doesn’t matter case2 private instance there’s nothing on the public ID address we can use Private IPs there’s no one of accessing that website running on the private one. the reason why we were able to access the instance, publicly was that in our security group, we had an inbound rule on port 80. Port 80 is what websites run on. when we’re accessing through the web browser, we’re allowing my IP here. that’s why I was allowed to access it. let’s change my IP I have a VPN it’s a service you can buy a lot of people use it so that they can watch Netflix in other regions. I have a VPN from brazil shortly once it connects. -&amp;gt; it shouldn’t work, it’s hanging because I’m not using that IP. -&amp;gt; that’s how security groups work for inbound rules. for outbound rules, that’s traffic going out to the internet. it’s almost always open like this. NACL (Network ACL) we would like to show off how NACLs work compared to security groups. security groups, by default, only can allow things so everything is denied. you’re adding allow rules only you can’t add an explicit deny rule. ⭐️ NACLs are very useful, is that you can use it to block a very specific IP addresses or IP ranges. ⭐️ ⭐️ security groups are associated with the actual EC2 instance ⭐️ NACLs are associated with the subnets. Q. how do we figure out the NACLs? A. in order to block individual IP address, we have to determine what subnet it runs in. check grab that IP address and paste it. it works! Bastion how do we actually get access to the private subnet. we have our private EC2 instance we don’t have an public IP address on it there’s no direct way to gain access to it. So we can’t just easily SSH into it.-&amp;gt; this is where we’re gonna need a bastion launch new instance go to marketplace and type in Bastion. use Guacamole Bastion Host there’s an associated cost they do have a trial version (you can get it without paying anything for it) we’re gonna need a small, this one doesn’t allow you to go into micros. (There’s an assciated cost) Configure instance detail select the network as private one. select the public subnet. create a new IAM role and set it you need to give it some access so that it can auto discover instances. it’s gonna give us permissions to cloud watch and STS EC2ReadOnlyAccess &amp;amp; Guaws result Grap the public DNS and paste it hit hide advanced hit allow on the top left login default admin id : guacadmin password : the name of the instance ID now it has auto discovered the instances which are in the VPC that is launched connect it and login, make the shell here login : that’s the way to gain access to the private instance. before doing something, I’m gonna configure something that’s why we use Bastions (you can see those in setup ) it’s a hardened instance. it does allow you to authenticate via multiple methods so you can enable multi factor authentication to use this it also has the ability to do screen recordings you can do show what people are up to we can also use a sessions manager which does a lot of this for us with the exception of screen recording within the AWS. Words explicit : 明示的 grab it here : copy itThe copyright of all material here is on this video https://www.youtube.com/watch?v=Ia-UEYYR44sThis post is just for studying AWS SAA." }, { "title": "[AWS Solution Architect] Follow Along - Launch an EC2 Instance", "url": "/posts/Launch-EC2/", "categories": "Development, AWS", "tags": "aws, certification, eng", "date": "2022-01-15 15:17:00 +0900", "snippet": "Launch an EC2 Instance for our public subnet choose t2 micro set network and subnet create new IAM role to give it access to both SSM for sessions manager and we have access to s3. advanced details - User data Create security group Review launch Done for private subnet the difference is only set to SSH and the file uploaded. The copyright of all material here is on this video https://www.youtube.com/watch?v=Ia-UEYYR44sThis post is just for studying AWS SAA." }, { "title": "[AWS Solution Architect] Follow Along - Create VPC, IGW, Route Tables and Subnets", "url": "/posts/Follow-Along-VPC-Core-Componenets/", "categories": "Development, AWS", "tags": "aws, certification, eng", "date": "2022-01-15 14:17:00 +0900", "snippet": "Create VPC and Core Components(IGW, Route table, Subnets) IPv4 CIDR 10.0.0.0 is commonly chosen one. this is saying how many IP addresses you want to allocate. IPv6 CIDR block it’s supported on AWS. it’s the future of our IP protocol. so it’s definitely something you might want to turn on. just be prepared for the future there Tenancy dedicated host is quite expensive we don’t have any DNS hostnames we definitely want to turn that on. if we launch EC2 instance, it’s not going to get a DNS hostname, that’s just like a URL. Create internet gateways internet gateways can only be attached to a very specific VPC it’s a one-to-one relationship but that still doesn’t mean that things within our network can reach the internet because we have to add a route to our route table see that there already is a route table associated with our VPC because it did create us a default route table But let’s create a route tableYou can see by default, it has the full scope of our local network here. Let change this one to our main. main route table is whenever what is going to be used by default. we’re gonna add a route for the internet gateway. 0.0.0.0/0 which means let’s take anything from anywhere. select internet gateway save now we have a way for our subnets to reach the internet. it’s time to create some subnets. these are default ones created with your default VPC there’s exactly one for every availability zone within each region my region is seoul, which has 4 public subnets. check the auto assign to Yes if this is set to Yes, that means any EC2 instance launch in the subnet is going to get a public IP address. Hence, it’s going to be considered a public subnet. a lot of companies wants to run on at least three availability zones for high availability. because one goes out, if you have another one, what happens if two goes out. so commonly create at least two additionals. we’re gonna make 3 subnets and 1 private subnet first of all, make subnet for A. this CIDR range is smaller than the one up here. the number is larger, but from the perspective of how many IP addresses it allocates, there’s actually a fewer here. you can set this as 16, it’s always goint to be less, I mean a higher number than 16. the auto sign is going to be set to No. modify this and set it is considered a public subnet. make subnets for B and C and private A too. public A, B, C are already automatically asscociated with main route table by default. but for our private one, we’re not gonna wanting to really use the main route table there. so we probably would want to create our own route table for our private subnets&amp;lt;/b&amp;gt;. we don’t need the subnet to reach the internet. so just change the association here.Words on the left hand side : 왼쪽에The copyright of all material here is on this video https://www.youtube.com/watch?v=Ia-UEYYR44sThis post is just for studying AWS SAA." }, { "title": "[AWS Solution Architect] NAT (Network Address Translation)", "url": "/posts/NAT/", "categories": "Development, AWS", "tags": "aws, certification, eng", "date": "2022-01-15 12:56:00 +0900", "snippet": "NAT (Network Address Translation) local network with its own IP address space Q. why do we want to this? A. two reasons for this. If you have a private networking need to help gain outbound access to the internet, you need to use a NAT gateway to rempat the Private IPs. If you have two networks which have conflicting network addresses, maybe they actaully have the same, you can use a NAT to make the addresses more agreeable for communication NAT instance VS NAT gateway NAT have two options NAT instances NAT gateway NAT instances you have to configure that instance, it’s just regular EC2 instance to do that remapping. the community came up with a bunch of NAT instances. in order for NAT instances to work, they have to be in a public subnet, because it has to be able to reach the internet if it’s in a private subnet, there’s no way to get to the internet. NAT gateways manage service you’re not gonna have access to it, Eva 100% manange it for you. but it’s not just gonna launch one, it’s gonna have a redundant instance for you, because when you launch your own NAT instances, if whatever reason it gets taken down, then you’d have to run more than one.what you have to do is to do all this work to make sure that these instances are going to scale based on your traffic or have the durability that you need. NAT gateways will take care this for you. you would lauch it in a public subnet you have to launch a NAT gateway per AZ, but you do get redundancy for your instances. NAT gateway doesn’t do launch them automatically across other AZs for you. Generally, you want to use NAT gateways when possible, because it’s the new way of doing it.but you could still use the legacy way of doing it. (???)SummaryActaully, it’s not that important on AWS SAA, is on sysops.Words go through the comparision of these two.The copyright of all material here is on this video https://www.youtube.com/watch?v=Ia-UEYYR44sThis post is just for studying AWS SAA." }, { "title": "[AWS Solution Architect Associate] SG (Security Group)", "url": "/posts/SG/", "categories": "Development, AWS", "tags": "aws, certification, eng", "date": "2022-01-15 12:26:00 +0900", "snippet": "SG (Security Groups) they protect our EC2 instances by acting as a virtual firewall controlling the inbound and outbound traffic. you would attach a security groups to an EC2 instance we can set the rules with a particular protocol and a port range, who are allowed to have access. in this case, I want to be able to SSH into EC2 instance, which uses the TCP protocol. and the standard port for SSH is 22. And I’m going to allow only my IP, so anytime you see forword /32 that always means my IP.that’s all you have to do to add inbound and outbound rules. there are different EC2 instances, they’re all in different subnets. Security groups do not care about subnets, you just assign EC2 instance to a security group.Use cases 3 scenarios the configuration is different the idea we have a web application running on a EC2 instance it is connecting to an RDS db to get its information running in a private subnet. 1st case we have an inbound rule on the sg-db saying allowing for anything from 5432, which is the Postgre’s port number for this specific IP address. it allows us EC2 instance to connect with RDS db. the takeaway you can specify the source to be an IP range or a specific IP 2nd case the only difference with 1st case is, instead of providing an IP address as a source, we can provide another SG. anything within SG is allowed to gain access for inbound traffic on 5432 3rd case we have inbound traffic on port 80, inbound traffic on port 22 for the sg-public group. we have the EC2 instance and the RDS db within its own security group. the EC2 instance is allowed to talk to that RDS db, and that EC2 instance is not exposing the RDS db., because it’s in a private subnet, that doesn’t have a public IP address. the takeaway this EC2 instance is able to get traffic from the internet and it’s also able to accept someone from like an SSH access. you can nest multiple SG onto one EC2 instanceLimits if you want to beyond 2500 SG, you need to make a service limit increase request to Eva support. Q. how many SG can you have on an instance? A. it’s depending on how many ENIs are actually attached to that SG. if you have 2 ENI that it’s attached to a SG, by default you’ll have 10. if you have the upper limit, you have 32 SG on a single instance. SummaryWords the big takeaway here is~ : the key point here is~ keep that stuff upper limit : 상한선 The copyright of all material here is on this video https://www.youtube.com/watch?v=Ia-UEYYR44sThis post is just for studying AWS SAA." }, { "title": "[AWS Solution Architect] NACL (Network Access Control List)", "url": "/posts/NACL/", "categories": "Development, AWS", "tags": "aws, certification, eng", "date": "2022-01-15 11:42:00 +0900", "snippet": "NACL (Network Access Control List) When you create VPC, you can get a NACL by default. inbound rules &amp;amp; outbound rulesUse CaseSummaryWords a malicious actor : 악의적 행동The copyright of all material here is on this video https://www.youtube.com/watch?v=Ia-UEYYR44sThis post is just for studying AWS SAA." }, { "title": "[AWS Solution Architect] VPC Flow Logs", "url": "/posts/VPC-Flow-Logs/", "categories": "Development, AWS", "tags": "aws, certification, eng", "date": "2022-01-14 15:50:00 +0900", "snippet": "VPC Flow Logs to capture IP traffic information in-and-out of Network interfaces within your VPC.You can turn on VPC Flow Logs at three different levels turn it on in VPC level : which doing it here turn it on at a specific Subnet turn it on for a specific network interface To find VPC flow logs, just go to the VPC console if you once turn flow log on, you can’t edit it. all you can do is delete it.Example of VPC flow logs ⭐️ srcaddr ⭐️ dstaddrQuestions Does VPC flow logs contain host names? N Does VPC flow logs contain IP addresses? YSummaryWords trickle down :　흘러내리다The copyright of all material here is on the video https://www.youtube.com/watch?v=Ia-UEYYR44sThis post is just for studying AWS SAA." }, { "title": "[AWS Solution Architect] VPC Endpoints", "url": "/posts/VPC-Endpoints/", "categories": "Development, AWS", "tags": "aws, certification, eng", "date": "2022-01-14 15:30:00 +0900", "snippet": "VPC Endpoints you have an EC2 instance, and you want to get something from your s3 bucket.so you normally do is use the AWS SDK and you would make that call, and it would go out of your IGW to the internet and back into the AWS network to get that file or object out of s3. SOo, it wouldn’t be more convenient if we could just keep the traffic within the AWS network. That is the purpose of a VPC endpoint.It helps you keep traffic within the AWS network.The idea because it does not leave a network, not required a public IP address to communicate with these services.to get to s3, we can now eliminate the need for an internet gateway and keep everything private.Type Interface Endpoint Gateway EndpointInterface EndpointsGateway EndpointSummaryWords elastic provision : supply, 供給, 공급The copyright of all material here is on the video https://www.youtube.com/watch?v=Ia-UEYYR44sThis post is just for studying AWS SAA." }, { "title": "[AWS Solution Architect] VPC", "url": "/posts/VPC/", "categories": "Development, AWS", "tags": "aws, certification, eng", "date": "2022-01-14 14:34:00 +0900", "snippet": "VPC Virtual Private Cloud it allows you to provide a logically isolated section of the AWS Cloud where you can launch AWS resources in a virtual network that you define.Core ComponentsKey features you can set its tenancy to default or dedicated tenancy how EC2 instances are distributed across physical hardware and affects pricing default Multiple AWS accounts may share the same physical hardware. dedicated Your instance runs on single-tenant hardware. Region Specific they do not span regions 5 VPC per region Every region comes with a default VPC 200 subnets per VPC The address of the VPC : IPv4 Cidr Block (+IPv6 Cidr Block) Cost nothing (it doesn’t cost you anything) VPC’s / Route Tables / Nacls / Internet Gateways / Security Groups and Subnets / VPC Peering Something cost money NAT Gateway / VPC Endpoints / VPN Gateway / Customer Gateway DNS hostnames they are disabled by default. should your instance have domain name addresses when you do create a VPC, it doesn’t have DNS host names turned on by default so there’s Public DNS. Default VPC DHCP Dynamic Host Configuration Protocol a client/server protocol that automatically provides an Internet Protocol (IP) host with its IP address and other related configuration information such as the subnet mask and default gateway. Default Everywhere IP giving access from anywhere or the internetVPC Peering which allows you to connect one VPC to another over direct network route using private IP addresses. the idea we have a VPC A, a VPC B and we want to treat it so like they behave like they’re on the same network. that’s what VPC peering connection allows us to do it’s very simple to create a peering connection just give it a name requester which could be a VPC A acceptor which could be a VPC B allow VPCs to talk to each other even they’re in different regionsLimitations around the configuration when you are peering, you’re using star configuaration 1 central VPC and you might have 4 other VPCs around it for each VPC, it have to have a peering connection. There’s No Transitive Peering if VPC C wants to talk to VPC B, hte traffic is not going to flow through a you actually would have to create another direct connection from C to B the idea it’s only to the nearest neighbor, where that communication is going to happen. You can&#39;t have Overlapping CIDR Blocks so it had the same CIDR block, this was 172 31 we’re gonna have a conflict we’re not gonna be able to talk to each other it’s the VPC peering in a nutshell Route Tables we can see routes, which has the internet gateway attached that allows access to the internet.IGW (Internet Gateway) It allows your VPC access to the internet we need to create a new route in our route table for the IGW igw-id identifies that resource then we’re goint to give it 0.0 point zero as the destination NAT : Network Address TranslationBastion (= Jumpbox) SSH (Secure Shell) a network protocol that gives users, particularly system administrators, a secure way to access a computer over an unsecured network. RCP (Remote copy) a tool for copying files to/from remote computers let’s say you wanted to SSH into that EC2 Instance (it’s in a private subnet), it doesn’t have a public IP address. So what you need is you need an intermediate EC2 Instance that you’re going to SSH into, which is Bastion And then, you’re going to jump from that box to this one that’s why bastions are also known as jumpboxes EC2 instance for the bastion is hardened so it should be very secure because it’s going to be your point of entry into your private EC2 instance. some people might ask can’t we a NAT instance(like NAT gateways) obviously turn into bastions?you can configure NATsand also from a security perspective, you’d never ever want to do that, you always wanna have a different EC2 instance as your Bastion.There is a service called Systems manager&#39;s session manager.It replaces the need for bastions, so you don’t have to launch your own EC2 instance.Generally, that’s recommended in AWS.But as you know, Bastions are being commonly used throughout a lot of companies because it needs to meet whatever their requirements are. and they’re just comfortable with them.Direct Connect depending on what configuration you get if it’s in the lower bandwidth, you are looking between 50 megabytes to 500 megabytes. or in the higher bandwidth is 1 gigabytes to 10 gigabytes so the transfer rate to your on-premise environment, the network to AWS, is it considerably fast. this can be really important if you are an enterprise and you want to keep the same level of performance that you’re used to. with direct connect, it helps reduce network costs, increase bandwidth throughput it provides a more consistent network experience than a typical internet based connectionWords full-name known as short-name (= short-name stands for full-name) it’s pretty easy to going forward in addition to come with imply I have a representation of how it works, so the idea is ~ intend for (=mean) be hardened : 굳은 premise environment considerably (= significantly) typical (= representative) bandwidth throughput : 대역폭 처리량The copyright of all material here is on the video https://www.youtube.com/watch?v=Ia-UEYYR44sThis post is just for studying AWS SAA." }, { "title": "[AWS Solution Architect] Snowball / Snowball Edge / Snowmobile", "url": "/posts/Snowball/", "categories": "Development, AWS", "tags": "aws, certification, eng", "date": "2022-01-14 12:36:00 +0900", "snippet": "Snowball Petabyte-scale data transfer service Move data onto AWS via physical briefcase computer very quickly very inexpensivelyspeed when you try and transfer 100 terabytes over a high speed internet to AWS, it could take over 100 days - but with a snowball, it will take less than a week.cost snowball is going to reduce that cost by 1/5thFeatures and limitations come with the kind of digitial shipping label temper and weather proof The data is encrypted end to end using tivity. has Trusted Platform Module (TPM) (chip) a specialized chip on an endpoint device that stores RSA encryption keys specific to the host system for hardware authentication. For security purposes, data transfers must be completed within 90days of the Snowball being prepared. Snowball can import and export from S3Size in two sizes 50 terabytes (42 TB of usable space) 80 terabytes (72 TB of usable space) you don’t need to utilize the space on there petabyte scale migration you can use multiple snowballs to get to petabytes A petabyte is a multiple of a byte Snowball Edge snowball + more storage and onsite compute capacity capabilties. difference orange bars that’s the way to distinguish snowball from snoball edge. more storage and with local processing features LCD display shipping information and other functionality instead of having E-ink display ⭐️ can undertake local processing and edge-computing workloads can use in a cluster in groups of 5 to 10 devices you can get a bunch of these noble edges have them work on a single job that is kind of like having your own little mini data center up to five to 10 devices. three options for device configurations you can optimize what you need and the CPU amounts are goint to change in this device based on what you need. storage optimized (24 vCPUs) compute optimized (54 vCPUs) GPU optimized (54 vCPUs) Size 100 TB (83 TB of uable space) 100 TB Clustered (45TB per node)Snowmobile a 45-foot long ruggedized shipping container size : 100 PB (perabytes)SummaryThe copyright of all material here is on the video https://www.youtube.com/watch?v=Ia-UEYYR44sThis post is just for studying AWS SAA." }, { "title": "[AWS Solution Architect] S3 2", "url": "/posts/S3_2/", "categories": "Development, AWS", "tags": "aws, certification, eng", "date": "2022-01-12 17:10:00 +0900", "snippet": "S3 S3 is in a global region. most services are going to be region specific.And you’d have to switch between them to see the resources of them but not for s3 you see all your buckets from every single region in one view, which is very convenient.Create S3 a bucket name has to be unique. has to be DNS compliant. you’re not allowed certain characters. Delete S3Upload files and make public If we’re going to access files by url after uploading files, we’re going to be see that it’s disabled.So, make it public Permissions (in the top) allow public access. Edit on ‘Block public access’ Untick ‘block all public access’ and save. Go to each file and click the button ‘make public’Versioning for newer files Properties (in the top) Versioning and tick ‘Enabled’ default : suspend versioning Overview (in the top) we can see versions tab we can go hide and show we can add information for the version ID if we hit show, we can see versions. Upload new files here, which have the exact same name if we hit show again, we can see that some of our files where we’ve done some uploading there have additional versions. the initial files has null version ID but if we upload files after turning versioning on, those files have the version ID the only reason the version ID is null is because they existed prior before turning versioning on. if we see files, we can see the latest version of file. if you wanna see the previous version, you drop down here. Make the latest version public the latest version is not gonna inherit the original properties like for the public access (but the previous version is still public) if you delete a file which is the latest version it still shows up in the console. but the file is no longer there. Features of Versioning it helps you protect from the deletion of files. it allows you to keep versions of stuff and those properties. which means it does not carry over to the next one. SSE (Server-side Encryption) Properties Default encryption by default, it is setting None. the warning : This property does not affect existing objects in your bucket. Turn AES-256 on but server-side encryption is still none. Go to Properties of each file you can set individual encryption profiles. you can also do it per bucket. now if we were to go access this URL but data is public. can’t we access it? NO the encryption doesn&#39;t mean that the files aren&#39;t accessible. It just because we have made this file public, it just means that when they&#39;re at rest on the servers on AWS, there are going to be encrypted. CLI for S3 (Command Line Interface) how to access private files using presigned URL.ls List all buckets aws s3 ls List all folders and objects in bucket aws s3 ls exampro-000 result : PRE enterprise-d/ (=) aws s3 ls s3://exampro-000 List all folders and objects in folder aws s3 ls exampro-000/enterprise-d/ (=) aws s3 ls s3://exampro-000/enterprise-d cp Download object to my desktop aws s3 cp s3://exampro-000/enterprise-d/barclay.jpg ~/Desktop/barclay.jpg cp (original file’s path) (new file’s path) Upload object to my s3 bucket aws s3 cp ~/Desktop/enterprise-d/q.jpg s3://exampro-000/enterprise-d/q.jpg by default, it’s private presign - generate a URL to provide temporary access to private files. - This is definitely a use case that you’d have if let’s say you had paid content behind, like a web application that you’d have to sign up to gain access. Create presigned url that expires in 300 seconds aws s3 presign s3://exampro-000/enterprise-d/q.jpg –expires-in 300 Lifecycle policies case1 change the storage class for objects we’re gonna do it at the object level. steps Properties Storage class Choose the class that we want to standardize and save we can save cost case2 if you want to automate that process. because if we were handling a lot of log files let’s say after 30 days we don’t really need them anymore, but we need to hold them on fro the next seven years. that’s where lifecycle policies are going to come in play we’re gonna do that at the bucket level steps Go to bucket Management Add a new lifecycle rules Name and scope we could limit the scope of what files we want Transition we have to decide whether it’s the current version or the previous version Expiration it’s not necessary, but if we want to actually delete the file after the current days CRR (Cross-Region Replication) for greater durability it allow us to copy one file from a bucket to another bucket. this could be another region and in another AWS account Go to S3 Create new bucket which has another region Go to new bucket (destination) Make sure that we have versioning turned on in both buckets (both the source bucket and destination bucket) Turn versioning on Go to origin bucket (source) - Management - Replication Add rules Set source Set destination Change storage class (not necessary) it’s a good idea if you want to save money. It’s like your backup bucket. If you don’t actually use files. Object ownership (not necessary) you can also send this to someone else’s bucket in another AWS account your use case is this bucket has files and you want to provide it to multiple clients. Configure rule options Bucket policies we can custom rules about the type of access we want to allow to our buckets. Go to bucket. Permissions Bucket Policy it’s providing a policy in the format of json file there’s a policy generator on below Use AWS Policy Generator Copy and paste jsonS3 cheat sheatWords That’s the question I have in the back of my mind apparently, we totally can a slightly different N syntax stand for (=represent) what does that stand for? it’s not a big deal : 별거 아니다 etc : Et cetera the roll isn’t created in time asterisk : * retrieval tradeoff availability : usefulness, 可用性 operantinal availability : 使用可用性 Usability : 易用性 ArchiveThe copyright of all material here is on the video https://www.youtube.com/watch?v=Ia-UEYYR44sThis post is just for studying AWS SAA." }, { "title": "[AWS Solution Architect] S3", "url": "/posts/S3/", "categories": "Development, AWS", "tags": "aws, certification, eng", "date": "2022-01-10 21:10:00 +0900", "snippet": "S3 (Simple Storage Service) it provides you with unlimited storage The S3 console provides an interface for you to upload and access your data. S3 Object : contain data like files. You can store data from 0 bytes to 5 Terabytes in size. S3 Bucket : hold objects like folders. Bucket names must be unique. Object-based storage servicedata storage architecture that manages data as objects (as opposed to other storage architecture) file systems which manages data as files and fire hierarchy block storage which manages data as blocks within sectors and tracksStorage Classes(less cheaper) Standard(default) Intelligent Tiering Standard Infrequently Accessed (IA) One Zone IA Glacier for cold data the points : price(The lowest price), safety(99.9% durability) -&amp;gt; so it’s the best for cold data Glacier Deep Archive(the cheapest)Amazon S3 Glacier is a secure, durable, and extremely low-cost Amazon S3 storage class for data archiving and long-term backup. With S3 Glacier, customers can store their data cost effectively for months, years, or even decades.** reference : https://bluese05.tistory.com/35AWS is guarantee of 99.99% of availability, 11&#39;s durability.Storage Classes Comparison** reference : https://www.youtube.com/watch?v=Ia-UEYYR44sSecurity Log files are generated and saved in a different bucket. (not the same bucket)(Logging per request can be turned on a bucket.) ACL(Access Control Lists the way to control access simply. Bucket Policies it is generally used more. you have to write a JSON document policy a lot more rich, complex rules. if you are ever setting up static S3, you definitely have to use a bucket policy there’s no fool proof. Encryption SSE (Server Side Encryption) SSE-AES : AES-256 (uses 256 bytes, very long encryption) SSE-KMS Key Management Service it uses envelope encryption so the key is then encrypted with another key It’s either managed by AWS or managed by you the key itself. SSE-C C : Customer provided keys it’s no option in default encryption it’s just encrypting the files locally and then uploading them to S3. Data Consistency Consistency Consistency is going to be different when you are overwriting files or deleting objects. New Objects(PUTS) when you put data or write new data to S3 as a new object, it’s going to be read after write consistency. What that means is as soon as you upload it, you can immediately read the data and it’s going to be consistent.Overwrite Objects(PUTS) / Delete Objects(DELETES) when it comes to overwriting and deleting objects, it’s going to take time for s3 to replicated to all those other AZs. (it only takes like a second or two to update) so if you were to immediately read the data, s3 may return to you an old copy. AZ Availability Zone the logical building block that makes up an AWS Region. the isolated locations within data center regions from which public cloud services originate and operate.CRR (Cross Region Replication) it provides higher durability in the case of disaster when you turn it on, we are going to specify a destination bucket in another region. and it’s going to automatically replicate those objects from the region source. it replicate to a bucket in another AWS account which is setting on another region. for it, you need to have versioning turned on in both the source and destination buckets.Versioning what versioning does is it allows you to version your objects. it help you to prevent data lose and just keeping track of versions. if you put a new file which has the exact same key, it’s going to create a new version of it. and it’s goint to it a new version ID the idea is if you access this object, it’s always goint to pull the one from the top. and if you were to delete that object,now it’s going to access the previous one. SO it’s a really good way of protecting your data. if you do turn on S3 versioning, you cannot disable it after the fact.which means once it’s turned on, you cannot remove versioning from existing file. all you can do is suspend versioning.Lifecycle Management what it does is it automates the process of moving objects to different storage classes or deleting them all together. it can be used together with versioning it can be applied to both current and previous versionsTransfer Acceleration it provides you fast and secure transfer of files over long distances between your end users and S3 bucket.Presigned Urls it generate a url which authenticate you temporary access to an object to either upload or download object data. it is commonly used to provide access to private objects. You can use AWS CLI / AWS SDK to generate it.** CLI : Commend Line Interface ** SDK : Software Development KitMFA Delete (Multi Factor Authentication) it makes you require an MFA code in order to delete object. there’s some limitations (caveats) around how you can use it or you can’t use MFA delete. You must use AWS CLI in order to turn on MFA You have to make sure version is turned on your bucket Only the bucket owner logged in as the root user can delete objects from the bucket. This is going to be a really good way to ensure that files do not get deleted by act.Important words stand for : 象徴する。代表 replicate : duplicate, 複製する。 take a look : 一度見る have a feature called ~ compliancy reason : 遵守理由 that is the concept caveats : 注意事項, 注意事项 durability : 耐久性 optimizing operational excellence : 운영 우수성의 최적화 that kind of stuff versus : vs elasticity : 탄력성 (elasticity of demand) scalability : 확장성 a bunch of ~ : 묶음, 다발 pillar : 축 nitty-gritty what is essential and basic be applicable to N you will be overwhelmed to overcome completely in mind or feeling foundational information resilient able to withstand or recover quickly from difficult conditions. strong and not easily damaged by being hit, stretched, or squeezed. reliable and resilient storage able to be trusted. " }, { "title": "[Chinese] 【我的时代，你的时代】 ep26", "url": "/posts/%E6%88%91%E7%9A%84%E6%97%B6%E4%BB%A3-%E4%BD%A0%E7%9A%84%E6%97%B6%E4%BB%A3ep26/", "categories": "Chinese", "tags": "chn", "date": "2022-01-08 01:30:00 +0900", "snippet": "ep26 中听力练习有的是错的，参考一下。你们的事情我不想吵过，你真的确定一直赌气，来的解释机会都不给一次吗？我告诉你我妹食物中毒了，刚打了点滴躺着呢。你知道这钥匙的意思是什么吗？对不起，那天我误会你了。我带你去一个地方。你在这儿等我一下。十年前，你们战队拿下全国冠军那一刻，我就在现场。当时我坐在这儿，看来你的青菜的比赛，还有看了采访。请你有没有跟大家想说的吗？请不要叫我们玩家。其实我们跟所有的运动员都是一样的。我们都是运动选手。每次一场比赛从零开始吧。失败或者胜利能决定着一切的都是只有你的个人技术。只要你不过强大，不过优秀，才会得到别人的尊重，甚至全世界都会为你的战术作为来你的Sun。这才是个到机器人比赛。就在这个体育馆，我第一次看你的比赛。你和我哥拿下全国冠军，而我是一个前门坐着观众席看的人。夺冠以后你哭了，所有人为你欢呼，大家都叫你一个格斗女神。我也从来没见过哪个女儿像跟你一样，在商场你技术胜负了所有的人。我是因为你爱上格斗机器人。就在那天我也爱上你了。可是我不敢追你身。因为我是一个普通观众。正式介绍一下。这次回来是为了大家一起夺下今年机器人大赛的冠军。目标这么远吗？拿下冠军就去新加坡代表中国比赛。我们是一个临时的战队，行吗？我在酒店订了三间房，两个月时间。我们的住宿，餐饮，训练，我来负责。哪个战队是你的过去，而你也是过去不可能再负责的哪一只段青春。我只会说这些啊。你能明白吗？新加坡房间里还有电脑，你还记得吗？记得。当时我想看，我来你就关上了。里面全是你的比赛视频，新闻和采访。我房间里那个蓝色的保险箱.记得。里面全是你的海报和照片。我是因为你才选择了行业。我希望自己有一天跟你一起并且作战，一起经历所有的失败和荣誉。我还想跟你说。有我而言，最重要的那个人是你。最好的我给你，不好的留给我自己。-我给你送吃的呀。你姐都跟我说了。你别欺负人家了。我什么时候欺负他了？行了，你们慢慢聊。我觉得这个高度不错。吵架要需会哄。这些男人的生存技能。行了，我回去了。慢走。我爸给你说什么了？他说那我多哄哄你。那你打算怎么哄啊？红了怎么样？还可以吧。公共场了。送你上去啊。时间不早了，我先走了。你我睡觉了就走好不好？把状态调整好。这上次说过我还有一个大的惊喜，你记得吗？那让我的领队告诉你咯。你们换下了领队了？刚前。你去了KK当领队？我去给你买点儿水。你也不跟我打说招呼，就自己跑去KK当领队了。眼睛怎么还红啊？我们俩公是公，私是私。我们很少谈公事的。顺便说一句，他人不错。啊，对了。虽然我现在是KK的领队，但是帮我转告让他们别丢人。每场比赛我都会看着呢。让他们的后背教教什么叫王子回来的。-这么早？给你了。这是设计图。我也不想占便宜。我还挺舍不得KK的。舍不得你们。别说那些没用的。赶紧升级吧。不然下次见面，肯定还出我赢。我也不会收下留情的。保重。-新人教到。下午给你送过来。用他的来说，你们每个人的健康，我都来负责。不客气SOLO战队的队长。竟然来了SP，那我先给你介绍一下。特点，单纯，善良，还哭。当然了，关键的说从来不丢面子。抹眼泪，继续上阵杀敌。我也不知道为什么，其实眼泪比较多。竟然来你可别相似别人这个啊，老流氓一个嘴特别滑，见到美女老宏大。我有社会性。当然了，关键是非常靠谱。赶紧介绍自己了。说说为什么打比赛？可能是天赋太高了吧。一辈子的兄弟。正式欢迎加入SP。-介绍一下，我们的新领队。从今天开始担任KK的领队，希望能更帮助大家。你那天说的是这样的意思啊。马上去全国比赛了。我有个想法，大家讨论一下。-" }, { "title": "[Chinese] 【我的时代，你的时代】 ep25", "url": "/posts/%E6%88%91%E7%9A%84%E6%97%B6%E4%BB%A3-%E4%BD%A0%E7%9A%84%E6%97%B6%E4%BB%A3ep25/", "categories": "Chinese", "tags": "chn", "date": "2022-01-08 01:30:00 +0900", "snippet": "ep25 中原来妒忌是可燃物，它一瞬间就能把理智燃烧殆尽，让我完全变样，自己也认不出了。第一次见到这样的吴白，这样的急切冲动，情绪外露，可是在惊讶和不解过去之后，我却突然很想拥抱他一下。我或许应该对他说一声谢谢！因为他给了我最真实的一面，我们之间消失了客气和伪装，带来了至亲之间才会发生的伤害，比起贴着男神标签的形象，也许这个在背影里堵着气的少年才离我更近一些。" }, { "title": "[HashSet] Find the Duplicate Number", "url": "/posts/algorithm-hashset2/", "categories": "Development, Algorithm", "tags": "algorithm, java, eng, leetcode, binary search", "date": "2021-11-04 22:59:00 +0900", "snippet": "‘Find the Duplicate Number’ in LeetCode (Medium)📌 Problemhttps://leetcode.com/problems/find-the-duplicate-number/📌 AnswerThe point contains() Time complexity : O(n) Space complexity : O(n)class Solution { public int findDuplicate(int[] nums) { Set&amp;lt;Integer&amp;gt; seen = new HashSet&amp;lt;Integer&amp;gt;(); for (int num : nums) { if (seen.contains(num)) return num; seen.add(num); } return -1; }}📌 Other answerThe point Time complexity : O(n) Space complexity : O(1)class Solution { public int findDuplicate(int[] nums) { while (nums[0] != nums[nums[0]]) { int nxt = nums[nums[0]]; nums[nums[0]] = nums[0]; nums[0] = nxt; } return nums[0]; }}The source : https://leetcode.com/problems/find-the-duplicate-number/solution/📌 Words intuitive : 직관적인" }, { "title": "[Binary Search] Search in Rotated Sorted Array", "url": "/posts/algorithm-binary-search2/", "categories": "Development, Algorithm", "tags": "algorithm, java, eng, leetcode, binary search", "date": "2021-11-04 01:08:00 +0900", "snippet": "‘Search in Rotated Sorted Array’ in LeetCode (Medium)📌 Problemhttps://leetcode.com/problems/search-in-rotated-sorted-array/📌 AnswerThe point set judgement to check two points whether which part is ordered whether target is in that range and move there is an constraint You must write an algorithm with O(log n) runtime complexity.class Solution { public int search(int[] nums, int target) { int start = 0; int end = nums.length - 1; int mid; while (start &amp;lt;= end){ mid = (start + end) / 2; if (nums[mid] == target) return mid; // 1. check whether which part is ordered if (nums[start] &amp;lt;= nums[mid]) { // 2. check whether target is in that range if (target &amp;lt; nums[mid] &amp;amp;&amp;amp; target &amp;gt;= nums[start]) end = mid - 1; else start = mid + 1; } // 1. check whether which part is ordered if (nums[mid] &amp;lt;= nums[end]) { // 2. check whether target is in that range if (target &amp;gt; nums[mid] &amp;amp;&amp;amp; target &amp;lt;= nums[end]) start = mid + 1; else end = mid - 1; } } return -1; }}The source : https://leetcode.com/problems/search-in-rotated-sorted-array/discuss/14472/Java-AC-Solution-using-once-binary-search" }, { "title": "[Data Structure] HashSet vs TreeSet", "url": "/posts/algorithm-hashset-treeset/", "categories": "Development, Algorithm", "tags": "algorithm, java, eng", "date": "2021-11-03 13:58:00 +0900", "snippet": "📌 Common feature No duplicate elements Only one null element📌 Comparison Most important difference between HashSet and TreeSet is ordering. HashSet TreeSet HashSet doesn’t guaranteed any order TreeSet maintains objects in Sorted order defined by either Comparable or Comparator method in Java. HashSet is faster than a TreeSet.   📌 Time complexity||HashSet|TreeSet||:—:|:—:|:—:||Add|O(1)|O(log n)||Contains|O(1)|O(log n)||Next|O(h/n)|O(log n)|TipsO(1) &amp;lt; O(log n) &amp;lt; O(n) &amp;lt; O(n * log n) &amp;lt; O(n²) &amp;lt; O(n³) &amp;lt; O(2^n) &amp;lt; O(n!)The source :https://soft.plusblog.co.kr/74" }, { "title": "[Algorithm] Big-O notation", "url": "/posts/algorithm-big-O/", "categories": "Development, Algorithm", "tags": "algorithm, java, eng", "date": "2021-11-03 13:58:00 +0900", "snippet": "Big-O notation📌 What is it? a mathematical notation that describes the limiting behavior of a function when the argument tends towards a particular value or infinity. In computer science, big O notation is used to classify algorithms according to how their run time or space requirements grow as the input size grows. Time complexity + Space complexity 📌 Let’s compareO(1) &amp;lt; O(log n) &amp;lt; O(n) &amp;lt; O(n * log n) &amp;lt; O(n²) &amp;lt; O(n³) &amp;lt; O(2^n) &amp;lt; O(n!)And,Big-O notation ignores the following case O(2N) -&amp;gt; O(N) O(N² + 2) &amp;gt; O(N²) O(N² + N) -&amp;gt; O(N²)📌 ExampleTime complexity// O(1)int sum1(int N) { return N * N;}// O(2N) =&amp;gt; O(N)int sum2(int N) { sum = 0; for (int i = 1; i &amp;lt;= N; i++) { sum = sum + N; } return sum;}// O(N²)int sum3(int N) { sum = 0; for (int i = 1; i &amp;lt;= N; i++) { for (int j = 1; j &amp;lt;= N; j++) { sum = sum + 1; } } return sum;}Space complexity// O(N)// recursionint sum(int N) { sum = 0; if (N &amp;lt; 1) return 0; return N + sum(N - 1);}// O(1)int mainSum(int N) { int result = 0; for (int i = 0; i &amp;lt; N; i++) result += sum(i, i + 1); return result;}int sum(int a, int b) { return a + b;}📌 Time complexityBinary searchO(logN)Example1. Find the square root (√)// O(logN)public static int squareRootBSearch(int n) { int min = 0; int max = n; int guess; while (min &amp;lt;= max) { guess = (min + max) / 2; if (guess * guess == n) return guess; else if (guess * guess &amp;gt; n) max = guess - 1; else min = guess + 1; } return -1;}// not binary search// O(N)public static int squareRootLoop(int n) { for (int i = 0; i &amp;lt; n; i++) if (i * i == n) return i; return -1;}Sorting algorithm Efficient but not simple algorithm quick sort(1), heap sort(3), merge sort(2) The source : https://cjh5414.github.io/big-o-notation/ https://cjh5414.github.io/binary-search/ https://velog.io/@gillog/시간복잡도 https://gmlwjd9405.github.io/2018/05/10/algorithm-quick-sort.html" }, { "title": "[Algorithm] Combination Sum", "url": "/posts/algorithm-combination-sum/", "categories": "Development, Algorithm", "tags": "algorithm, java, eng, leetcode", "date": "2021-10-30 13:15:00 +0900", "snippet": "‘Combination Sum’ in LeetCode (Medium)📌 Problemhttps://leetcode.com/problems/combination-sum/📌 AnswerThe point backtrackingimport java.util.List;class Solution { public List&amp;lt;List&amp;lt;Integer&amp;gt;&amp;gt; combinationSum(int[] candidates, int target) { List&amp;lt;List&amp;lt;Integer&amp;gt;&amp;gt; result = new ArrayList&amp;lt;&amp;gt;(); Arrays.sort(candidates); backtrack(result, new ArrayList&amp;lt;&amp;gt;(), candidates, target, 0); return result; } private void backtrack(List&amp;lt;List&amp;lt;Integer&amp;gt;&amp;gt; list, List&amp;lt;Integer&amp;gt; temp, int[] nums, int remain, int start) { if (remain &amp;lt; 0) return; else if (remain == 0) { // System.out.println(&quot;when? &quot;); list.add(new ArrayList&amp;lt;&amp;gt;(temp)); } else { for (int i = start; i &amp;lt; nums.length; i++) { // System.out.println(temp); temp.add(nums[i]); backtrack(list, temp, nums, remain - nums[i], i); // check again until remain become minus temp.remove(temp.size() - 1); // System.out.println(temp); // System.out.println(); } } }}/**[Question]- candidates : distinct integers- target : a target integer- return : a list of all unique combinations of candidates where the chosen numbers sum to target**/The source : https://leetcode.com/problems/combination-sum/discuss/16502/A-general-approach-to-backtracking-questions-in-Java-(Subsets-Permutations-Combination-Sum-Palindrome-Partitioning)I’m gonna eat sandwich 🥪🥪🥪" }, { "title": "[Algorithm] Binary search", "url": "/posts/algorithm-binary-search/", "categories": "Development, Algorithm", "tags": "algorithm, java, eng, binary search", "date": "2021-10-30 11:50:00 +0900", "snippet": "📌 What is binary search algorithm?1️⃣ Choose the middle element, as doing so causes the set of candidates to be halved each time.(To reduce the set of candidates maximally.)2️⃣ Use the information that all the elements are sorted3️⃣ The time complexity is O(log n)📌 Implementation- Java Iterative binary seach More efficient than recursive binary search // space complexity : O(1)// time complexity : O(log n)int BSearch(int arr[], int target) { int low = 0; int high = arr.length - 1; int mid; while (low &amp;lt;= high) { mid = (low + high) / 2; if (arr[mid] == target) return mid; else if (arr[mid] &amp;gt; target) high = mid - 1; else low = mid + 1; } return -1;} Recursive binary search// space complexity : O(log N)// time complexity : O(log n)int BSearchRecursive(int arr[], int target, int low, int high) { if (low &amp;gt; high) return -1; int mid = (low + high) / 2; if (arr[mid] == target) return mid; else if (arr[mid] &amp;gt; target) return BSearchRecursive(arr, target, low, mid - 1); else return BSearchRecursive(arr, target, mid + 1, high);}The major difference between the iterative and recursive version of Binary Search is that the recursive version has a space complexity of O(log N) while the iterative version has a space complexity of O(1). Hence, even though recursive version may be easy to implement, the iterative version is efficient.Time complexity is same.📌 When is binary search best applied?Binary search is an efficient algorithm for finding an item in an sorted array.📌 Binary search tree vs Binary search- Binary search tree A tree data structure Each node has up to 2 children The left subtree of a node contains only nodes with keys less than the node’s key The right subtree of a node contains only nodes with keys greater than the node’s key- Binary search An algorithm that works on a sorted data structure (usually, but not necessarily, an array) At each step, looking at the value in the middle and recursing to either the left or the right, depending on whether the target value is smaller or greater than the value in the middle (or stopping if it’s equal).The source : https://cjh5414.github.io/binary-search/ https://stackoverflow.com/questions/21586085/difference-between-binary-search-and-binary-search-tree" }, { "title": "[Binary Search] Find First and Last Position of Element in Sorted Array", "url": "/posts/algorithm-find-first-and-last-position/", "categories": "Development, Algorithm", "tags": "algorithm, java, eng, leetcode, binary search", "date": "2021-10-29 15:22:00 +0900", "snippet": "‘Find First and Last Position of Element in Sorted Array’ in LeetCode (Medium)📌 Problemhttps://leetcode.com/problems/find-first-and-last-position-of-element-in-sorted-array/📌 AnswerThe point binary search : time complextiy is O(logN)Resultclass Solution { public int[] searchRange(int[] nums, int target) { int[] result = new int[2]; result[0] = findFirst(nums, target); result[1] = findLast(nums, target); return result; } private int findFirst(int[] nums, int target) { int idx = -1; int start = 0; int end = nums.length - 1; while (start &amp;lt;= end) { int mid = (start + end) / 2; // here is difference if (nums[mid] &amp;gt;= target) end = mid - 1; else start = mid + 1; if (nums[mid] == target) idx = mid; } return idx; } private int findLast(int[] nums, int target) { int idx = -1; int start = 0; int end = nums.length - 1; while (start &amp;lt;= end) { int mid = (start + end) / 2; // here is difference if (nums[mid] &amp;lt;= target) start = mid + 1; else end = mid - 1; if (nums[mid] == target) idx = mid; } return idx; }}/**[Question]- Find First and Last Position of Element in Sorted Array- find the starting and ending position of a given target value.- If target is not found in the array, return [-1, -1].[Condition]- 0 &amp;lt;= nums.length &amp;lt;= 10.5- 10.9 &amp;lt;= nums[i] &amp;lt;= 10.9- -10.9 &amp;lt;= target &amp;lt;= 10.9**/The source : https://leetcode.com/problems/find-first-and-last-position-of-element-in-sorted-array/discuss/14734/Easy-java-O(logn)-solution" }, { "title": "[Algorithm] Generate Parentheses", "url": "/posts/algorithm-generate-parentheses/", "categories": "Development, Algorithm", "tags": "algorithm, java, eng, leetcode", "date": "2021-10-26 20:20:00 +0900", "snippet": "‘Generate Parentheses’ in LeetCode (Medium)📌 Problemhttps://leetcode.com/problems/generate-parentheses/📌 Insight|Recursion|Backtracking|DFS||:—|:—|:—||In recursion, the function calls itself until it reaches a base case.|In backtracking, we use recursion to explore all the possibilities until we get the best result for the problem.|||| - Backtracking is a more general algorithm that doesn’t necessarily even relate to trees. - Backtracking is usually implemented as DFS plus search pruning (backtracking is the general form of DFS.) - If we extend DFS to general problems, we can call it backtracking. | - DFS is the special form of backtracking - If we use backtracking to tree/graph related problems, we can call it DFS.The source : https://stackoverflow.com/questions/1294720/whats-the-difference-between-backtracking-and-depth-first-search📌 Answer1. Use DFSThe time and space complexity is very nice.Resultclass Solution { public List&amp;lt;String&amp;gt; generateParenthesis(int n) { List&amp;lt;String&amp;gt; output = new ArrayList&amp;lt;&amp;gt;(); dfs(n, &quot;&quot;, output, n, n); return output; } public void dfs(int n, String cur, List output, int left, int right) { if (left &amp;gt; right) return; if (left == 0 &amp;amp;&amp;amp; right == 0) { output.add(cur); return; } if (left &amp;gt; 0) dfs(n, cur + &quot;(&quot;, output, left - 1, right); if (right &amp;gt; 0) dfs(n, cur + &quot;)&quot;, output, left, right - 1); }}The source : https://leetcode.com/problems/generate-parentheses/discuss/248359/Extremely-simple-Java-DFS-(beats-100)2. Use BacktrackingBacktracking is usually implemented as DFS plus search pruning.The pointThe time and space complexity is bad….Resultimport java.util.List;import java.util.ArrayList;class Solution { public List&amp;lt;String&amp;gt; generateParenthesis(int n) { List&amp;lt;String&amp;gt; list = new ArrayList&amp;lt;&amp;gt;(); backtrack(list, &quot;&quot;, 0, 0, n); return list; } private void backtrack(List&amp;lt;String&amp;gt; list, String s, int open, int close, int n) { System.out.println(s); // end backtracking if (s.length() == n * 2) { list.add(s); return; } if (open &amp;lt; n) { System.out.println(&quot;open &amp;lt; max&quot;); backtrack(list, s + &quot;(&quot;, open + 1, close, n); } if (close &amp;lt; open) { System.out.println(&quot;close &amp;lt; open&quot;); backtrack(list, s + &quot;)&quot;, open, close + 1, n); } } }The source : https://leetcode.com/problems/generate-parentheses/discuss/10100/Easy-to-understand-Java-backtracking-solution📌 Words Parentheses : 괄호 discard : ~를 버리다 constraints : 제약 interpret : 해석하다 prefix : 접두사 concatenation : 연속 traverse : 가로지르다 extend : 확장하다 search pruning : 검색 가지치기 🍆But I think two codes are not so different….?Let’s know step by step 🐤" }, { "title": "[Algorithm] Remove Nth Node From End of List", "url": "/posts/algorithm-remove-nth-node/", "categories": "Development, Algorithm", "tags": "algorithm, java, eng, leetcode", "date": "2021-10-26 19:00:00 +0900", "snippet": "‘Remove Nth Node From End of List’ in LeetCode (Medium)📌 Problemhttps://leetcode.com/problems/remove-nth-node-from-end-of-list/📌 AnswerTwo-PointerThe point For a singly linked list, used two pointer ‘fast’, ‘slow’The time and space complexity is quite good.Resultclass Solution { public ListNode removeNthFromEnd(ListNode head, int n) { ListNode start = new ListNode(0); // two pointer ListNode slow = start, fast = start; start.next = head; for (int i = 1; i &amp;lt;= n + 1; i++) { fast = fast.next; } while (fast != null) { slow = slow.next; fast = fast.next; } slow.next = slow.next.next; return start.next; }}/** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode() {} * ListNode(int val) { this.val = val; } * ListNode(int val, ListNode next) { this.val = val; this.next = next; } * } *//**[Question]- remove the nth node from the end of the list- return its head.[Condition]- The number of nodes in the list is sz. **/The source : https://leetcode.com/problems/remove-nth-node-from-end-of-list/discuss/589304/CLEAR-JAVA-SOLUTION-WITH-DETAILED-EXPLANATION!And ⭐️ it’s the best explanationI’m not good at singly linked list…. Let’s search it." }, { "title": "[Algorithm] Letter Combinations of a Phone Number", "url": "/posts/algorithm-letter-combinations/", "categories": "Development, Algorithm", "tags": "algorithm, java, eng, leetcode", "date": "2021-10-26 09:37:00 +0900", "snippet": "‘Letter Combinations of a Phone Number’ in LeetCode (Medium)📌 Problemhttps://leetcode.com/problems/letter-combinations-of-a-phone-number/📌 Answer1. BacktrackingThe point recursion void backtrack() for (char letter : dict[digit].toCharArray())The time and space complexity is so nice!Resultclass Solution { public List&amp;lt;String&amp;gt; letterCombinations(String digits) { List&amp;lt;String&amp;gt; list = new ArrayList&amp;lt;&amp;gt;(); if (digits.length() == 0) return list; String[] dict = new String[] {&quot;&quot;, &quot;&quot;, &quot;abc&quot;, &quot;def&quot;, &quot;ghi&quot;, &quot;jkl&quot;, &quot;mno&quot;, &quot;pqrs&quot;, &quot;tuv&quot;, &quot;wxyz&quot; }; backtrack(list, digits.toCharArray(), &quot;&quot;, dict); return list; } public void backtrack(List&amp;lt;String&amp;gt; list, char[] digits, String s, String[] dict) { if (s.length() == digits.length) { list.add(s); return; } int i = s.length(); int digit = digits[i] - &#39;0&#39;; for (char letter : dict[digit].toCharArray()) backtrack(list, digits, s + Character.toString(letter), dict); }}The source : https://leetcode.com/problems/letter-combinations-of-a-phone-number/discuss/402087/Backtracking-Java-Solution-(100-runtime-98-memory)2. Simple answerThe point int num = digits.charAt(i) - &#39;0&#39;; convert char to int The time and space complexity is slower than backtracking.Resultclass Solution { public List&amp;lt;String&amp;gt; letterCombinations(String digits) { String digitletter[] = {&quot;&quot;,&quot;&quot;,&quot;abc&quot;,&quot;def&quot;,&quot;ghi&quot;,&quot;jkl&quot;,&quot;mno&quot;,&quot;pqrs&quot;,&quot;tuv&quot;,&quot;wxyz&quot;}; List&amp;lt;String&amp;gt; result = new ArrayList&amp;lt;String&amp;gt;(); if (digits.length() == 0) return result; result.add(&quot;&quot;); for (int i = 0; i &amp;lt; digits.length(); i++) { int num = digits.charAt(i) - &#39;0&#39;; result = combine(digitletter[num], result); } return result; } public List&amp;lt;String&amp;gt; combine(String digit, List&amp;lt;String&amp;gt; l) { List&amp;lt;String&amp;gt; result = new ArrayList&amp;lt;String&amp;gt;(); for (int i = 0; i&amp;lt; digit.length(); i++) for (String x : l) result.add(x + digit.charAt(i)); return result; }}The source : https://leetcode.com/problems/letter-combinations-of-a-phone-number/discuss/8118/Easy-understand-Java-Solution3. Without using input specific datas I defined a function for this pattern : String getLetters()Let’s check.import java.util.List;import java.util.ArrayList;import java.util.Collections;class Solution { public List&amp;lt;String&amp;gt; letterCombinations(String digits) { if (digits.length() == 0) return Collections.emptyList(); List&amp;lt;String&amp;gt; list = new ArrayList&amp;lt;&amp;gt;(); // condition : 0 &amp;lt;= digits.length &amp;lt;= 4 String[] arr = new String[4]; for (int i = 0; i &amp;lt; digits.length(); i++) { int num = digits.charAt(i) - &#39;0&#39;; // char to int int count = 3; // default if (num == 7 || num == 9) count = 4; arr[i] = getLetters(num, count); } // combine datas of arr // I&#39;ve not declared yet return list; } private String getLetters(int num, int count) { String letters = &quot;&quot;; int start = 3 * (num - 2); int end = start + count; for (int i = start; i &amp;lt; end; i++) letters += String.valueOf((char) (&#39;a&#39; + i)); return letters; }}/**[Question]- Return the answer in any order.- condition - 1 does not map to any letters. - 0 &amp;lt;= digits.length &amp;lt;= 4**/📌 Word|Declaration|Definition||:—:|:—:||You are declaring that something exists, such as a class, function or variable. You don’t say anything about what that class or function looks like, you just say that it exists.|You define how something is implemented, such as a class, function or variable, i.e. you say what it actually is.|The source : https://stackoverflow.com/questions/11715485/what-is-the-difference-between-declaration-and-definition-in-java" }, { "title": "[Algorithm] 3Sum", "url": "/posts/algorithm-3sum/", "categories": "Development, Algorithm, Leetcode", "tags": "algorithm, java, eng, leetcode", "date": "2021-10-25 22:27:00 +0900", "snippet": "‘3Sum’ in LeetCode (Medium)📌 Problemhttps://leetcode.com/problems/3sum/📌 AnswerThe point Sort array first Used Two-pointers technique i and j More detail about ‘Two pointers algorithm’Resultclass Solution { public List&amp;lt;List&amp;lt;Integer&amp;gt;&amp;gt; threeSum(int[] nums) { Arrays.sort(nums); List&amp;lt;List&amp;lt;Integer&amp;gt;&amp;gt; list = new ArrayList&amp;lt;&amp;gt;(); for (int i = 0; i &amp;lt; nums.length - 2; i++) { // avoid duplicates if (i &amp;gt; 0 &amp;amp;&amp;amp; (nums[i] == nums[i-1])) continue; // start : i, j , , , , , k int j = i + 1; int k = nums.length-1; while (j &amp;lt; k) { int sum = nums[i] + nums[j] + nums[k]; if (sum == 0) { list.add(Arrays.asList(nums[i], nums[j], nums[k])); // move again to make new list j++; k--; // avoid duplicates while ((j &amp;lt; k) &amp;amp;&amp;amp; (nums[j] == nums[j - 1])) j++; while ((j &amp;lt; k) &amp;amp;&amp;amp; (nums[k] == nums[k + 1])) k--; } else if (sum &amp;gt; 0) k--; else if (sum &amp;lt; 0) j++; } } return list; }}/**[Question]- return all the triplets [nums[i], nums[j], nums[k]]- condition - i != j, i != k, j != k (index) - nums[i] + nums[j] + nums[k] == 0 (value) - the solution set must not contain duplicate triplets.**/The source : https://leetcode.com/problems/3sum/discuss/7631/Simple-Java-Solution-Without-using-HashSet" }, { "title": "[Algorithm] Longest Palindromic Substring", "url": "/posts/algorithm-palindromic/", "categories": "Development, Algorithm, Leetcode", "tags": "algorithm, java, eng, leetcode", "date": "2021-10-25 18:49:00 +0900", "snippet": "‘Longest Palindromic Substrings’ in LeetCode (Medium)📌 Problemhttps://leetcode.com/problems/longest-palindromic-substring/📌 Answer1. Simple answerThe point for ( ; 0 &amp;lt;= i &amp;amp;&amp;amp; j &amp;lt; s.length(); i--, j++) {} This expression can check all datas from start to end Resultclass Solution { public String longestPalindrome(String s) { String max = &quot;&quot;; for (int i = 0; i &amp;lt; s.length(); i++) { String s1 = extend(s, i, i); // 0 0 String s2 = extend(s, i, i + 1); // 0 1 if (s1.length() &amp;gt; max.length()) max = s1; // s1 = b if (s2.length() &amp;gt; max.length()) max = s2; // } return max; } private String extend(String s, int i, int j) { for ( ; 0 &amp;lt;= i &amp;amp;&amp;amp; j &amp;lt; s.length(); i--, j++) // core idea : i--, j++ if (s.charAt(i) != s.charAt(j)) break; return s.substring(i + 1, j); // i : -1, j : 1 }}/**[Question]- s consist of only digits and English letters.- return the longest palindromic substring in s. - palindromic? ex. abba, samsung- **/The source : https://leetcode.com/problems/longest-palindromic-substring/discuss/2928/Very-simple-clean-java-solution2. Use Dynamic programmingThe point boolean[][] dp = new boolean[len][len]; the way to record the datas which are already checked in Dynamic programming (⭐️⭐️⭐️ Don’t forget purpose of dp) But…this way is quite slow and less efficientResultpublic class Solution { public String longestPalindrome(String s) { if (s == null || s.length() == 0) return &quot;&quot;; int len = s.length(); boolean[][] dp = new boolean[len][len]; // dp int start = 0; int end = 0; int max = 0; for (int i = 0; i &amp;lt; s.length(); i++) { for (int j = 0; j &amp;lt;= i; j++) { // important : j &amp;lt;= i // i - j : length of substring if (s.charAt(i) == s.charAt(j) &amp;amp;&amp;amp; (i - j &amp;lt;= 2 || dp[j + 1][i - 1])) dp[j][i] = true; // the way of dp if (dp[j][i] &amp;amp;&amp;amp; max &amp;lt; i - j + 1) { max = i - j + 1; // i - j + 1 : length of substring start = j; end = i; } } } return s.substring(start, end + 1); }}The source : https://leetcode.com/problems/longest-palindromic-substring/discuss/2987/Clean-Java-solution-using-DP-yet-the-time-complexity-is-O(N2)Let’s use debugger! And let’s eat dinner 🍱" }, { "title": "[Data Sturcture] HashSet vs HashMap vs LinkedHashMap", "url": "/posts/hashset/", "categories": "Development, DataStructure", "tags": "datastructure, java, eng", "date": "2021-10-25 18:00:00 +0900", "snippet": "HashSet 🆚 HashMap📌 Let’s compare   HashSet HashMap Implements Set Interface Map Interface Data Objects &amp;lt;Key,Value&amp;gt; Duplicate elements No Key : No Values : Yes Null elements Only one Key : Only one Values: multiple Insertion method add(Object) put(Key, Value) Advantage - There are no duplicate elements in HashSet - It’s faster than HashSet The source : https://javaconceptoftheday.com/differences-between-hashmap-vs-hashset-in-java/📌 Methods in JavaHashSetThe source : https://docs.oracle.com/javase/8/docs/api/java/util/HashSet.htmlHashMapThe source : https://docs.oracle.com/javase/8/docs/api/java/util/HashMap.htmlHashMap 🆚 LinkedHashMap📌 Let’s compare LinkedHashMap ; the keys are ordered when put HashMap : the keys are not ordered when putThe source : https://fruitdev.tistory.com/141" }, { "title": "[Algorithm] Longest Substring Without Repeating Characters", "url": "/posts/algorithm-hashset1/", "categories": "Development, Algorithm, Leetcode", "tags": "algorithm, java, eng, leetcode", "date": "2021-10-25 18:00:00 +0900", "snippet": "HashSetDetail‘Longest Substring Without Repeating Characters’ in LeetCode (Medium)📌 Problemhttps://leetcode.com/problems/longest-substring-without-repeating-characters/📌 AnswerThe point HashSet.contains(Object) Object ex. Character, String… String.charAt(int index) import java.lang.Math;import java.util.Set;import java.util.HashSet;import java.lang.Math;class Solution { public int lengthOfLongestSubstring(String s) { int i = 0, j = 0, max = 0; Set&amp;lt;Character&amp;gt; set = new HashSet&amp;lt;&amp;gt;(); while (j &amp;lt; s.length()) { // make the set without duplication // if there is no duplicate element in set if (!set.contains(s.charAt(j))) { set.add(s.charAt(j++)); // add to set max = Math.max(max, set.size()); // get max length } else set.remove(s.charAt(i++)); // if not, remove the duplicate element in set } return max; }}/**[Question]- find the length of the longest substring without repeating characters.**/The source : https://leetcode.com/problems/longest-substring-without-repeating-characters/discuss/1812/Share-my-Java-solution-using-HashSet" }, { "title": "[Diary] Modify goal", "url": "/posts/modify-goal/", "categories": "Diary", "tags": "diary, eng", "date": "2021-10-25 10:39:00 +0900", "snippet": "I found the good top 100 questions in LeetCode. Top 100 questionsPlus, I also must solve the problems in HackerRank.So, I think I must reschedule my study plan. I will solve the problems as below in a day. Questions Minutes 10 30 It only remains 15 days. Let’s keep doing hard yuha! I heard a word ‘Fighting’ is gaining popularity because of ‘Squid game’. So, I’m gonna tell Fighting! 🎃🎃🎃🎃🎃No pain, no gain.If no darkness, no light." }, { "title": "[Algorithm] Stack2", "url": "/posts/algorithm-stack2/", "categories": "Development, Algorithm, Leetcode", "tags": "algorithm, java, eng, leetcode", "date": "2021-10-25 10:03:00 +0900", "snippet": "StackTask‘Min Stack’ in LeetCode (Easy)📌 Problemhttps://leetcode.com/problems/min-stack/submissions/📌 Answer1. Use StackThe point If a inputted data is minimum, push two times. Pop two times when pop is same as minResultclass MinStack { private Stack&amp;lt;Integer&amp;gt; stack; private int min; // constructor public MinStack() { stack = new Stack&amp;lt;&amp;gt;(); min = Integer.MAX_VALUE; } public void push(int val) { // important if (min &amp;gt;= val) { stack.push(min); min = val; } stack.push(val); } public void pop() { int top = stack.pop(); if (top == min) min = stack.pop(); // pop again } public int top() { return stack.peek(); } public int getMin() { return min; }}/** * Your MinStack object will be instantiated and called as such: * MinStack obj = new MinStack(); * obj.push(val); * obj.pop(); * int param_3 = obj.top(); * int param_4 = obj.getMin(); */The source : https://leetcode.com/problems/min-stack/discuss/49014Well, its efficiency is not bad2. Implementation by yourselfThe point Make the custom class in the class -&amp;gt; incredible 😲Resultclass MinStack { ListNode top; public class ListNode { int data; int min; ListNode next; ListNode(int data) { this.data = data; next = null; min = Integer.MAX_VALUE; } } /** initialize your data structure here. */ public MinStack() { top = null; } public void push(int val) { ListNode t = new ListNode(val); t.next = top; if (top == null) { t.min = t.data; // SecondStack.Push(t.data); } else { if (t.data &amp;lt; top.min) { t.min = t.data; // SecondStack.Push(t.data); } else { t.min = top.min; // SecondStack.Push(top.min); } } top = t; } public void pop() { if (top == null) { System.err.println(&quot;Empty Stack&quot;); return; } top = top.next; } public int top() { return top.data; } public int getMin() { return top.min; }}The source : https://leetcode.com/problems/min-stack/discuss/509793/Java-Solution-one-Stack-O(1)-time-solutionIt’s almost same efficient as first answer.It’s the first time I use LeetCode.It’s so useful site because I can check the other answers easily after I submit mine.So interesting!" }, { "title": "[Data Sturcture] Heap", "url": "/posts/heap/", "categories": "Development, DataStructure", "tags": "datastructure, java, eng", "date": "2021-10-24 19:08:00 +0900", "snippet": "Heap📌 What is heap?1️⃣ A Heap is a special Tree-based data structure in which the tree is a complete binary tree. 2️⃣ All the nodes of the heap are arranged in a specific order.In Java, PriorityQueue can be used as a Heap.📌 Then, what is PriorityQueue?A PriorityQueue is used when the objects are supposed to be processed based on the priorityBy default, the priority queue in Java is min Priority queue with natural ordering. To make it max, we have to use a custom comparator so that head of the queue returns the greatest element in the queue.// 1. declare// min-heapPriorityQueue&amp;lt;Integer&amp;gt; priorityQueue = new PriorityQueue&amp;lt;&amp;gt;();// max-heapPriorityQueue&amp;lt;Integer&amp;gt; priorityQueue = new PriorityQueue&amp;lt;&amp;gt;(Collections.reverseOrder());// 2. addpriorityQueue.add(1); priorityQueue.add(2); priorityQueue.offer(3);// 3. remove priorityQueue.poll(); // get data and remove itpriorityQueue.remove(); // only removepriorityQueue.clear();// 4. getpriorityQueue.peek(); // only get📌 FeatureGenerally, Heaps can be of two types: Min-Heap In a Min-Heap, the key present at the root node must be minimum among the keys present at all of it’s children. The same property must be recursively true for all sub-trees in that Binary Tree. PriorityQueue&amp;lt;Integer&amp;gt; minHeap = new PriorityQueue&amp;lt;Integer&amp;gt;(); // ex. [1, 3, 5] // get the minimum value at the moment System.out.println(heap.poll()); // 1 System.out.println(heap.poll()); // 3 Max-Heap In a Max-Heap, the key present at the root node must be greatest among the keys present at all of it’s children. The same property must be recursively true for all sub-trees in that Binary Tree. PriorityQueue&amp;lt;Integer&amp;gt; maxHeap = new PriorityQueue&amp;lt;&amp;gt;(Comparator.reverseOrder()); // same as PriorityQueue&amp;lt;Integer&amp;gt; maxHeap = new PriorityQueue&amp;lt;Integer&amp;gt;(new Comparator&amp;lt;Integer&amp;gt;() { @Override public int compare(Integer o1, Integer o2) { return - Integer.compare(o1, o2); } }); // ex. [1, 3, 5] // get the maximum value at the moment System.out.println(heap.poll()); // 5 System.out.println(heap.poll()); // 3 📌 ImplementationTask 1The source :https://stackoverflow.com/questions/14165325/is-there-a-heap-in-java https://www.geeksforgeeks.org/heap-data-structure/ https://coding-factory.tistory.com/603" }, { "title": "[Algorithm] Heap", "url": "/posts/algorithm-heap/", "categories": "Development, Algorithm, Programmers", "tags": "algorithm, java, eng, programmers", "date": "2021-10-24 19:08:00 +0900", "snippet": "HeapIn Java, PriorityQueue can be used as a Heap. DetailTask더 맵게 in Programmers (Level 2)📌 Problemhttps://programmers.co.kr/learn/courses/30/lessons/42626📌 The point Use PriorityQueue &amp;amp; Min-Heap PriorityQueue&amp;lt;Integer&amp;gt; heap = new PriorityQueue&amp;lt;&amp;gt;(); to pick the minimum value When I face problems which need to get the minimum value or the maximum value,It&#39;s more efficient if I use PriorityQueue! Let&#39;s apply it afterwards 🎃📌 Answerimport java.util.PriorityQueue;class Solution { public int solution(int[] scoville, int K) { int answer = 0; // Used min-heap PriorityQueue&amp;lt;Integer&amp;gt; heap = new PriorityQueue&amp;lt;&amp;gt;(); // convert int array to PriorityQueue // ex. scoville [1, 2, 9, 3, 10, 12] -&amp;gt; heap [1, 2, 3, 9, 10, 12] for (int i = 0; i &amp;lt; scoville.length; i++) heap.offer(scoville[i]); while (heap.peek() &amp;lt; K) { if (heap.size() &amp;lt; 2) return -1; // if all datas can&#39;t be K or more int f1 = heap.poll(); // get the minimum value and remove int f2 = heap.poll(); int newFood = f1 + (f2 * 2); heap.offer(newFood); // add data answer++; } return answer; }}/**[Question]- scoville : 모든 음식의 스코빌 지수 (value : 2 or more and 1,000,000 or less)- K : 스코빌 지수 (value : 0 or more and 1,000,000 or less)- return : 섞어야 하는 최소 횟수 for 모든 음식의 스코빌 지수 &amp;gt;= K - 만들 수 없는 경우에는 -1 - 섞은 음식의 스코빌 지수 = 가장 맵지 않은 음식의 스코빌 지수 + (두 번째로 맵지 않은 음식의 스코빌 지수 * 2)**/The source : https://velog.io/@peppermint100/Algo프로그래머스-더-맵게-in-Java" }, { "title": "[Algorithm] Hash2", "url": "/posts/algorithm-hash2/", "categories": "Development, Algorithm, Programmers", "tags": "algorithm, java, eng, programmers", "date": "2021-10-24 17:36:00 +0900", "snippet": "HashHashMap&amp;lt;Key, Value&amp;gt;Task2. 위장 in Programmers (Level 2)📌 Problemhttps://programmers.co.kr/learn/courses/30/lessons/42578📌 The point Use number of cases ex. If {hat=3, shirt=2, pants=1}, it must be calculated like (3*2*1) + (3*2) + (3*1) + (1*2) + 3 + 2 + 1 If the formula, it’s (n + 1) * (m + 1) * (o + 1) - 1 (⭐️⭐️⭐️ Do remember) Use HashMap HashMap.containsKey(String) HashMap.put(key, value) HashMap.get(key) HashMap.keySet() : iterator of keys 📌 Answerimport java.util.HashMap;class Solution { public int solution(String[][] clothes) { // for multiplication int answer = 1; // save &amp;lt;type, count&amp;gt; HashMap&amp;lt;String, Integer&amp;gt; map = new HashMap&amp;lt;&amp;gt;(); for (int i = 0; i &amp;lt; clothes.length; i++) { String type = clothes[i][1]; if (!map.containsKey(type)) map.put(type, 1); else map.put(type, map.get(type) + 1); } // result : ex. {eyewear=1, headgear=2} // calculate number of cases // ex. (eyewear1 + 1) * (headgear2 + 1) - 1 = 5 for (String keys : map.keySet()) answer *= (map.get(keys) + 1); answer -= 1; return answer; }}/**[Condition]- 매일 다른 옷을 조합 - clothes[i] : [&quot;name&quot;, &quot;type&quot;]- clothes.length : 1 ~ 30- clothes.[i].length : 1 ~ 20- 하루에 최소 한 개의 의상- return 서로 다른 옷의 조합의 수**/The source : https://sas-study.tistory.com/215📌 Words number of cases : 경우의 수 formula : 公式　공식 factor : 因数　인수 factorize : 因数分解 인수분해 multiplication : 곱셈 plus / minus / time / divided by : + / - / * / /Why I almost forgot math I learned when I was in high school? lolOf course it also is needed knowledge of the basic math in coding test.But it’s so interesting and funny because I like math and can feel I go back to young moment 🤭I’ll be the genious of math!!! Keep doing hard!" }, { "title": "[Algorithm] Hash", "url": "/posts/algorithm-hash/", "categories": "Development, Algorithm, Programmers", "tags": "algorithm, java, eng, programmers", "date": "2021-10-24 13:58:00 +0900", "snippet": "HashHashMap(Key, Value)Task전화번호 목록 in Programmers (Level 2)📌 Problemhttps://programmers.co.kr/learn/courses/30/lessons/42577📌 Answer1. Use HashMapThe point HashMap.containsKey(String) String.substring(start, end); Check the splited number is in map HashMap is super quick lol so, if hashmap, multi for loop was also okay…import java.util.HashMap;class Solution { public boolean solution(String[] phone_book) { // put datas of phone_book to HashMap // Q : why number is key? // A : because we&#39;re gonna use &#39;HashMap.containsKey(String)&#39;&#39; HashMap&amp;lt;String, Integer&amp;gt; map = new HashMap&amp;lt;&amp;gt;(); for (int i = 0; i &amp;lt; phone_book.length; i++) map.put(phone_book[i], i); // check there are num in the map for (String num : phone_book) { for (int i = 1; i &amp;lt; num.length(); i++) { if (map.containsKey(num.substring(0, i))) return false; } } return true; }}The source : https://coding-grandpa.tistory.com/entry/프로그래머스-전화번호-목록-해시-Lv-2-자바-Java2. Use Arrays.sort()The point Arrays.sort(String[]) ex. before sorting { &quot;99&quot;, &quot;7894&quot;, &quot;123&quot;, &quot;123456&quot;, &quot;789&quot; } after sorting { &quot;123&quot;, &quot;123456&quot;, &quot;789&quot;, &quot;7894&quot;, &quot;99&quot;} String.startsWith(String) But it was slower than HashMapimport java.util.Arrays;class Solution { public boolean solution(String[] phone_book) { Arrays.sort(phone_book); // you only need to compare the current number and the next number // because Arrays.sort(); for (int i = 0; i &amp;lt; phone_book.length - 1; i++) if (phone_book[i + 1].startsWith(phone_book[i])) return false; return true; }}The source : https://sso-feeling.tistory.com/318?category=922139📌 Words 2 or more, more than 2: 以上 2 or less : 以下 over 2, above 2, grater than 2 : 超過（ちょうか） under 2, below 2, less than 2 : 未満（みまん）" }, { "title": "[Algorithm] Sort2", "url": "/posts/algorithm-sort2/", "categories": "Development, Algorithm, Programmers", "tags": "algorithm, java, eng, programmers", "date": "2021-10-24 11:50:00 +0900", "snippet": "SortTask2. H-Index in Programmers (Level 2)📌 Problemhttps://programmers.co.kr/learn/courses/30/lessons/42747📌 Answer1. Use Arrays.sort()import java.util.Arrays;class Solution { public int solution(int[] citations) { int answer = 0; Arrays.sort(citations); for (int i = 0; i &amp;lt; citations.length; i++) { int h = citations.length - i; // from last if (citations[i] &amp;gt;= h) { answer = h; break; } } return answer; }}/**[Question]- 논문 n편 (1 &amp;lt;= n &amp;lt;= 1000) -&amp;gt; h번 이상 인용된 논문 = h편 이상 : h &amp;lt;= n (0 &amp;lt;= h &amp;lt;= 10000) -&amp;gt; 나머지 논문(h번 이하 인용) : n - h -&amp;gt; H-Index : h의 최댓값- citations : 논문의 인용 횟수- return H-IndexThe source : https://ju-nam2.tistory.com/742. Use Binary SearchBut this way takes longer than 1. Use Arrays.sort()import java.util.Arrays;class Solution { public int solution(int[] citations) { int answer = 0; Arrays.sort(citations); int len = citations.length; int h = 0; int low = 0; int high = len - 1; while (low &amp;lt;= high) { int mid = (low + high) / 2; h = len - mid; if (citations[mid] &amp;gt;= h) { if (mid == 0) { answer = h; break; } if (mid != 0 &amp;amp;&amp;amp; citations[mid - 1] &amp;lt;= h) { answer = h; // update high = mid - 1; // move to the left } else high = mid - 1; // move to the left } else low = mid + 1; // move to the right } return answer; }}The source : https://leetcode.com/problems/h-index-ii/discuss/1325353/java-binary-search-solution-ologn-time-o1-spaceActually, I came up with all of two ways. But, I couldn’t apply those….I have to learn more examples and get used to it.I ate Chueotang in the morning, but it tasted not good compared to the other restaurant I often go hh.I’m gonna solve two more problems and go to bakery to buy sandwichs consisted of a half of basil chicken sandwich and a half of sweet pumpkin sandwich!It sounds like nnyami 😆" }, { "title": "[Algorithm] Sort", "url": "/posts/algorithm-sort/", "categories": "Development, Algorithm, Programmers", "tags": "algorithm, java, eng, programmers", "date": "2021-10-23 19:30:00 +0900", "snippet": "SortTask1. 가장 큰 수 in Programmers (Level 2)📌 Problemhttps://programmers.co.kr/learn/courses/30/lessons/42746📌 The point Used **Arrays.sort(array, Comparator)** It’s one of the fast way to sort array [Different type 1] Arrays.sort(array) If array is primitive type such as int[] and char[], it use Dual-Pivot QuickSort (InsertionSort + QuickSort). If array is Object type such as String[] and Integer[], it use TimSort (InsertionSort + MergeSort). – [Different type 2] Arrays.sort(array, new Comparator&amp;lt;String&amp;gt;() { @Override public int compare(String o1, String o2) { return ((o2 + o1).compareTo(o1 + o2)); }); 📌 Answerimport java.util.Arrays;class Solution { public String solution(int[] numbers) { // Convert int array to String array String[] result = new String[numbers.length]; for (int i = 0; i &amp;lt; numbers.length; i++) result[i] = String.valueOf(numbers[i]); // Sort (lambda expression) // specific meaning : String.compareTo(String) // why (o2 + o1)? because it sort datas by dscending order // then, (o1 + o2) -&amp;gt; become ascending order Arrays.sort(result, (o1, o2) -&amp;gt; (o2 + o1).compareTo(o1 + o2)); // [Same expression] // Comparator&amp;lt;String&amp;gt; comp = (o1, o2) -&amp;gt; (o2 + o1).compareTo(o1 + o2); // Arrays.sort(result, comp); // If there are multiple zero, return only 0 if (result[0].equals(&quot;0&quot;)) { return &quot;0&quot;; } // Convert String array to String String answer = &quot;&quot;; for (String a : result) answer += a; return answer; }}The source : https://haeng-on.tistory.com/7Don’t forget the contents of OCPJP!It’s quite useful on coding test." }, { "title": "[Algorithm] Greedy3", "url": "/posts/algorithm-greedy3/", "categories": "Development, Algorithm, Programmers", "tags": "algorithm, java, eng, programmers", "date": "2021-10-23 18:17:00 +0900", "snippet": "Greedy algorithmTask3. 조이스틱 in Programmers (Level 2)📌 Problemhttps://programmers.co.kr/learn/courses/30/lessons/42860📌 The point Use the greedy Check the condition Choose the best at each moment move up vs down compare the length of movement move left vs right compare the length of movement 📌 Answerclass Solution { public int solution(String name) { int answer = 0; int len = name.length(); // if name only consists of &#39;A&#39; // -&amp;gt; the minimum movement = just go right continuously int min = len - 1; for (int i = 0; i &amp;lt; len; i++) { // get each char from String char c = name.charAt(i); // decide to move &#39;up or down&#39; // up : c - &#39;A&#39; // down : &#39;Z&#39; - c + 1 int move = (c - &#39;A&#39; &amp;lt; &#39;Z&#39; - c + 1) ? (c - &#39;A&#39;) : (&#39;Z&#39; - c + 1); answer += move; // decide to move &#39;right or left&#39; // 1. first, go right -&amp;gt; count index by using nextIndex int nextIndex = i + 1; while (nextIndex &amp;lt; len &amp;amp;&amp;amp; name.charAt(nextIndex) == &#39;A&#39;) nextIndex++; // 2. compare which is the minimum value and update &#39;min&#39; // - go right : min // - go back to left : (i * 2) + len - nextIndex // -&amp;gt; i * 2 : go right + go back to left // -&amp;gt; len - nextIndex : count from last index min = Math.min(min, (i * 2) + len - nextIndex); } answer += min; return answer; }}The source : https://hellodavid.tistory.com/4aIt is not difficult code, but I think it takes long time to come up with the way to solve.And I have a heavy stomachache these days, so I make a reservation on hostipal on next wednesday 🥲I hope I’m fine." }, { "title": "[Algorithm] Greedy2", "url": "/posts/algorithm-greedy2/", "categories": "Development, Algorithm, Programmers", "tags": "algorithm, java, eng, programmers", "date": "2021-10-23 14:20:00 +0900", "snippet": "Greedy algorithmTask2. 구명보트 in Programmers (Level 2)📌 Problemhttps://programmers.co.kr/learn/courses/30/lessons/42885📌 The point Use the greedy Check the condition Choose one from the below Count the number of persons who can ride a boat Count that person who will ride a boat alone Sort an array📌 Answerimport java.util.Arrays;class Solution { public int solution(int[] people, int limit) { int answer = 0; Arrays.sort(people); int min = 0; // the number of people who can ride a boat for (int max = people.length - 1; min &amp;lt;= max; max--) { if (people[min] + people[max] &amp;lt;= limit) min++; answer++; // ride a boat alone // System.out.println(&quot;min : &quot; + min); // System.out.println(&quot;max : &quot; + max); // System.out.println(&quot;answer : &quot; + answer); // System.out.println(); } return answer; }}/**[Condition]- 최대 2명씩- 구명보트를 최대한 적게 사용, 모든 사람을 구출[Test case]-[70kg, 50kg, 80kg, 50kg], limit : 100kg[Logic]- greedy algorithm**/The source : https://velog.io/@ajufresh/프로그래머스-구명보트-문제풀이-JavaI can’t come up with good greedy algorithm which can be the best choice at each moment when I solve the problem yet…." }, { "title": "[Algorithm] Greedy1", "url": "/posts/algorithm-greedy1/", "categories": "Development, Algorithm, Programmers", "tags": "algorithm, java, eng, programmers", "date": "2021-10-23 13:20:00 +0900", "snippet": "Greedy algorithmTask1. 큰 수 만들기 in Programmers (Level 2)📌 Problemhttps://programmers.co.kr/learn/courses/30/lessons/42883📌 The point Compare the size of numbers and save the result to Stack -&amp;gt; so, it’s quite fast because of stack📌 Answerimport java.util.Stack;class Solution { public String solution(String number, int k) { char[] result = new char[number.length() - k]; Stack&amp;lt;Character&amp;gt; stack = new Stack&amp;lt;&amp;gt;(); for (int i = 0; i &amp;lt; number.length(); i++) { char now = number.charAt(i); // make stack empty // important condition : stack.peek() &amp;lt; now // = if (the top of stack &amp;lt; now) delete top while (!stack.isEmpty() &amp;amp;&amp;amp; stack.peek() &amp;lt; now &amp;amp;&amp;amp; k &amp;gt; 0) { stack.pop(); k--; // System.out.println(&quot;k : &quot; + k); } stack.push(now); // System.out.println(&quot;now : &quot; + now); // System.out.println(&quot;stack : &quot; + stack); // System.out.println(); } // get the data in the order for (int i = 0; i &amp;lt; result.length; i++) result[i] = stack.get(i); // make char array to string return new String(result); }}/**[Logic]- greedy algorithm : choose the best answer at each moment- compare the numbers**/The source : https://wpioneer.tistory.com/110There are so many genius in the world,,,,I’ll study all ways how they solve the problem." }, { "title": "[Algorithm] Brute-force Search 3", "url": "/posts/algorithm-brute-force3/", "categories": "Development, Algorithm, Programmers", "tags": "algorithm, java, eng, programmers", "date": "2021-10-22 17:16:00 +0900", "snippet": "Brute-force SearchTaskPrevious task1Previous task23. 카펫 in Programmers (Level 2)📌 Problemhttps://programmers.co.kr/learn/courses/30/lessons/42842📌 The pointUsed recursion📌 Answerclass Solution { public int[] solution(int brown, int yellow) { int[] answer = new int[2]; int sum = brown + yellow; // 12 int hori, verti = 0; // find the possibility of hori and verti // condition : hori &amp;gt;= verti -&amp;gt; so i-- for (int i = sum / 2; i &amp;gt; 2; i--) { if (sum % i == 0) { hori = i; if (check(hori, brown, yellow)) { answer[0] = hori; answer[1] = sum / hori; break; } } } return answer; } private boolean check(int hori, int brown, int yellow) { int y_hori = hori - 2; if (yellow % y_hori != 0) return false; return true; }}/**[Question]return { horizontal length, vertical length }[Condition]- 8 &amp;lt;= brown &amp;lt;= 5000- 1 &amp;lt;= yellow &amp;lt;= 2,000,000- horizontal length &amp;gt;= vertical length[Algorithm]- Brute-force search : dfs (recursion)[Logic]- the goal : get hori, verti- it&#39;s okay only know one variable, hori or verti- brown must be 2 * hori + (verti - 2)- yello must be hori - 2**/" }, { "title": "[Algorithm] Brute-force Search 2", "url": "/posts/algorithm-brute-force2/", "categories": "Development, Algorithm, Programmers", "tags": "algorithm, java, eng, programmers", "date": "2021-10-22 16:23:00 +0900", "snippet": "Brute-force SearchTaskPrevious task2. 소수 찾기 in Programmers (Level 2)📌 Problemhttps://programmers.co.kr/learn/courses/30/lessons/42839📌 The pointUse backtracking (dfs -&amp;gt; recursion)📌 Answer// backtracking -&amp;gt; use recursionimport java.util.List;import java.util.ArrayList;class Solution { private boolean[] checked; private List&amp;lt;Integer&amp;gt; nums; public int solution(String numbers) { int answer = 0; nums = new ArrayList&amp;lt;&amp;gt;(); checked = new boolean[numbers.length()]; // string.length() for (int i = 1; i &amp;lt;= numbers.length(); i++) dfs(numbers, i, &quot;&quot;); // 자리수 증가시키기 for (int i = 0; i &amp;lt; nums.size(); i++) if (isPrimeNum(nums.get(i))) answer++; return answer; } private void dfs(String numbers, int len, String tmp) { if (tmp.length() == len) { int n = Integer.parseInt(tmp); if (!nums.contains(n)) nums.add(n); return; } for (int i = 0; i &amp;lt; numbers.length(); i++) { if (!checked[i]) { tmp += numbers.charAt(i); checked[i] = true; dfs(numbers, len, tmp); tmp = tmp.substring(0, tmp.length() - 1); checked[i] = false; } } } private boolean isPrimeNum(int n) { // case1. 0 or 1 if (n == 0 || n == 1) return false; // case2. it can be divided with other number for (int i = 2; i &amp;lt; n; i++) if (n % i == 0) return false; return true; }}/**[Question]- make primary number by using numbers(string) ** what is primary number? : the number can be only divided with 1 and itself.[Condition]- numbers : length = 1 ~ 7 (value = 0 ~ 9)**/The source : https://blog.naver.com/PostView.naver?blogId=seop1284&amp;amp;logNo=222450982972&amp;amp;parentCategoryNo=&amp;amp;categoryNo=9&amp;amp;viewDate=&amp;amp;isShowPopularPosts=true&amp;amp;from=searchIt’s quite difficult!Let’s resolve it afterwards." }, { "title": "[Algorithm] Brute-force Search", "url": "/posts/algorithm-brute-force/", "categories": "Development, Algorithm, Programmers", "tags": "algorithm, java, eng, programmers", "date": "2021-10-22 14:17:00 +0900", "snippet": "Brute-force Searchenumerate all possible candidates for the solution and check whether each candidate satisfies the problem&#39;s statement.It is often used with BFS / DFSTask1. 타겟 넘버 in Programmers (Level 2)📌 Problemhttps://programmers.co.kr/learn/courses/30/lessons/43165📌 The pointYou must visit all nodes and check all possibility.📌 AnswerCase 1. Used BFS (Queue)The point Brute-force search + BFS(Queue) make a variable ‘index’ for depth But, BFS is slower than DFS -&amp;gt; so DFS is more preferable than BFS.import java.util.Queue;import java.util.LinkedList;class Solution { class Pair { int index; int number; Pair(int index, int number) { this.index = index; this.number = number; } } public int solution(int[] numbers, int target) { int answer = 0; Queue&amp;lt;Pair&amp;gt; queue = new LinkedList&amp;lt;&amp;gt;(); queue.add(new Pair(0, numbers[0])); queue.add(new Pair(0, -numbers[0])); // -&amp;gt; at first, start the negative number (ex. -1) while (!queue.isEmpty()) { Pair now = queue.poll(); // get data and delete it // if it is last index if (now.index == numbers.length - 1) { // if it is same with target if (now.number == target) answer++; continue; } // case1. add int newNum1 = now.number + numbers[now.index + 1]; queue.add(new Pair(now.index + 1, newNum1)); // case2. minus int newNum2 = now.number - numbers[now.index + 1]; queue.add(new Pair(now.index + 1, newNum2)); } return answer; }}Case 2. Used DFS (Recursion)The point Brute-force search + DFS(Recursion) DFS is faster and more space-efficient than BFS -&amp;gt; you must select this way to solve itclass Solution { // main function public int solution(int[] numbers, int target) { int answer = 0; // recursion // case1. add answer += dfs(numbers, target, numbers[0], 1); // case2. minus answer += dfs(numbers, target, -numbers[0], 1); return answer; } private int dfs(int[] numbers, int target, int pre, int index) { if (index &amp;gt;= numbers.length) { if (pre == target) return 1; // answer++; return 0; } int answer = 0; // case1. add int cur1 = pre + numbers[index]; answer += dfs(numbers, target, cur1, index + 1); // case2. minus int cur2 = pre - numbers[index]; answer += dfs(numbers, target, cur2, index + 1); return answer; }}The source : https://www.pymoon.com/entry/Programmers-타겟-넘버-BFSDFS-Java-풀이" }, { "title": "[Diary] Today&#39;s diary", "url": "/posts/diary/", "categories": "Diary", "tags": "diary, eng", "date": "2021-10-21 22:20:00 +0900", "snippet": "I can say that this year, 2021 is the hardest year I’m doing my best everyday in my life. I slept only 4 hours everyday from march, 2021.But, I can’t sure I can get what I want.As time goes by, I’m losing confidence and self-esteem, especialy when I see mails which is writting I failed to get pass.It’s time to get used to it, but it always breaks my heart.And I come up with one question ‘how many more days I have to do my best’.But, you know, when I feel this kind of emotion, I feel grow up. Even if I didn’t get good result yet, honestly, these sad days make me strong and decide that I should be perfect.If the world don’t know my value and I can’t become shine in this world, let’s create new world I can be shine.Believe yourself.Don’t regret on your passionate past.Today will be yesterday, tomorrow will be today.So, just keep doing hard as always and make everyday and evey moment more precious.It will make a miracle for you, for your world, for your universe.Desparate triumphs over luckI’m unlucky like other lucky people, but I’m more desparate than anyone else.Desparate will win." }, { "title": "[Algorithm] Stack", "url": "/posts/algorithm-stack/", "categories": "Development, Algorithm, Programmers", "tags": "algorithm, java, eng, programmers", "date": "2021-10-21 21:06:00 +0900", "snippet": "StackExplainTask📌 Previous taskQueue task 1Queue task 2Queue task 31. 주식가격 in Programmers (Level 2)📌 Problemhttps://programmers.co.kr/learn/courses/30/lessons/42584📌 The point Used custom class Used stack efficiently📌 Answerimport java.util.Stack;class Solution { private class Price { int index; int price; public Price(int index, int price) { this.index = index; this.price = price; } } private Stack&amp;lt;Price&amp;gt; stack; public int[] solution(int[] prices) { int[] answer = new int[prices.length]; stack = new Stack&amp;lt;&amp;gt;(); // Object &#39;Price&#39; 1 ~ (i - 1) for (int i = 0; i &amp;lt; prices.length; i++) { int currentPrice = prices[i]; while (!stack.isEmpty()) { Price top = stack.peek(); // get only data if (top.price &amp;gt; currentPrice) { answer[top.index] = i - top.index; stack.pop(); // delete top data } else break; // do nothing } stack.push(new Price(i, currentPrice)); // add data } while (!stack.isEmpty()) { Price top = stack.pop(); // get top data and remove it answer[top.index] = prices.length - 1 - top.index; // &#39;-1&#39; is important that it catch the condition the last object&#39;s price is not down } return answer; }}/**[Question]- prices : 주식가격 (초 단위) -&amp;gt; values: 1 ~ 10,000, length: 2 ~ 100,000- return 가격이 떨어지지 않은 기간은 몇 초?**/The source : https://hongjw1938.tistory.com/10It is first time to solve a problem by using stack algorithm, so it was quite difficult…I think I know how to use queue well, but I didn’t get used to stack.Don’t forget a quote From zero to heroYou can do it." }, { "title": "[Algorithm] Queue3", "url": "/posts/algorithm-queue3/", "categories": "Development, Algorithm, Programmers", "tags": "algorithm, java, eng, programmers", "date": "2021-10-21 19:39:00 +0900", "snippet": "QueueExplainTaskPrevious task 1Previous task 2📌 3. 다리를 지나는 트럭 in Programmers (Level 2)⭐️ The point Used while loop and break📌 Answerimport java.util.Queue;import java.util.LinkedList; class Solution { private Queue&amp;lt;Integer&amp;gt; queue; public int solution(int bridge_length, int weight, int[] truck_weights) { int time = 0; int sumOfWeight = 0; queue = new LinkedList&amp;lt;&amp;gt;(); for (int i = 0; i &amp;lt; truck_weights.length; i++) { int truck = truck_weights[i]; while (true) { // case1. just add truck, don&#39;t need to consider sum of weights if (queue.isEmpty()) { queue.add(truck); sumOfWeight += truck; time++; break; // already added truck, so go out whlie loop } // case2. add truck and need to consider sum of weights else if (!queue.isEmpty() &amp;amp;&amp;amp; queue.size() == bridge_length) { int arrived = queue.poll(); sumOfWeight -= arrived; } // case3. else if (!queue.isEmpty()) { // Let&#39;s consider sum of weights // case2-1. if (sumOfWeight + truck &amp;gt; weight) { queue.add(0); // add nothing time++; } // case2-2. else { queue.add(truck); sumOfWeight += truck; time++; break; } } } } // have to + bridge_length because the remained trucks also must be arrived return time + bridge_length; // important }}/**[Question]- 트럭 여러 대가 정해진 순으로 건넘- return 모든 트럭이 다리를 &#39;순서대로 최단 시간 안에&#39; 건너려면 최소 몇 초?[Condition]- 다리 - 트럭이 최대 bridge_length대 올라갈 수 있으며 - weight 이하까지의 무게를 견딜 수 있습니다 - 단, 다리에 완전히 오르지 않은 트럭의 무게는 무시 - bridge_length, weight, truck_weights : 1 ~ 10,000[Example]- 트럭 2대 + 무게 총 합 10kg까지- 트럭 [7, 4, 5, 6]-&amp;gt; 최소 8초**/Let’s keep it simple always." }, { "title": "[Algorithm] DFS vs BFS", "url": "/posts/algorithm-dfs-bfs/", "categories": "Development, Algorithm, Contents", "tags": "algorithm, java, eng", "date": "2021-10-21 14:20:00 +0900", "snippet": "DFS vs BFS📌 Let’s compare   BFS DFS Full form Breadth-First Search Depth-First Search Data structure often used BFS uses Queue data structure to save the nodes which is already visited for finding the shortest path. (FIFO) DFS uses Stack data structure to save the nodes which is already visited (LIFO) Features BFS is better when target is closer to Source. -&amp;gt; There is no need of backtracking. DFS is better when target is far from source -&amp;gt; There is a need of backtracking. -&amp;gt; There is a possibility that it visit all nodes. Advantages A BFS will find the shortest path between the starting point and any other reachable node - A DFS on a binary tree generally requires less memory than BFS. - DFS can be easily implemented with recursion. - DFS is faster than BFS. Disadvantages - A BFS on a binary tree generally requires more memory than a DFS. - BFS is slower than DFS. A DFS doesn’t necessarily find the shortest path to a node, while DFS does. Situation - A problem requiring the shortest path - A problem that you must store the features of each path 📌 Implementation1. BFS- Used queueclass Graph { private int V; private LinkedList&amp;lt;Integer&amp;gt; adj[]; Graph(int v) { V = v; adj = new LinkedList[v]; for (int i=0; i&amp;lt;v; ++i) adj[i] = new LinkedList(); } void addEdge(int v, int w) { adj[v].add(w); } /* BFS */ void BFS(int s) { boolean visited[] = new boolean[V]; LinkedList&amp;lt;Integer&amp;gt; queue = new LinkedList&amp;lt;Integer&amp;gt;(); // Big difference with DFS // use queue features (FIFO) visited[s] = true; queue.add(s); while (queue.size() != 0) { // = (!queue.isEmpty()) // get the first node and delete it from queue s = queue.poll(); System.out.print(s + &quot; &quot;); // get other nodes near the node which visit Iterator&amp;lt;Integer&amp;gt; i = adj[s].listIterator(); while (i.hasNext()) { int n = i.next(); // if it is not a node which is already visited, check visiting and send to the last if (!visited[n]) { visited[n] = true; queue.add(n); } } /** This expression is also okay Queue&amp;lt;Integer&amp;gt; q = new LinkedList&amp;lt;Integer&amp;gt;(); q.offer(v); visited[v] = true; for (int i = 1; i &amp;lt; n+ 1 ; i++) { if (map[vv][i] == 1 &amp;amp;&amp;amp; !visited[i]) { q.offer(i); // visit map[vv][i~n] visited[i] = true; } } **/ } }}2. DFS- Used stackstatic int map[][];static boolean[] visited; static String answer = &quot;&quot;;public static void dfs_stack(int v) { Stack&amp;lt;Integer&amp;gt; stack = new Stack&amp;lt;Integer&amp;gt;(); stack.push(v); while (!stack.isEmpty()) { int vv = stack.pop(); visited[vv] = true; answer += vv + &quot; &quot;; for (int i = 1; i &amp;lt; n + 1; i++) { if (map[vv][i] == 1 &amp;amp;&amp;amp; !visited[i]) { stack.push(i); break; // Big difference with BFS } } }}- Used recursionclass Graph { private int V; private LinkedList&amp;lt;Integer&amp;gt; adj[]; Graph(int v) { V = v; adj = new LinkedList[v]; // initialization for (int i=0; i &amp;lt; v; ++i) adj[i] = new LinkedList(); } void addEdge(int v, int w) { adj[v].add(w); } /* DFS */ void DFS(int v) { boolean visited[] = new boolean[V]; // Big difference with BFS // recursion with v as the starting node DFSUtil(v, visited); } // recursion void DFSUtil(int v, boolean visited[]) { // store the node already is visited visited[v] = true; System.out.print(v + &quot; &quot;); // get other nodes near the node which visit Iterator&amp;lt;Integer&amp;gt; it = adj[v].listIterator(); while (it.hasNext()) { int n = it.next(); // if it is not a node which is already visited, revoke DFSUtil if (!visited[n]) DFSUtil(n, visited); } }} ** the source https://devuna.tistory.com/32https://velog.io/@ming/DFS-vs-BFS-탐색" }, { "title": "[Algorithm] Queue2", "url": "/posts/algorithm-queue2/", "categories": "Development, Algorithm, Programmers", "tags": "datastructure, java, eng, algorithm, programmers", "date": "2021-10-20 22:50:00 +0900", "snippet": "QueueExplainTaskPrevious task 12. 프린터 in Programmers (Level 2)https://programmers.co.kr/learn/courses/30/lessons/42587📌 The point Code that is often used when using queue while (!queue.isEmpty()) { int num = queue.poll(); // blah blah blah} Used custom class Input class to queue Used boolean flag📌 Answerimport java.util.Queue;import java.util.LinkedList;class Solution { class Task { int index; int priority; public Task(int index, int priority) { this.index = index; this.priority = priority; } } public int solution(int[] priorities, int location) { int answer = 0; // make queue of printing Queue&amp;lt;Task&amp;gt; queue = new LinkedList&amp;lt;&amp;gt;(); for (int i = 0; i &amp;lt; priorities.length; i++) { queue.add(new Task(i, priorities[i])); } int nowIndex = 0; while (!queue.isEmpty()) { // get first task Task currTask = queue.poll(); boolean flag = false; // true if there are bigger priorities in remaining queue for (Task t : queue) if (t.priority &amp;gt; currTask.priority) flag = true; if (flag) queue.add(currTask); else { // if it&#39;s the biggest priority // to skip big priority in order from next time nowIndex++; // if it&#39;s my print if (currTask.index == location) { answer = nowIndex; break; } } } return answer; }}/**중요도가 높은 문서를 먼저 인쇄하는 프린터[Logic]1. 인쇄 대기목록의 가장 앞에 있는 문서(J)를 대기목록에서 꺼냅니다. 2. 나머지 인쇄 대기목록에서 J보다 중요도가 높은 문서가 한 개라도 존재하면, J를 대기목록의 가장 마지막에 넣습니다. 3. 그렇지 않으면 J를 인쇄합니다. return 내가 인쇄를 요청한 문서가 몇 번째로 인쇄되는지[Condition]- priorities : 문서의 중요도 배열 (value : 1~9)- location : 내가 인쇄를 요청한 문서가 현재 대기목록의 어떤 위치에 있는지 (0~99 like index of array) ** the number of documents : 1 ~ 100- ex. priorities : 1 1 9 1 1 1 -&amp;gt; print by order &#39;C D E F A B&#39;**/// [Test case]// 2 1 3 2 -&amp;gt; 1 3 2 2 -&amp;gt; 3 2 2 1 -&amp;gt; return 1// 9 1 1 1 1 1 -&amp;gt; return 5// 3 5 1 2 4 2, 4(4) My head can’t work well anymore….I’m gonna go back home" }, { "title": "[Data Sturcture] Stack vs Queue", "url": "/posts/stack-queue/", "categories": "Development, DataStructure", "tags": "datastructure, java, eng", "date": "2021-10-20 16:02:00 +0900", "snippet": "Stack 🆚 Queue📌 Common featurethe ways to use &#39;Linear structure&#39; ( + &#39;List, LinkedList )📌 Let’s compare   Stack Queue Feature LIFO (Last In Fisrt Out) FIFO (First In First Out) Input / Output push(data) / pop() enQueue() / deQueue() Parts - front : the part only remove data / rear : the part only insert data Situations Stack can be used in most situations Queue is used in situations where data needs to be processed in order of the time. Examples of situation - undo - make the strings in reverse order - BFS (Breadth-First Search) - waiting process Implementation Stack, ArrayDeque LinkedList, ArrayDeque Useful algorithm DFS (Depth-First Search) BFS (Breadth-First Search) ⭐️ Methods in Java8StackQueue📌 ImplementationStackimport java.util.Stack;import java.util.stream.Collectors;Stack&amp;lt;String&amp;gt; stack1 = new Stack&amp;lt;String&amp;gt;();// = Deque&amp;lt;String&amp;gt; stack1 = new ArrayDeque&amp;lt;String&amp;gt;(); for complex and speedy stack// push()stack1.push(&quot;A&quot;);stack1.push(&quot;B&quot;);stack1.push(&quot;C&quot;);List&amp;lt;String&amp;gt; list = stack1.stream().collect(Collectors.toList());System.out.println(&quot;Stack1 : &quot; + list); // Stack : [A, B, C]// pop()System.out.println(stack1.pop()); // [C] &amp;amp; delete itSystem.out.println(stack1); // [A, B]// clear()stack1.clear();System.out.println(stack1); // null//******Stack&amp;lt;Integer&amp;gt; stack2 = new Stack&amp;lt;&amp;gt;();// push()stack2.push(5);stack2.push(2);stack2.push(7);// peek()System.out.println(stack2.peek()); // 7 -&amp;gt; only return the last dataSystem.out.println(stack2); // [5, 2, 7]// size(), empty(), contains()System.out.println(stack.size()); // 3System.out.println(stack.empty()); // falseSystem.out.println(stack.contains(1)); // false -&amp;gt; check there is &#39;1&#39; in stack, contains(int value)// search()System.out.println(stack.search(2)) // 2 -&amp;gt; return indexSystem.out.println(stack.search(5)) // 1Queueimport java.util.Queue;import java.util.LinkedList;Queue&amp;lt;Integer&amp;gt; queue = new LinkedList&amp;lt;&amp;gt;();// = Deque&amp;lt;String&amp;gt; qu = new ArrayDeque&amp;lt;String&amp;gt;(); for complex and speedy queue// add()queue.add(5);queue.add(1);queue.add(2);queue.add(3);queue.add(4);queue.forEach((value)-&amp;gt;{ System.out.print(value);}); // 51234// poll()System.out.println(queue.poll()); // 5 &amp;amp; delete itSystem.out.println(queue); // [1,2,3,4]System.out.println(queue.poll()); // 1 &amp;amp; delete itSystem.out.println(queue); // [2,3,4]// peek()System.out.println(queue.peek()); // 2System.out.println(queue); // [2, 3, 4] // remove()queue.remove(3);System.out.println(queue); // [2, 4]Suddenly, I come up with ‘Stack overflow’ and me when I studied for OCPJP lol" }, { "title": "[Algorithm] Queue1", "url": "/posts/algorithm-queue/", "categories": "Development, Algorithm, Programmers", "tags": "datastructure, java, eng, algorithm, programmers", "date": "2021-10-20 16:02:00 +0900", "snippet": "QueueExplainTask1. 기능개발 in Programmers (Level 2)https://programmers.co.kr/learn/courses/30/lessons/42586📌 The point Code that is often used when using queue while (!queue.isEmpty()) { int num = queue.poll(); // blah blah blah} Convert List to int[] array listname.stream().mapToInt(x -&amp;gt; x).toArray(); 📌 Answerimport java.util.Queue;import java.util.LinkedList;import java.util.List;import java.util.ArrayList;class Solution { public int[] solution(int[] progresses, int[] speeds) { List&amp;lt;Integer&amp;gt; answer = new ArrayList&amp;lt;&amp;gt;(); // 1. make a queue which has the days of each progresses Queue&amp;lt;Integer&amp;gt; queue = new LinkedList&amp;lt;&amp;gt;(); int n = progresses.length; for (int i = 0; i &amp;lt; n; i++) { int day = 0; while (progresses[i] + speeds[i] * day &amp;lt; 100) day++; queue.add(day); } // 2. find the release day // case1 : day1 &amp;lt; day2 // case2 : day1 &amp;gt;= day2 int day1 = queue.poll(); int day2 = 0; int count = 1; while (!queue.isEmpty()) { day2 = queue.poll(); if (day1 &amp;gt;= day2) count++; else { answer.add(count); count = 1; // initialization day1 = day2; // switch } } answer.add(count); // important return answer.stream().mapToInt(x -&amp;gt; x).toArray(); }}// [condition]// 1. 배포 순 작업 진도 : progresses (&amp;lt;=100) (value : 1~99)// 2. 작업별 &#39;개발 속도&#39; : speeds (&amp;lt;=100) (value : 1~100)// 3. 배포는 하루에 한 번만, 매일 하루 끝에// return 각 배포마다 몇 개의 기능이 배포? // [Logic]// 가장 앞에 있는 기능이 개발 완료될 때, 이미 개발 완료 된 뒤에 있는 기능이 같이 배포되고 out -&amp;gt; 뒤의 기능들이 재정렬됨 -&amp;gt; 반복// ---&amp;gt; Use LinkedList (Queue : FIFO)// dynamic programming// 1. 모든 기능이 개발 완료되는 날짜 구하기// -&amp;gt; 개발 완료되는 날짜를 linkedlist에 저장하기 ok// 2. day1 &amp;lt; day2 라면, answer.add(count), queue에서 poll()// 아니라면, (day1 &amp;gt;= day2)// 3. day1 &amp;lt; day2가 될때까지 count++, queue에서 poll()// 4. answer.add(count)// 5. 새로 만들어진 queue로 다시 1, 2, 3을 반복// [Test case]// 7 3, 9 -&amp;gt; [2, 1]// 5, 10 1 1, 20 1 -&amp;gt; [1, 3, 2]// 5, 10 1 1 1, 20 -&amp;gt; [1, 4, 1]// 5, 10 1 1, 3, 5 -&amp;gt; [1, 3, 1, 1]/**System.out.println(&quot;day1 : &quot; + day1);System.out.println(&quot;day2 : &quot; + day2);System.out.println(&quot;in loop : &quot; + queue);System.out.println(&quot;count : &quot; + count);System.out.println(&quot;answer : &quot; + answer);System.out.println();**/Important words natural number : 자연수 (1~) positive integer : 양의 정수 negative integer : 음의 정수Solving problem by using queue is quite fun 😆" }, { "title": "[Diary] The goal from today", "url": "/posts/the-goal/", "categories": "Diary", "tags": "diary, eng, algorithm", "date": "2021-10-20 01:17:00 +0900", "snippet": "1. The goalSolving at least 100 problems until 11/11 and passing the coding test ---2. For this goalStudy scheduleAt least 5 algorithm problems everyday (~2021.11.11)(Don’t sleep before you are done)Algorithm site- LeetCodehttps://leetcode.com/problemset/algorithms/?difficulty=MEDIUM&amp;amp;page=1- HackerRankhttps://www.hackerrank.com- Codilityhttps://app.codility.com/programmers/- Programmershttps://programmers.co.kr/learn/challengesGood information about coding testPost : https://m.hanbit.co.kr/channel/category/category_view.html?cms_code=CMS7793635735The most frequently asked problem in the coding test Greedy Implementation BFS/DFS (Breadth-First Search/ Depth-First Search) BS (Brute-force Search = Exhaustive Search)I saw a blog post someone wrote that if you prepare coding test, you have to solve at least 10 questions at each coding site, because every company give us the different site.I’m gonna do it first!Well begun is half done.Let’s challenge!I’ll make miracle in the world.Cheer up, yuha🌈" }, { "title": "[Algorithm] Dynamic programming", "url": "/posts/algorithm-dynamic-programming/", "categories": "Development, Algorithm, Codility", "tags": "algorithm, java, eng", "date": "2021-10-20 01:15:00 +0900", "snippet": "I’ve mentioned this before, but I’m gonna explain it in more detail.What is dynamic programming?An algorithmic paradigm that1️⃣ solves a given complex problem by breaking it into subproblemsand2️⃣ stores the results of subproblems to avoid computing the same results againFeature of dynamic programming📌 Memoization make dynamic table and store the results of expensive function calls for do later things. When you do the next task, you calculate it by looking at the values stored in the table, it’s not calculating it from the beginning. 📌 Condition (Property)For dynamic programming, these two conditions is needed. Optimal substructure An optimal solution to the problem contains an optimal solution to subproblems. Overlapping problems A problem have overlapping subproblems which are reused several times or a recursive algorithm for the problem solves the same subproblem over and over rather than always generating new subproblems. 📌 Example Assembly Line Problem Matrix Chain Multiplication Problem 0/1 Knapsack Problem⭐️ Plus‘Dynamic programming’ 🆚 ‘Divide and conquer algorithm’ Common feature solve an optimization problem by breaking it down into simpler subproblem Differencethe divide and conquer : combines the solutions of the sub-problems to obtain the solution of the main problemdynamic programming : uses the result of the sub-problems to find the optimum solution of the main problem" }, { "title": "[Data Sturcture] Quick sort", "url": "/posts/quick-sort/", "categories": "Development, DataStructure", "tags": "datastructure, java, eng", "date": "2021-10-19 13:31:00 +0900", "snippet": "What is quick sort?Make a pivot which means middle index to divide array.It is based on divide and conquer algorithm Implementation⭐️ The point quickSort() : main sort() partition() swap()public class QuickSorter { // main public static void quickSort(int[] arr) { sort(arr, 0, arr.length - 1); } private static void sort(int[] arr, int low, int high) { if (low &amp;gt;= high) return; int mid = partition(arr, low, high); // divide sort(arr, low, mid - 1); // 0 ~ mid - 1 sort(arr, mid, high); // mid ~ arr.length - 1 } private static int partition(int[] arr, int low, int high) { int pivot = arr[(low + high) / 2]; while (low &amp;lt;= high) { while (arr[low] &amp;lt; pivot) low++; while (arr[high] &amp;gt; pivot) high--; if (low &amp;lt;= high) { swap(arr, low, high); low++; high--; } } return low; } private static void swap(int[] arr, int i, int j) { int tmp = arr[i]; arr[i] = arr[j]; arr[j] = tmp; }}" }, { "title": "[Data Sturcture] sort methods", "url": "/posts/arrays-sorts/", "categories": "Development, DataStructure", "tags": "datastructure, java, eng", "date": "2021-10-19 13:31:00 +0900", "snippet": "📌 What is ###.sort()?sort the datas of array or list ascending order or descending order📌 Sort arrayArrays.sort() The primitive way to sort array It will increase time complexity on your code from O(n) to O(n log n) (average is O(n log n)) and also increase space complexity from O(n/2) to O(1).Because in Java 8, Arrays.sort is implemented with Dual-pivot Quicksort algorithm, not single pivot.// Ascending orderint[] array = new int[] {2, -1, 9, 4};Arrays.sort(array);System.out.prinln(array); // {-1, 1, 4, 9};// Descending order// *** Only wrapper class can be sorted by descending order Integer[] array = new Integer[] {2, -1, 9, 4};Arrays.sort(array, Collections.reverseOrder());System.out.prinln(array); // {9, 4, 2, -1};// lambda expressionArrays.sort(array, (int x[] - int y[] -&amp;gt; x[0] - y[0]))📌 Sort list1. Collections.sort() The way to sort list It will increase a time complexity of O(n log n)import java.util.ArrayList;import java.util.Arrays;import java.util.Collections; // importantpublic class Sort { public static void main(String[] args) { ArrayList&amp;lt;String&amp;gt; list = new ArrayList&amp;lt;&amp;gt;(Arrays.asList(&quot;C&quot;, &quot;A&quot;, &quot;B&quot;, &quot;a&quot;)); // Ascending order Collections.sort(list); System.out.println(list); // [A, B, C, a] // Descending order Collections.sort(list, Collections.reverseOrder()); System.out.println(list); // [a, C, B, A] // Ascending order without checking cases (uppercase and lowercase) Collections.sort(list, String.CASE_INSENSITIVE_ORDER); System.out.println(list); // [a, A, B, C] // Descending order without considering cases (uppercase and lowercase) Collections.sort(list, Collections.reverseOrder(String.CASE_INSENSITIVE_ORDER)); System.out.println(list); // [C, B, a, A] }}2. List.sort() The way to sort listimport java.util.ArrayList;import java.util.Arrays;import java.util.Comparator; // importantpublic class Sort { public static void main(String[] args) { ArrayList&amp;lt;String&amp;gt; list = new ArrayList&amp;lt;&amp;gt;(Arrays.asList(&quot;C&quot;, &quot;A&quot;, &quot;B&quot;, &quot;a&quot;)); // Ascending order list.sort(Comparator.naturalOrder()); System.out.println(list); // [A, B, C, a] // Descending order list.sort(Comparator.reverseOrder()); System.out.println(list); // [a, C, B, A] // Ascending order without checking cases (uppercase and lowercase) list.sort(String.CASE_INSENSITIVE_ORDER); System.out.println(list); // [a, A, B, C] // Descending order without checking cases (uppercase and lowercase) list.sort(Collections.reverseOrder(String.CASE_INSENSITIVE_ORDER)); System.out.println(list);; // [C, B, a, A] }}2-1. List.sort() with lambdaimport java.util.ArrayList;import java.util.Arrays;public class Sort { public static void main(String[] args) { // type1 : Integer ArrayList&amp;lt;String&amp;gt; list = new ArrayList&amp;lt;&amp;gt;(Arrays.asList(2, 4, 7, -1)); list.sort((num1, num2) -&amp;gt; num1 - num2); list.sort((num1, num2) -&amp;gt; Integer.compare(num1, num2)); list.sort(Integer::compare); // type2 : String ArrayList&amp;lt;String&amp;gt; list = new ArrayList&amp;lt;&amp;gt;(Arrays.asList(&quot;C&quot;, &quot;A&quot;, &quot;B&quot;, &quot;a&quot;)); list.sort((s1, s2) -&amp;gt; s1.getAlphabet() - s2.getAlphabet()); list.sort(comparing(English::getAlphabet)); // suppose there is a class &#39;English&#39; which has a getter &#39;getAlphabet&#39;Important words ascending descendingThe source :https://stackoverflow.com/questions/22571586/will-arrays-sort-increase-time-complexity-and-space-time-complexity https://atechdaily.com/posts/Difference-between-Arrays-sort-and-Collections-sort" }, { "title": "[Algorithm] Fibonacci numbers1", "url": "/posts/algorithm-fibonacci1/", "categories": "Development, Algorithm, Codility", "tags": "algorithm, java, eng, codility", "date": "2021-10-18 22:35:00 +0900", "snippet": "What is fibonacci numbers?1️⃣ The first two numbers in the Fibonacci sequence are 0 and 1, and each subsequent number is the sum of the previous two.2️⃣ Enumeration of the Fibonacci numbers can be done faster simply by using a basis of dynamic programming###Example not efficientFinding Fibonacci numbers recursively.def fibonacci(n): if (n &amp;lt;= 1): return n return fibonacci(n - 1) + fibonacci(n - 2)###Example efficientFinding Fibonacci numbers dynamically. (by using a basis of dynamic programming)The time complexity of this algorithm is O(n).def fibonacciDynamic(n): fib = [0] * (n + 2) # initialization fib[1] = 1 # fib[0] = 0 for i in xrange(2, n + 1): # memozation fib[i] = fib[i - 1] + fib[i - 2] return fib[n]+ Then, what is dynamic programming?1️⃣ An algorithmic technique for solving an optimization problem by breaking it down into simpler subproblem2️⃣ Store the result of subproblems and reuse itThe point #####⭐️ Memoization store the results of expensive function calls and returning the cached result when the same inputs occur again.#####⭐️ VS &#39;Divide and conquer algorithm&#39; Common feature solve an optimization problem by breaking it down into simpler subproblem Difference ``` the divide and conquer combines the solutions of the sub-problems to obtain the solution of the main problem dynamic programming uses the result of the sub-problems to find the optimum solution of the main problem```Tasks1. FibFrog in codility (Lesson 13): Count the minimum number of jumps required for a frog to get to the other side of a river.It’s quite difficult lol🥲Questionhttps://app.codility.com/programmers/lessons/13-fibonacci_numbers/fib_frog/AnswerRESULTclass Solution { private int[] fibArray; public int solution(int[] A) { int N = A.length; makeFibArray(N); int fibLength = fibArray.length; int result = -1; for (int i = 0; i &amp;lt;= N; i++) { // i : for A array if (i == N || A[i] == 1) { int min = Integer.MAX_VALUE; for (int j = 0; j &amp;lt; fibLength &amp;amp;&amp;amp; fibArray[j] &amp;lt;= i + 1; j++) { // j : for fibArray final int start = i - fibArray[j]; if (start == -1) min = 1; else if (A[start] &amp;gt; 0) { if (A[start] + 1 &amp;lt; min) min = A[start] + 1; } } if (i &amp;lt; N) { if (min == Integer.MAX_VALUE) A[i] = 0; else A[i] = min; } else { // i == N : arrived if (min != Integer.MAX_VALUE) result = min; } } } return result; } private void makeFibArray(int N) { fibArray = new int[N &amp;lt; 2 ? 2 : N + 1]; fibArray[0] = 1; fibArray[1] = 2; for (int i = 2; fibArray[i - 1] &amp;lt;= N; i++) fibArray[i] = fibArray[i - 1] + fibArray[i - 2]; }}" }, { "title": "[Algorithm] Caterpillar method 3", "url": "/posts/algorithm-caterpillar3/", "categories": "Development, Algorithm, Codility", "tags": "algorithm, java, eng, codility", "date": "2021-10-17 12:08:00 +0900", "snippet": "See previous postTasks4. MinAbsSumOfTwo in codility (Lesson 15): Find the minimal absolute value of a sum of two elements.My first answer It occurred timeout error… Time complexity: O(N * N) (No~~~~~😫)import java.lang.Math;class Solution { // (P, Q) -&amp;gt; |A[P] + A[Q]|, 0 ≤ P ≤ Q &amp;lt; N // 1. set a -&amp;gt; for // 2. set b -&amp;gt; for ** I wondered multiple for loop is okay for time complexity? // 3. get a + b and make it to the absolute value // 4. compare the previous value -&amp;gt; if the current is smaller, save to variable // 5. return the last value private int min = 0; public int solution(int[] A) { min = Math.abs(A[0] + A[0]); for (int a : A) { for (int b : A) { if (min &amp;gt; Math.abs(a + b)) min = Math.abs(a + b); } } return min; }}Final answer⭐️ The point Don’t use only for loop -&amp;gt; I thought two for loop is okay lol-&amp;gt; Let’s avoid two for loop, too!! Don’t forget this problem is related with caterpillar method algorithmRESULTimport java.util.Arrays;import java.lang.Math;class Solution { public int solution(int[] A) { int min = Integer.MAX_VALUE; int p = 0; int q = A.length - 1; Arrays.sort(A); while (p &amp;lt;= q) { // the other way of for loop int current = A[p] + A[q]; min = Math.min(min, Math.abs(current)); // caterpillar method if (current &amp;lt; 0) p++; // - else q--; // + } return min; }}QuestionLet A be a non-empty array consisting of N integers.The abs sum of two for a pair of indices (P, Q) is the absolute value |A[P] + A[Q]|, for 0 ≤ P ≤ Q &amp;lt; N.For example, the following array A: A[0] = 1 A[1] = 4 A[2] = -3has pairs of indices (0, 0), (0, 1), (0, 2), (1, 1), (1, 2), (2, 2). The abs sum of two for the pair (0, 0) is A[0] + A[0] = |1 + 1| = 2. The abs sum of two for the pair (0, 1) is A[0] + A[1] = |1 + 4| = 5. The abs sum of two for the pair (0, 2) is A[0] + A[2] = |1 + (−3)| = 2. The abs sum of two for the pair (1, 1) is A[1] + A[1] = |4 + 4| = 8. The abs sum of two for the pair (1, 2) is A[1] + A[2] = |4 + (−3)| = 1. The abs sum of two for the pair (2, 2) is A[2] + A[2] = |(−3) + (−3)| = 6.the function should return 1, as explained above.Write an efficient algorithm for the following assumptions: - N is an integer within the range [1..100,000]; - each element of array A is an integer within the range [−1,000,000,000..1,000,000,000].New words indices : multiple indexes" }, { "title": "[Algorithm] Caterpillar method 2", "url": "/posts/algorithm-caterpillar2/", "categories": "Development, Algorithm, Codility", "tags": "algorithm, java, eng, codility", "date": "2021-10-17 11:02:00 +0900", "snippet": "See previous postTasks3. CountTriangles in codility (Lesson 15): Count the number of triangles that can be built from a given set of edges.My first answer -&amp;gt; occurred timeout errors…. Time complexity : O(N**3) Performance tests : score 0 …🥲The reason why it occured errors : nested loop (I guess) -&amp;gt; so answer can’t be tested with large datasclass Solution { public int solution(int[] A) { // p, q, r -&amp;gt; A[P], A[Q] and A[R], 0 ≤ P &amp;lt; Q &amp;lt; R &amp;lt; N // 1. set p -&amp;gt; for // 2. set q -&amp;gt; for // 3. set r -&amp;gt; for // 4. check conditions // A[P] + A[Q] &amp;gt; A[R] : 1 + 2 &amp;gt; 3 -&amp;gt; if // A[Q] + A[R] &amp;gt; A[P] : 2 + 3 &amp;gt; 1 -&amp;gt; if // A[R] + A[P] &amp;gt; A[Q] : 3 + 1 &amp;gt; 2 -&amp;gt; if // count++ // else continue; int count = 0; for (int p = 0; p &amp;lt; A.length - 2; p++) { // p for (int q = p + 1; q &amp;lt; A.length - 1; q++) { // q for (int r = q + 1; r &amp;lt; A.length; r++) { // r if (A[p] + A[q] &amp;gt; A[r]) if (A[q] + A[r] &amp;gt; A[p]) if (A[r] + A[p] &amp;gt; A[q]) count++; else continue; } } } return count; }}So,,,what should I do to solve it more efficiently?⭐️ The point Don’t use only for loop -&amp;gt; There are many other ways instead of for loop In addition, let’s start considering abstraction when you write codeRESULTimport java.util.Arrays;class Solution { // Encapsulation private int count = 0; private int[] A; public int solution(int[] A) { this.A = A; Arrays.sort(this.A); for (int p = 0; p &amp;lt; A.length - 2; p++) { int q = p + 1; int r = q + 1; while (q &amp;lt; A.length - 1) { if (r &amp;lt; A.length &amp;amp;&amp;amp; isTriangular(p, q, r)) { r++; } else { count += (r - q - 1); // important q++; } } } return count; } // abstraction private boolean isTriangular(int p, int q, int r) { return A[p] + A[q] &amp;gt; A[r] &amp;amp;&amp;amp; A[q] + A[r] &amp;gt; A[p] &amp;amp;&amp;amp; A[r] + A[p] &amp;gt; A[q]; }}QuestionAn array A consisting of N integers is given. A triplet (P, Q, R) is triangular if it is possible to build a triangle with sides of lengths A[P], A[Q] and A[R]. In other words, triplet (P, Q, R) is triangular if 0 ≤ P &amp;lt; Q &amp;lt; R &amp;lt; N and:A[P] + A[Q] &amp;gt; A[R],A[Q] + A[R] &amp;gt; A[P],A[R] + A[P] &amp;gt; A[Q].For example, consider array A such that: A[0] = 10 A[1] = 2 A[2] = 5 A[3] = 1 A[4] = 8 A[5] = 12There are four triangular triplets that can be constructed from elements of this array, namely (0, 2, 4), (0, 2, 5), (0, 4, 5), and (2, 4, 5).the function should return 4, as explained above.Write an efficient algorithm for the following assumptions: - N is an integer within the range [0..1,000]; - each element of array A is an integer within the range [1..1,000,000,000].New words triplets 三つ構成のセット" }, { "title": "[Algorithm] Caterpillar method", "url": "/posts/algorithm-caterpillar/", "categories": "Development, Algorithm, Codility", "tags": "algorithm, java, eng, codility", "date": "2021-10-16 19:31:00 +0900", "snippet": "What is caterpillar method?The caterpillar crawls through the array. We remember the front and back positions of the caterpillar,and at every step either of them is moved forward.Tasks1. AbsDistinct in codility (Lesson 15): Compute number of distinct absolute values of sorted array elements⭐️ The point Math.abs(number) ➡️ import java.lang.Math; HashSet ➡️ import java.util.HashSet; / import java.util.Set;import java.lang.Math;import java.util.HashSet;import java.util.Set;class Solution { public int solution(int[] A) { Set&amp;lt;Integer&amp;gt; set = new HashSet&amp;lt;&amp;gt;(); for (int i : A) set.add(Math.abs(i)); return set.size(); }}⭐️ ReviewSet : no sequence, no duplicate Class Features Method HashSet 순서가 필요없는 데이터를 hash table에 저장. Set 중에 가장 성능이 좋음 add(), size(), equals(), hashCode(), removeAll() TreeSet 저장된 데이터의 값에 따라 정렬됨. red-black tree 타입으로 값이 저장. HashSet보다 성능이 느림   LinkedHashSet 연결된 목록 타입으로 구현된 hash table에 데이터 저장. 저장된 순서에 따라 값이 정렬. 셋 중 가장 느림   Questiongiven a non-empty array A consisting of N numbers, returns absolute distinct count of array A.For example, consider array A such that: A[0] = -5 A[1] = -3 A[2] = -1 A[3] = 0 A[4] = 3 A[5] = 6The absolute distinct count of this array is 5, because there are 5 distinct absolute values among the elements of this array, namely 0, 1, 3, 5 and 6.Write an efficient algorithm for the following assumptions: - N is an integer within the range [1..100,000]; - each element of array A is an integer within the range [−2,147,483,648..2,147,483,647]; - array A is sorted in non-decreasing order.2. CountDistinctSlices in codility (Lesson 15): Count the number of distinct slices (containing only unique numbers)It’s quite difficult…..⭐️ The point boolean[] ➡️ to check which value is already checked. divide case ➡️ case1. distinct, case2. not distinctclass Solution { public int solution(int M, int[] A) { boolean[] seen = new boolean[M+1]; // 0~M // pair (p, q) int p = 0; int q = 0; int count = 0; // move p and q while (p &amp;lt; A.length &amp;amp;&amp;amp; q &amp;lt; A.length) { // case1. not distinct if (seen[A[q]] == true) { seen[A[p]] = false; p++; // go to next } else { // case2. distinct seen[A[q]] = true; count += (q - p + 1); // not just &#39;count++;&#39;, it has to count &#39;p ~ q&#39; q++; } if (count &amp;gt; 1000_000_000) return 1000_000_000; } return count; }}QuestionGiven an integer M and a non-empty array A consisting of N integers, returns the number of distinct slices.A pair of integers (P, Q), such that 0 ≤ P ≤ Q &amp;lt; N, is called a slice of array A. The slice consists of the elements A[P], A[P + 1], ..., A[Q]. A distinct slice is a slice consisting of only unique numbers. That is, no individual number occurs more than once in the slice.For example, consider integer M = 6 and array A such that: A[0] = 3 A[1] = 4 A[2] = 5 A[3] = 5 A[4] = 2There are exactly nine distinct slices: (0, 0), (0, 1), (0, 2), (1, 1), (1, 2), (2, 2), (3, 3), (3, 4) and (4, 4).Write an efficient algorithm for the following assumptions: - N is an integer within the range [1..100,000]; - M is an integer within the range [0..100,000]; - each element of array A is an integer within the range [0..M].New words reminiscent 連想させる contiguous 連続的な subsequence 次 compute 計算する distinct absolute values 絶対値" }, { "title": "[Algorithm] Greedy algorithm", "url": "/posts/algorithm-greedy/", "categories": "Development, Algorithm, Codility", "tags": "algorithm, java, eng, codility", "date": "2021-10-13 13:08:00 +0900", "snippet": "What is greedy algorithm?1️⃣ The algorithm makes the optimal choice at each step as it attempts to find the overall optimal way to solve the entire problem. (like who greedily want to do what he want at the moment, not for future)2️⃣ If it is not the best approach, then it often returns a result which is approximately correct but suboptimal. Advantages solutions to smaller instances of the problem can be straightforward and easy to understand Greedy methods are generally faster than dynamic programming. Disadvantages it is entirely possible that the most optimal short-term solutions may lead to the worst possible long-term outcome. Condition 1. Greedy-choice property A global optimum can be arrived at by selecting a local optimum. (which means local optimums make global optimum efficient in the end) 2. Optimal substructure An optimal solution to the problem contains an optimal solution to subproblems. (It is also related on dynamic programming) 1, 2 are quite same meaning..? lol Example Activity Selection Problem Fractional knapsack problem Kruskal’s Algorithm Tasks1. MaxNonoverlappingSegments in codility (Lesson 16): Find a maximal set of non-overlapping segmentsclass Solution { public int solution(int[] A, int[] B) { int N = A.length; if (N == 0) return 0; int count = 1; // standard : skip A[0], B[0] int b_end = B[0]; for (int i = 1; i &amp;lt; N; i++) { if (A[i] &amp;gt; b_end) { count++; b_end = B[i]; } } } }QuestionLocated on a line are N segments, numbered from 0 to N − 1, whose positions are given in arrays A and B. For each I (0 ≤ I &amp;lt; N) the position of segment I is from A[I] to B[I] (inclusive). The segments are sorted by their ends, which means that B[K] ≤ B[K + 1] for K such that 0 ≤ K &amp;lt; N − 1.Two segments I and J, such that I ≠ J, are overlapping if they share at least one common point. In other words, A[I] ≤ A[J] ≤ B[I] or A[J] ≤ A[I] ≤ B[J].For example, consider arrays A, B such that: A[0] = 1 B[0] = 5 A[1] = 3 B[1] = 6 A[2] = 7 B[2] = 8 A[3] = 9 B[3] = 9 A[4] = 9 B[4] = 10The size of a non-overlapping set containing a maximal number of segments is 3. For example, possible sets are {0, 2, 3}, {0, 2, 4}, {1, 2, 3} or {1, 2, 4}. There is no non-overlapping set with four segments.Write an efficient algorithm for the following assumptions: - N is an integer within the range [0..30,000]; - each element of arrays A, B is an integer within - the range [0..1,000,000,000]; - A[I] ≤ B[I], for each I (0 ≤ I &amp;lt; N); - B[K] ≤ B[K + 1], for each K (0 ≤ K &amp;lt; N − 1).2. TieRopes in codility (Lesson 16): Tie adjacent ropes to achieve the maximum number of ropes of length &amp;gt;= Kclass Solution { public int solution(int K, int[] A) { // return count when the sum is greater than or equals to K int count = 0; int sum = 0; for (int i = 0; i &amp;lt; A.length; i++) { sum += A[i]; if (sum &amp;gt;= K) { count++; sum = 0; } } return count; } }QuestionThere are N ropes numbered from 0 to N − 1, whose lengths are given in an array A, lying on the floor in a line. For each I (0 ≤ I &amp;lt; N), the length of rope I on the line is A[I].We say that two ropes I and I + 1 are adjacent. Two adjacent ropes can be tied together with a knot, and the length of the tied rope is the sum of lengths of both ropes. The resulting new rope can then be tied again.For a given integer K, the goal is to tie the ropes in such a way that the number of ropes whose length is greater than or equal to K is maximal.For example, consider K = 4 and array A such that: A[0] = 1 A[1] = 2 A[2] = 3 A[3] = 4 A[4] = 1 A[5] = 1 A[6] = 3We can tie:- rope 1 with rope 2 to produce a rope of length A[1] + A[2] = 5;- rope 4 with rope 5 with rope 6 to produce a rope of length A[4] + A[5] + A[6] = 5.After that, there will be three ropes whose lengths are greater than or equal to K = 4. It is not possible to produce four such ropes.For example, given K = 4 and array A such that: A[0] = 1 A[1] = 2 A[2] = 3 A[3] = 4 A[4] = 1 A[5] = 1 A[6] = 3the function should return 3, as explained above.Write an efficient algorithm for the following assumptions: - N is an integer within the range [1..100,000]; - K is an integer within the range [1..1,000,000,000]; - each element of array A is an integer within the range [1..1,000,000,000].Important words optimum : 最適なもの optimal solution　: 最適な解決方法 property : 特性" }, { "title": "[Diary] First post", "url": "/posts/first-post/", "categories": "Diary", "tags": "diary, eng", "date": "2021-10-13 12:19:00 +0900", "snippet": "The purpose of this blogHi, I’m yuha jo👋🏻This is my first content on this blog.Honestly, I’ve wanted to make a blog for a long time. But I didn’t have enough time to choose blog design, consider layout, learn how to post if it’s a github blog. Because I was super super busy for doing develop projects and preparing japanese interview, learning english conversation, bluh bluh bluh….. (I did my best til now and also will do my best from now on, because I don’t want to regret on my precious days later) Today is a historic and honored day that I finally did what I want!Btw, the reason why I make a blog is..1️⃣ to share what I studied about developing (ex. algorithm, design pattern, etc)2️⃣ to record my precious moment (ex. diary)I’m quite excited and curious about what I’ll record afterwards.I felt that it’s quite difficult to make and post a github blog or use markdown lang while doing first, but it was nothing when I look back hh.Yes, you don’t know exactly and you can’t be sure before you actually try it.Let&#39;s do my best everydayMake every single moment meaningfulLook beyond what you see" } ]
